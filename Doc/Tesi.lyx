#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\fancyhf{}               % Clear fancy header/footer
\fancyhead[RE]{\leftmark}
\fancyhead[LO]{\leftmark}
\fancyfoot[RE]{\thepage}
\fancyfoot[LO]{\thepage}
\fancyfoot[LE]{Carmen Barletta}   % My name in Left footer
\fancyfoot[RO]{Carmen Barletta}   % My name in Left footer
\makeatletter
\let\ps@plain\ps@fancy   % Plain page style = fancy page style
\makeatother
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\usepackage{algorithm,algpseudocode}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\renewcommand*\Call[2]{\textproc{#1}(#2)}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing onehalf
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
frontmatter
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../../UNI/Tesi/Cicci Tesi Help/document/images/20151105101950!Logo_Politecnico_Milano.png
	lyxscale 30
	width 60text%

\end_inset


\end_layout

\end_inset


\begin_inset VSpace 0cm
\end_inset


\end_layout

\begin_layout Standard
\align center
Scuola di Ingegneria Industriale e dell'Informazione
\begin_inset Newline newline
\end_inset

Dipartimento di Elettronica, Informazione e Bioingegneria
\end_layout

\begin_layout Standard
\align center
Corso di Laurea Magistrale in Computer Science and Engineering
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "50page%"
height "0.4pt"

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
large
\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

Privacy-Preserving Convolutional Neural Networks
\begin_inset Newline newline
\end_inset

 through Homomorphic Encryption
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\begin_inset VSpace 0.5cm
\end_inset


\end_layout

\begin_layout Standard
\align right

\size small
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="1">
<features tabularvalignment="middle">
<column alignment="right" valignment="top">
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Master Thesis of:
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Carmen Barletta
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="right" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Matr.
 877129
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\size default

\begin_inset VSpace 0.5cm
\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="1">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Advisor: 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Prof.
 Manuel Roveri
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Co-Advisor: 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Simone Disabato
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\align right
\begin_inset VSpace 1.4cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Academic Year 2017–2018
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter*
Ringraziamenti
\end_layout

\begin_layout Standard

\emph on
Questi cinque anni universitari si concludono con tante consapevolezze in
 più.
 Una e la più preziosa è che non importa quante difficoltà dovrò ancora
 affrontare, perché so che al mio fianco avrò sempre sei persone straordinarie
 pronte a sostenermi e a farmi capire quanto sono fortunata.
\begin_inset Newline newline
\end_inset

 Ringrazio Matteo, una persona speciale, che soprattutto in questi ultimi
 mesi ha dimostrato di avere un pazienza infinita, fingendo di lavorare
 anche nel tempo libero solo per non farmi sentire l’unica sfigata, vestendo
 i panni del coach armato di “bastone e carota” per spronarmi e consolarmi
 in ogni momento.
 
\begin_inset Newline newline
\end_inset

Ringrazio Mamma e Papà che hanno costantemente vegliato su di me e non si
 sono mai stancati di dispensare importantissimi consigli infondendomi coraggio
 e sicurezza.
 
\begin_inset Newline newline
\end_inset

Ringrazio Giò che è sempre stata un esempio da seguire per me, la roccia
 su cui contare e la sorella che mi ha sempre dato uno spunto per crescere
 e sognare.
 
\begin_inset Newline newline
\end_inset

Ringrazio Stè per tutte le chiacchierate, i momenti spensierati, il sorriso
 e gli abbracci che ha saputo donarmi incondizionatamente.
 
\begin_inset Newline newline
\end_inset

Ringrazio Annalisa, l’amica di una vita, per non avermi mai chiuso la porta
 in faccia soprattutto quando ne avevo più bisogno.
 
\begin_inset Newline newline
\end_inset

Questo traguardo lo dedico a voi perché ve lo meritate e perché spero che
 insieme ne raggiungeremo tanti altri.
\end_layout

\begin_layout Standard
\align right

\emph on
Grazie,
\end_layout

\begin_layout Standard
\align right

\emph on
Carmen
\end_layout

\begin_layout Chapter*
Abstract
\end_layout

\begin_layout Standard
In the last few years Machine Learning techniques have become popular thanks
 to their ability to solve complex problems.
 A popular machine-learning application paradigm considers 
\emph on
Software as a Service
\emph default
, that is a software distribution model in which a third-party provider,
 usually a cloud server, hosts applications (i.e., machine learning algorithms)
 and makes them available to customers over the Internet.
 On the one hand this cloud-based machine-learning parading is useful since
 it is usually fast and scalable, thus allows to reach a big number of users,
 but, on the other hand, it poses sever issues in terms of privacy because
 analyzed data, on the untrusted cloud server, might be sensible data.
 This issue is also particularly relevant after the recent approval of the
 European’s General Data Protection Regulation.
 This thesis provides a methodological solution about how to design a privacy-pr
eserving machine-learning system based on Homomorphic Encryption (HE).
 More precisely, this work focuses on Convolutional Neural Networks (CNNs)
 and presents both a methodology and a library to convert a pre-trained
 CNN to a privacy-preserving CNN able to process encrypted data, by employing
 the Brakerski, Fan and Vercauteren (BFV) HE scheme.
 Moreover, this thesis provides a mathematical formulation for the problem
 of finding the best encryption parameters for the BFV encryption scheme
 as well as a heuristic, based on a binary search algorithm, to solve the
 problem of the parameters’ choice, tailored on the privacy-preserving CNN.
 The proposed heuristic aims to find the best transformation for the given
 CNN.
 The experimental results show that the proposed methodology is able to
 operate on CNNs characterized by different architectures and processing
 pipelines.
 The results also prove that privacy-preserving deep learning is possible
 at the cost of a small loss in accuracy and slower predictions.
 
\end_layout

\begin_layout Chapter*
Estratto
\end_layout

\begin_layout Standard
Negli ultimi anni le tecniche di Machine Learning si sono diffuse ampiamente
 poiché esse permettono di risolvere problemi complessi.
 Uno dei modelli di machine-learning più comunemente usati è il Software
 as a Service.
 Si tratta di un modello di distribuzione del software nel quale un terzo,
 solitamente un server cloud, ospita le applicazioni (ovvero, gli algoritmi
 di machine learning) e le rende fruibili agli utenti attraverso Internet.
 Da un lato questa tecnica di machine learning basata sul cloud risulta
 utile poiché è solitamente veloce e scalabile, quindi permette di raggiungere
 un gran numero di utenti, ma, dall'altro lato pone seri problemi in termini
 di privacy, poiché i dati analizzati sul server, considerato inaffidabile,
 potrebbero essere dati sensibili.
 Questo aspetto negativo è particolarmente rilevante soprattutto alla luce
 della recente approvazione dell'European's General Data Protection Regulation.
 Questa tesi fornisce una soluzione metodologica alla progettazione di un
 sistema di machine-learning in grado di preservare la privacy dei dati
 analizzati, detto privacy-preserving, attraverso l'impiego della crittografia
 omomorfica.
 Più precisamente, questo lavoro si focalizza sulle Reti Neurali Convoluzionali
 (CNNs) e presenta sia una metodologia che una libreria per convertire una
 rete neurale già addestrata in una rete in grado di preservare la privacy,
 utilizzando lo schema omomorfico di Brakerski, Fan and Vercauteren (BFV).
 Inoltre, questo lavoro propone una formulazione matematica relativa al
 problema di trovare i migliori parametri di crittografia per lo schema
 omomorfico BFV, nonché un'euristica, basata sull'algoritmo di ricerca binaria,
 per risolvere il problema della scelta dei parametri considerando una specifica
 privacy-preserving CNN.
 L'euristica proposta mira quindi a trovare la miglior trasformazione per
 la data rete convoluzionale.
 I risultati sperimentali mostrano che la metodologia proposta è in grado
 di funzionare su CNNs caratterizzate da differenti architetture e pipelines
 di elaborazione.
 I risultati provano anche che è possibile preservare la privacy dei dati
 analizzati con algoritmi di deep learning, pagando un piccolo prezzo in
 termini di perdita di accuratezza e tempi di predizione più lenti.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList table

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList algorithm

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature
set_width "auto"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
mainmatter
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Section
Problem and Motivations
\begin_inset CommandInset label
LatexCommand label
name "sec:Problem-and-Motivations"

\end_inset


\end_layout

\begin_layout Standard
The early birth of Machine Learning
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
It is a field of artificial intelligence that uses statistical techniques
 to give computer systems the ability to "learn" (e.g., progressively improve
 performance on a specific task) from data, without being explicitly programmed.
\end_layout

\end_inset

 and artificial neural networks
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
It is a type of learning algorithm that is vaguely inspired by biological
 neural networks.
\end_layout

\end_inset

 can be positioned in 1943, when a neurophysiologist and a mathematician
 co-wrote a paper to illustrate how to model a neural network with electrical
 circuits.
 This work opened the way to the possibility of describing computers as
 systems that are able to learn form their own experience and solve complex
 problems in different situations, abilities that were previously thought
 to be unique to mankind.
 Since there, machine learning techniques have become more and more popular
 moving out of research environments and coming into everybody lives with
 applications across industries, also thanks to the availability of huge
 amounts of data, coupled with an increase in processing power and access
 to cheaper and greater storage capacity.
 A popular machine-learning application paradigm considers 
\emph on
Software as a Service
\emph default
 (SaaS), that is a software distribution model in which a third-party provider,
 usually a cloud server, hosts applications (i.e., machine learning algorithms)
 and makes them available to different costumers over the Internet.
 This cloud based machine learning technique is useful since it is usually
 fast, scalable and easy-to-use, thus allows to reach a big number of users.
 This model enables to collect and analyze many data that are not property
 of the cloud server, but of some data providers, and to use them for prediction
s, image and speech recognition and others useful tasks.
 However, in most of cases these data are sensible data and this places
 issues in terms of privacy implications, since the server is an untrusted
 party considered as an "honest but curious sever", that handles computations
 correctly but tries to capture informations from analyzed data.
 This problem has become even more relevant after the approval of the European's
\series bold
 General Data Protection Regulation (GDPR).
 
\series default
The answer to the question as to whether it is possible to use machine learning
 techniques and protect people’s data while doing so, is yes.
 It is both possible and necessary in order to safeguard fundamental personal
 data protection rights.
 The field of cryptography and in particular of Homomorphic Encryption (HE)
 offers promising possibilities.
 By employing a Homomorphic Encryption scheme, a data owner can encrypt
 its data, with its public key, before to send them to a cloud service that
 hosts the algorithm to compute.
 The encryption ensures that the data remain confidential since the cloud
 has not access to the secret key needed to decrypt the data, but at the
 same time, it is able to perform the computations required on the encrypted
 data, make predictions, and return them to the data owner in an encrypted
 form.
 Thus, only the data owner in the end will be able to decrypt the prediction
 and obtain its results.
 Therefore the cloud service does not gain any information about the raw
 data nor about the prediction it made.
\end_layout

\begin_layout Subsection
The EU-GDPR
\end_layout

\begin_layout Standard
The necessity to take into account privacy when dealing with machine learning
 has been strengthen by the entry into force on 24 May 2016 of the 
\series bold
EU's General Data Protection Regulation (GDPR)
\series default

\begin_inset CommandInset citation
LatexCommand cite
key "GDPR"

\end_inset

.
 The GDPR replaces the Data Protection Directive 95/46/EC and was designed
 to harmonize data privacy laws across Europe, to protect and empower all
 EU citizens data privacy and to reshape the way organizations across the
 region approach data privacy.
 The GDPR has a broad territorial scope.
 It applies not only to all organizations established in the EU that handles
 personal data but also to any non-EU established organization that processes
 personal data of individuals who are in the EU in order to offer them goods
 or services.
 The GDPR aims to protect personal data at all stages of data processing
 and it identifies two different entities that both have obligations: data
 controllers and data processors.
 The provisions of the GDPR govern the data controller’s duties and the
 rights of the data subject when personal information is processed.
 The GDPR therefore applies when artificial intelligence 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Colloquially, the term "artificial intelligence" is applied when a machine
 mimics "cognitive" functions that humans associate with other human minds,
 such as "learning" and "problem solving".
\end_layout

\end_inset

 (AI) 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "AI"
description "Artificial Intelligence"

\end_inset

 is 
\emph on
under development
\emph default
 with the help of personal data, and also when it is used to 
\emph on
analyze
\emph default
 or 
\emph on
reach
\emph default
 
\emph on
decisions
\emph default
 about individuals, as for example in Convolutional Neural Networks (CNNs)
 that analyze sensible images.
\begin_inset Newline newline
\end_inset

It is important to clarify what one means when he speaks about 
\emph on
personal data
\emph default
.
 Personal data means any information relating to an identified or identifiable
 natural person (GDPR Article 4 (1)).
 The data may be directly linked to a person, such as a name, identification
 number or location data.
 The data may also be indirectly linked to a person.
 
\emph on
Sensitive data
\emph default
 is a special sub-category of personal data which holds extra consideration
 and protection in GDPR as they may give rise to strong stigmatization or
 discrimination in society; they include information about racial or ethnic
 origin, political convictions, religious or philosophical beliefs, as well
 as the processing of genetic and biometric data with the aim of uniquely
 identifying a natural person, health details or information regarding a
 person’s sexual relationships or sexual orientation (GDPR Article 4).
 Secondly the 
\emph on
data controller
\emph default
 is the natural or legal person, public authority, agency or other body
 which determines the purposes and means of processing of personal data
 (GDPR Article 4 (7)), where 
\emph on
processing
\emph default
 means any operation or set of operations which is performed on personal
 data, such as collection, recording, organization, structuring, storage,
 alteration, retrieval, consultation or use (GDPR Article 4 (2)).
\begin_inset Newline newline
\end_inset

Article 5 of the GDPR lists the principles that apply to all personal data
 processing.
 The most important one is the 
\noun on
principle of integrity and confidentiality
\noun default
 and requires that personal data is: 
\emph on
processed in a way that ensures adequate personal data protection
\emph default
.
\begin_inset Newline newline
\end_inset

A new requirement that is especially relevant for organizations using AI,
 is the 
\emph on
privacy by design
\emph default
 requirement
\emph on
.

\emph default
 To enable privacy by design, the data controller shall build privacy protection
 into the system and ensure that data protection is safeguarded in the system’s
 standard settings.
 This requirement is described in Article 25 of the GDPR and apply when
 developing software, ordering new systems, solutions and services, as well
 as when developing these further.
 The rules require that data protection is given due consideration in all
 stages of system development, in routines and in daily use.
 Standard settings shall be as protective of privacy as possible, and data
 protection features shall be embedded at the design stage.
 The principle of data minimization is expressly mentioned in the provision
 relating to privacy by design.
 
\emph on
Data minimization
\emph default
 is a principle aiming to limit the amount of detail included in training
 or in the use of a model.
 This may be achieved by making it difficult to identify the individuals
 contained in the basic data.
 The use of pseudonymization or encryption techniques protect the data subject’s
 identity and help limit the extent of intervention 
\begin_inset CommandInset citation
LatexCommand cite
key "AIPrivacy"

\end_inset

.
\end_layout

\begin_layout Section
Goals and Results 
\begin_inset CommandInset label
LatexCommand label
name "sec:Goals"

\end_inset


\end_layout

\begin_layout Standard
This study aims to provide a methodological solution about how to design
 a privacy-preserving machine learning system through the usage of the Homomorph
ic Encryption.
 More precisely, this work focuses on one of the most used and versatile
 machine learning algorithms for image analysis, the Convolutional Neural
 Networks (CNNs) and presents both a methodology and a library to convert
 a pre-trained CNN to a privacy-preserving CNN (encoded network), by employing
 a Homomorphic Encryption scheme.
 The HE scheme considered is the one proposed by Brakerski, Fan and Vercauteren
 (BFV) that is mathematically based on polynomial rings.
 Moreover, since the usage of HE introduces some limitations in the number
 and types of operation performed on the encrypted data, this study focuses
 in understanding which is the optimal neural network to encode in the homomorph
ic encryption world, given a specific task to solve and some computational
 constraints.
 This is done by proposing a mathematical formulation for this problem and
 by solving it through the provided heuristic algorithm.
 In a more structured manner, this document has the following goals:
\end_layout

\begin_layout Itemize
Provide a library to convert a plain CNN in a privacy-preserving CNN end
 able to execute calculi on encrypted data (i.e., images).
\end_layout

\begin_layout Itemize
Propose a methodology that allows to accomplish the previously mentioned
 transformation of the CNN.
\end_layout

\begin_layout Itemize
Implement a heuristic methodology that allows to estimate the optimal encryption
 parameters (useful for the BFV HE scheme), aiming at reducing the computational
 and memory complexities without sacrificing the classification performances.
 
\end_layout

\begin_layout Section
Thesis Structure
\begin_inset CommandInset label
LatexCommand label
name "sec:Thesis-Structure"

\end_inset


\end_layout

\begin_layout Standard
Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Background"

\end_inset

 introduces the reader to context of the research, giving an overview on
 the Homomorphic Encryption, its limitations and advantages, with a strong
 focus on the BFV HE scheme.
 Moreover Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Background"

\end_inset

 gives an overview on the Convolutional Neural Networks and the approximations
 needed to allow their functioning in the HE world.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:State-of-the-Art"

\end_inset

 illustrates the current state of the art of privacy-preserving machine
 learning techniques, implementations and solution.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Methodology"

\end_inset

 provides a methodology to accomplish the CNN mutation along with its mathematic
al formulation and gives the explanation of the heuristic used to solve
 the problem posed by the mathematical formulation.
 In Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Practical-Methodology"

\end_inset

 the methodology is revisioned taking into account also its practical implicatio
ns.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:CrCNN:A-CNN-Library"

\end_inset

 presents the structure and implementation details of the developed Crypto
 CNN (CrCNN) library used to practically make a network able to predict
 on encrypted data.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Experimental-Results"

\end_inset

 shows the experimental results made to compare the proposed methodology
 with other techniques, to study the performances of the proposed library
 and heuristic.
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Conclusions-and-Future"

\end_inset

 reports the conclusions and the possible future works.
\end_layout

\begin_layout Chapter
Background
\begin_inset CommandInset label
LatexCommand label
name "chap:Background"

\end_inset


\end_layout

\begin_layout Standard
In this Chapter the reader will be introduced to the basics of homomorphic
 encryption and its limitations in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Homomorphic-Encryption"

\end_inset

.
 In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BFV"

\end_inset

 the Brakerski/Fan-Vercauteren homomorphic encryption scheme will be presented
 more in detail with its security assumptions (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:RLWE-Problem"

\end_inset

), key generations and encryption/decryption operations (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

), the possible arithmetic operations (Subsections 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-and-Noise"

\end_inset

 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-with-plaintext"

\end_inset

) and the plaintext encoding (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

).
 A brief overview on Convolutional Neural Networks will be given in Section
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Convolutional-Neural-Networks"

\end_inset

, along with the approximations required by the application of HE on them
 (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximations-For-HE"

\end_inset

) and the mention of some CNNs examples in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Convolutional-Neural-Networks in Lit"

\end_inset

.
\end_layout

\begin_layout Section
Homomorphic Encryption
\begin_inset CommandInset label
LatexCommand label
name "subsec:Homomorphic-Encryption"

\end_inset


\end_layout

\begin_layout Standard
Traditional encryption schemes, both symmetric and asymmetric, were not
 designed to respect any algebraic structure of the plaintext and ciphertext
 spaces, i.e., no computations can be performed on the ciphertext in a way
 that would pass through the encryption to the underlying plaintext without
 using the secret key, and such a property would in many contexts be considered
 a vulnerability.
 An encryption scheme that allows computations to be done directly on the
 encrypted data is said to be a 
\emph on
homomorphic encryption scheme
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
 In mathematics, a homomorphism is a 
\emph on
structure-preserving
\emph default
 transformation.
 For example, consider the map 
\begin_inset Formula $\varPhi:\mathbb{Z}\longrightarrow\mathbb{Z}_{7}$
\end_inset

 such that 
\begin_inset Formula $\varPhi(z):=z\;(mod\;7)$
\end_inset

 .
 This map 
\begin_inset Formula $\varPhi$
\end_inset

 preserves both the additive and the multiplicative structure of the integers
 in the sense that for every 
\begin_inset Formula $z_{1},z_{2}\in\mathbb{Z}$
\end_inset

 we have that 
\begin_inset Formula $\varPhi(z_{1}+z_{2})=\varPhi(z_{1})\oplus\varPhi(z_{2})$
\end_inset

 and 
\begin_inset Formula $\varPhi(z_{1}\cdot z_{2})=\varPhi(z_{1})\otimes\varPhi(z_{2})$
\end_inset

 where 
\begin_inset Formula $\oplus$
\end_inset

 and 
\begin_inset Formula $\otimes$
\end_inset

 are the addition and multiplication operations in 
\begin_inset Formula $\mathbb{Z}_{7}$
\end_inset

.
 The map 
\begin_inset Formula $\varPhi$
\end_inset

 is a ring homomorphism (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ring-Definition"

\end_inset

) between the rings 
\begin_inset Formula $\mathbb{Z}$
\end_inset

 and 
\begin_inset Formula $\mathbb{\mathbb{Z}}_{7}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy"

\end_inset

.
 Finding a general method for computing on encrypted data had been a goal
 in cryptography since it was proposed in 1978 by Rivest, Adleman and Dertouzos
 
\begin_inset CommandInset citation
LatexCommand cite
key "Rivest1978"

\end_inset

.
 Since there the interest in this topic is grown due to its numerous application
s.
\end_layout

\begin_layout Subsection
Classification of Homomorphic Encryption Schemes
\begin_inset CommandInset label
LatexCommand label
name "subsec:Classification-of-Homomorphic"

\end_inset


\end_layout

\begin_layout Standard
It is worth to analyze different classes of homomorphic schemes to clarify
 the potentiality of this type of encryption as described in 
\begin_inset CommandInset citation
LatexCommand cite
key "journals/iacr/ArmknechtBCGJRS15"

\end_inset

.
\begin_inset Newline newline
\end_inset

Given that a circuit 
\emph on
C 
\emph default
is a series of computations made on some inputs, it is possible to state
 some preliminary definitions:
\end_layout

\begin_layout Definition
(
\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

-Evaluation Scheme).
 Let 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

 
\emph default
be a set of circuits.
 A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

-
\emph default
evaluation scheme for 
\emph on
C 
\emph default
is a tuple of probabilistic polynomial-time algorithms 
\begin_inset Formula $(\mathsf{Gen,Enc,Eval},$
\end_inset

 
\begin_inset Formula $\mathsf{Dec)}$
\end_inset

 such that:
\end_layout

\begin_layout Description
\begin_inset Formula $\mathsf{Gen}(1^{\lambda},\alpha)$
\end_inset

 is the key generation algorithm.
 It takes two inputs, security parameter 
\begin_inset Formula $\lambda$
\end_inset

 and auxiliary input 
\begin_inset Formula $\alpha$
\end_inset

, and outputs a key tuple 
\begin_inset Formula $(pk,sk,evk)$
\end_inset

, where 
\emph on
pk 
\emph default
is the public key used for encryption, 
\emph on
sk 
\emph default
is the secret key used for decryption and 
\emph on
evk 
\emph default
is the key used for the 
\begin_inset Formula $\mathsf{Eval}$
\end_inset

 algorithm.
\end_layout

\begin_layout Description
\begin_inset Formula $\mathsf{Enc}(pk,m)$
\end_inset

 is the encryption algorithm.
 As input takes the encryption key 
\emph on
pk 
\emph default
and a plaintext 
\emph on
m.
 
\emph default
It outputs a ciphertext 
\emph on
c
\emph default
.
\end_layout

\begin_layout Description
\begin_inset Formula $\mathsf{Eval}(evk,C,(c_{1},...,c_{n}))$
\end_inset

 is the evaluation algorithm.
 It takes as input the evaluation key 
\emph on
evk
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The evaluation key is used to perform the relinearization operation as explained
 in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset


\end_layout

\end_inset

, a circuit 
\emph on
C
\emph default
 
\emph on

\begin_inset Formula $\in\mathscr{\mathcal{C}}$
\end_inset

 
\emph default
and a tuple of inputs 
\begin_inset Formula $(c_{1},...,c_{n})$
\end_inset

 that can be a mix of ciphertexts and previous evaluation results.
 It produces an evaluation output.
\end_layout

\begin_layout Description
\begin_inset Formula $\mathsf{Dec}(sk,c)$
\end_inset

 is the decryption algorithm.
 It takes as input the decryption key 
\emph on
sk 
\emph default
and either a ciphertext or an evaluation output and produces a plaintext
 
\emph on
m.
\end_layout

\begin_layout Definition
(Correct Decryption).
 A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset


\emph default
-evaluation scheme 
\begin_inset Formula $(\mathsf{Gen,Enc,Eval},$
\end_inset

 
\begin_inset Formula $\mathsf{Dec)}$
\end_inset

 is said to 
\emph on
correctly decrypt 
\emph default
if for all 
\emph on
m 
\emph default
in the plaintext space,
\begin_inset Formula 
\[
\mathsf{Pr[Dec(\mathit{sk,}\mathsf{Enc}(\mathit{pk,m}))=m]=1}
\]

\end_inset

This means that it must be able to decrypt a ciphertext to the correct plaintext
 without error.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(Correct Evaluation 
\begin_inset CommandInset citation
LatexCommand cite
key "brakerski2014efficient"

\end_inset

) A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

 -
\emph default
 evaluation scheme 
\begin_inset Formula $(\mathsf{Gen,Enc,Eval},$
\end_inset

 
\begin_inset Formula $\mathsf{Dec)}$
\end_inset

 
\emph on
correctly evaluates 
\emph default
all circuits in 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

 
\emph default
if for all inputs 
\begin_inset Formula $c_{i},\text{ for each }i=1,...,n$
\end_inset

, for every 
\emph on
C
\emph default
 
\emph on

\begin_inset Formula $\in\mathscr{\mathcal{C}}$
\end_inset


\emph default
, 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\mathsf{Pr[Dec(\mathit{sk,\mathsf{Eval}(evk,C,c_{1},...,c_{n})})}=C(m_{1},\ldots,m_{n})]=1-\epsilon(\lambda)
\]

\end_inset

where 
\begin_inset Formula $m_{i}\gets\mathsf{Dec}(sk,c_{i})$
\end_inset

 and 
\begin_inset Formula $\epsilon$
\end_inset

 is a negligible function.
\begin_inset Newline newline
\end_inset

This means that with overwhelming probability, decryption of the homomorphic
 evaluation of a permitted circuit yields the correct result.
\begin_inset Newline newline
\end_inset

A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

-
\emph default
evaluation scheme is 
\emph on
correct 
\emph default
if it satisfies the properties of correct evaluation and correct decryption.
 It is also 
\emph on
compact 
\emph default
if the ciphertext size does not grow too much through homomorphic operations
 and the output length only depends on the security parameter 
\begin_inset Formula $\lambda$
\end_inset

.
\begin_inset Newline newline
\end_inset

The classification of schemes is based on which kind of circuits the scheme
 itself can evaluate.
 
\end_layout

\begin_layout Description
Somewhat
\begin_inset space ~
\end_inset

Homomorphic.
 A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset


\emph default
-evaluation scheme 
\begin_inset Formula $(\mathsf{Gen,Enc,Eval},$
\end_inset

 
\begin_inset Formula $\mathsf{Dec)}$
\end_inset

 with correctness property is called 
\emph on
somewhat homomorphic 
\emph default
encryption scheme (SHE).
 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "SHE"
description "Somewhat Homomorphic Encryption"

\end_inset


\begin_inset Newline newline
\end_inset

There are no guarantees for compactness and the set 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

 
\emph default
of permitted circuits does not contain all the circuits.
\end_layout

\begin_layout Description
Leveled
\begin_inset space ~
\end_inset

Homomorphic 
\begin_inset CommandInset citation
LatexCommand cite
key "brakerski2014efficient"

\end_inset

.
 A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset


\emph default
-evaluation scheme 
\begin_inset Formula $(\mathsf{Gen,Enc,Eval},$
\end_inset

 
\begin_inset Formula $\mathsf{Dec)}$
\end_inset

 is called a 
\emph on
leveled homomorphic scheme 
\emph default
if it takes an auxiliary input 
\begin_inset Formula $\alpha=d$
\end_inset

 to 
\begin_inset Formula $\mathsf{Gen}$
\end_inset

 which specifies the maximum depth of circuits that can be evaluated.
 Its properties are correctness and compactness.
 The latter implies that the 
\emph on
length of the evaluation output 
\emph default
(i.e., the result) does not depend on 
\emph on
d
\emph default
.
 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

The difference between SHE and leveled HE is that the depth of circuits
 which a SHE can handle can be increased through parameters choice - this
 usually means that the ciphertext size increases with the depth of the
 circuit allowed, while for a leveled HE the maximum depth is an input parameter
 and the length of the ciphertext does not depend on it.
 
\end_layout

\begin_layout Description
Fully
\begin_inset space ~
\end_inset

Homomorphic
\begin_inset space ~
\end_inset

Encryption 
\begin_inset CommandInset citation
LatexCommand cite
key "brakerski2014efficient"

\end_inset

.
 A 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset


\emph default
-evaluation scheme 
\begin_inset Formula $(\mathsf{Gen,Enc,}$
\end_inset

 
\begin_inset Formula $\mathsf{Eval,Dec)}$
\end_inset

 that is compact, correct, and where 
\emph on

\begin_inset Formula $\mathscr{\mathcal{C}}$
\end_inset

 
\emph default
is the set of all circuits is called 
\emph on
fully homomorphic 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "FHE"
description "Fully Homomorphic Encryption"

\end_inset

 
\emph default
encryption scheme.
\begin_inset Newline newline
\end_inset

This definition means that the scheme can evaluate any circuit of arbitrary
 size, which does not need to be known when setting the parameters.
\begin_inset Newline newline
\end_inset

However, it is fair to say that FHE mostly exists on papers.
\end_layout

\begin_layout Subsection
Brief History of Homomorphic Encryption Schemes 
\begin_inset CommandInset label
LatexCommand label
name "subsec:History-of-HE"

\end_inset


\end_layout

\begin_layout Standard
RSA is the first feasible achievement of public key cryptosystem and has
 been introduced by Rivest, Shamir and Adleman in 1978 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/cacm/RivestSA78"

\end_inset

, soon after the invention of public key cryptography by Diffie and Hellman
 in 1976 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/tit/DiffieH76"

\end_inset

.
 However, the homomorphic property of RSA was shown by Rivest, Adleman and
 Dertouzous 
\begin_inset CommandInset citation
LatexCommand cite
key "Rivest1978"

\end_inset

, just after the seminal work of RSA.
 Indeed, the first attested use of the term "privacy homomorphism" is introduced
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Rivest1978"

\end_inset

.
 The security of the RSA cryptosystem is based on the hardness of 
\emph on
factoring the product of two large prime numbers
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Montgomery94asurvey"

\end_inset

.
 Moreover plain RSA is not secure against 
\emph on
Chosen Plaintext Attacks 
\emph default
(CPA) 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "CPA"
description "Chosen Plaintext Attacks "

\end_inset

which presumes that the attacker can obtain the ciphertexts for arbitrary
 plaintext 
\begin_inset CommandInset citation
LatexCommand cite
key "Biryukov2011"

\end_inset

,  as its encryption algorithm is deterministic.
 RSA is only homomorphic over multiplication and this operation can be performed
 an unlimited number of times.
 Hence, it does not allow the homomorphic addition of ciphertexts.
 In 1982 Goldwasser and Micali (GM) 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/stoc/GoldwasserM82"

\end_inset

 proposed the first probabilistic public key encryption scheme, based on
 the hardness of 
\emph on
quadratic residuosity problem
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:reference/crypt/Kaliski05xd"

\end_inset

.

\emph on
 
\emph default
The GM scheme is homomorphic over only addition of binary numbers, however
 the probabilistic property of this scheme ensures 
\emph on
semantic security, 
\emph default
that is equivalent to 
\emph on
ciphertext indistinguishability 
\emph default
under CPA 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/jcss/GoldwasserM84"

\end_inset

.
 Intuitively, if a cryptosystem possesses the property of indistinguishability,
 then an adversary will be unable to distinguish pairs of ciphertexts based
 on the message they encrypt.
 In 1985, Taher El-Gamal proposed a new public key encryption scheme 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/tit/Elgamal85"

\end_inset

 which is the improved version of the original Diffie-Hellman Key Exchange
 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/tit/DiffieH76"

\end_inset

 algorithm and is based on the hardness of certain problems in
\emph on
 discrete logarithm 
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "mccurleydiscrete"

\end_inset

.
 It is mostly used in hybrid encryption systems to encrypt the secret key
 of a symmetric encryption system.
 As RSA, El-Gamal cryptosystem is only multiplicatively homomorphic.
 In 1999 Paillier 
\begin_inset CommandInset citation
LatexCommand cite
key "Paillier"

\end_inset

 introduced another novel probabilistic encryption scheme based on c
\emph on
omposite residuosity
\emph default
 problem 
\begin_inset CommandInset citation
LatexCommand cite
key "jager2012generic"

\end_inset

.
 Paillier’s encryption scheme is homomorphic over addition, but it allows
 also other extra basic operations.
\begin_inset Newline newline
\end_inset

Before 2005, all proposed cryptosystems' homomorphic properties where restricted
 to only either addition or multiplication operation.
 An important step toward an FHE scheme was the BGN 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "BGN"
description "Boneh-Goh-Nissim"

\end_inset

SHE scheme proposed by Boneh-Goh-Nissim in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/tcc/BonehGN05"

\end_inset

.
 BGN supports an arbitrary number of addition and one multiplication and
 it is able to keep constant the ciphertext size.
 The hardness of the scheme is based on the 
\emph on
subgroup decision problem
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "gjosteen2004subgroup"

\end_inset

.
 After almost 30 years from the introduction of privacy homomorphism concept
 
\begin_inset CommandInset citation
LatexCommand cite
key "Rivest1978"

\end_inset

, in his PhD thesis Craig Gentry presented the first FHE scheme that respects
 both addition and multiplication and proposed a general framework to obtain
 a FHE scheme 
\begin_inset CommandInset citation
LatexCommand cite
key "Gentry:2009:FHE:1536414.1536440"

\end_inset

.
 Although Gentry's scheme was very promising it also had a lot of bottlenecks
 such as its computational cost in terms of applicability in real life and
 some of its advanced mathematical concepts made the scheme complex and
 hard to implement.
 What makes Gentry's scheme FHE are the techniques called 
\emph on
squashing
\emph default
 and 
\emph on
bootstrapping
\emph default
 that allow to evaluate unlimited number of operations.
 Basically squashing is a preliminary operation for the bootstrapping and
 aims at reducing the decryption algorithm complexity, while the bootstrapping
 is a "re-encrypting" procedure (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-and-Noise"

\end_inset

).
 Since 2009 new and more efficient schemes have been proposed such as 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/pkc/SmartV10"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/eurocrypt/DijkGHV10"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/crypto/BrakerskiV11"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Lopez-Alt:2012:OMC:2213977.2214086"

\end_inset

 in order to address the aforementioned bottlenecks, but despite the promising
 theoretical power of homomorphic encryption, the practical side has remained
 underdeveloped for a long time.
 
\end_layout

\begin_layout Subsection
Limitations of Homomorphic Encryption 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Limitations-of-Homomorphic"

\end_inset


\end_layout

\begin_layout Standard
Despite HE is a powerful instrument with many possible applications in real-worl
d scenarios, it has some limitations that must be taken into account.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Description
Support
\series bold

\begin_inset space ~
\end_inset

for
\begin_inset space ~
\end_inset

multiple
\begin_inset space ~
\end_inset

users
\series default
.
 Traditional FHE schemes are 
\emph on
single-key 
\emph default
in the sense that they can perform (arbitrarily complex) computations on
 inputs encrypted under the same key.
 Nevertheless, Gentry 
\begin_inset CommandInset citation
LatexCommand cite
key "homenc"

\end_inset

 proposed a way of using single key FHE scheme in order to do multiparty
 computation, by using a joint public key and a 
\emph on
shared-secret key 
\emph default
among all parties.
 However, it requires an 
\emph on
interactive 
\emph default
cooperations of all parties during computations.
 López-Alt et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Lopez-Alt:2012:OMC:2213977.2214086"

\end_inset

 have shown promising direction to address this problem by proposing an
 
\emph on
N-key fully homomorphic encryption scheme.

\emph default
 Despite these results, at the time of writing, 
\emph on
multi-key
\emph default
 FHEs are not very efficient and there are no practical implementations
 in any library.
\end_layout

\begin_layout Description
Large
\series bold

\begin_inset space ~
\end_inset

computational
\begin_inset space ~
\end_inset

overhead
\series default
 describes the ratio between the computation time in the encrypted version
 versus computation time in the clear.
 Although polynomial in size, this overhead tends to be a rather large polynomia
l, which increases runtimes substantially and makes homomorphic computation
 of complex functions impractical.
 One benchmark commonly used is the homomorphic evaluation of the AES 
\begin_inset CommandInset citation
LatexCommand cite
key "Daemen99aesproposal:"

\end_inset

 circuit, since it is nontrivial but also not completely infeasible.
 One study 
\begin_inset CommandInset citation
LatexCommand cite
key "HomomorphicEvalAESCircuit"

\end_inset

 based on the RLWE Brakerski-Gentry-Vaikuntanathan cryptosystem 
\begin_inset CommandInset citation
LatexCommand cite
key "Brakerski:2012:FHE:2090236.2090262"

\end_inset

 and on its library implementation HElib 
\begin_inset CommandInset citation
LatexCommand cite
key "HElibmanual"

\end_inset

, shows that it takes about 4 minutes and 3GB of RAM, running on a laptop
 Intel Core i5-3320M running at 2.6GHz, to evaluate an entire AES-128 encryption
 operation.
 With optimizations as ciphertext packing 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/dcc/SmartV14"

\end_inset

, called Single Instruction Multiple Data techniques, which allows several
 plaintexts to be encoded in a single ciphertext, it is possible to process
 up to 120 blocks in each such evaluation, yielding an amortized rate of
 just over 2 seconds per block.
 This implies that performances can be similar to the non-encrypted version
 of the AES circuit, but at the cost of increased memory consumption.
\end_layout

\begin_layout Description
Some
\series bold

\begin_inset space ~
\end_inset

inefficient
\begin_inset space ~
\end_inset

operations.

\series default
 For example there is no efficient way to implement the comparison operation,
 because it requires dealing with binary messages 
\begin_inset CommandInset citation
LatexCommand cite
key "migliore:hal-01394362"

\end_inset

.
 This latter representation brings an important issue: to perform an integer
 addition or multiplication with the binary representation, one must reconstruct
 the binary circuit of the operators.
\end_layout

\begin_layout Description
FHE
\series bold

\begin_inset space ~
\end_inset

does
\begin_inset space ~
\end_inset

not
\begin_inset space ~
\end_inset

necessarily
\begin_inset space ~
\end_inset

imply
\begin_inset space ~
\end_inset

secret
\begin_inset space ~
\end_inset

function
\begin_inset space ~
\end_inset

evaluation
\series default
.
 Indeed its goal is to allow the evaluation of arithmetic circuits on encrypted
 inputs, without revealing the input wire values to the evaluator.
 In particular, no attempt is made to keep any information hidden from the
 owner of the secret key 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
 For example, the homomorphic execution of the forward phase of a CNN on
 encrypted data does not guarantee the secrecy of the CNN model (i.e.
 anyone could see the structure of the network).
 However, it is possible to solve this problem and obtain 
\emph on
function privacy 
\emph default
in a number of ways.
 One way, already described by Gentry in 
\begin_inset CommandInset citation
LatexCommand cite
key "Gentry:2009:FHE:1536414.1536440"

\end_inset

, is to flood additional noise in the ciphertext.
 An other way is to use the GSW cryptosystem 
\begin_inset CommandInset citation
LatexCommand cite
key "crypto-2013-24633"

\end_inset

 as described in 
\begin_inset CommandInset citation
LatexCommand cite
key "journals/iacr/BoursePMW16"

\end_inset

.
\end_layout

\begin_layout Description

\series bold
Malleability
\series default
.
 It is a property of some cryptographic algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "Dolev00non-malleablecryptography"

\end_inset

.
 It is the ability to transform a ciphertext into a different ciphertext
 which will produce a new and different plaintext when decoded.
 That is, given an encryption of a plaintext 
\emph on
m
\emph default
, it is possible to generate another ciphertext which decrypts to 
\emph on
f(m)
\emph default
, for a known function 
\emph on
f
\emph default
, without necessarily knowing or learning 
\emph on
m
\emph default
.
 For example, suppose that a user sends an encrypted message to a bank containin
g, say, "TRANSFER $0000100.00 TO ACCOUNT #199." If an attacker can modify
 the message on the wire, and can guess the format of the unencrypted message,
 the attacker could be able to change the amount of the transaction, or
 the recipient of the funds, e.g.
 "TRANSFER $0100000.00 TO ACCOUNT #227".
 However, homomorphic encryption systems are malleable by design, allowing
 authorized parties to alter enciphered text without knowing the contents
 of the message.
 That is, they can manipulate an encrypted stream (set a flag, add a value)
 without having the ability to decipher the stream, or without expending
 the effort to decrypt and re-encrypt the stream.
 Moreover if an encrypted message is sent to an external server for outsourced
 computation, it must be considered a trusted party.
 Indeed no one can guarantee that the server has performed the desired computati
on.
 Even the RSA (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:History-of-HE"

\end_inset

) is a malleable cryptosystem, however if it is used together with padding
 methods such as OAEP 
\begin_inset CommandInset citation
LatexCommand cite
key "Bellare1995OptimalAE"

\end_inset

 this issue can be solved.
 
\end_layout

\begin_layout Section
Brakerski/Fan-Vercauteren scheme (BFV)
\begin_inset CommandInset label
LatexCommand label
name "sec:BFV"

\end_inset


\end_layout

\begin_layout Standard
One of the practical implementations of Gentry scheme 
\begin_inset CommandInset citation
LatexCommand cite
key "Gentry:2009:FHE:1536414.1536440"

\end_inset

 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:History-of-HE"

\end_inset

) is the FHE conjectured by Brakerski, Fan and Vercauteren (BFV) 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "BFV"
description "Brakerski/Fan-Vercauteren"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

.
 In this Section this homomorphic scheme will be described in detail since
 it is the one used for the practical part of this thesis.
 
\end_layout

\begin_layout Subsection
Ring Definition 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Ring-Definition"

\end_inset


\end_layout

\begin_layout Standard
The BFV relies on the concept of ring, in particular on the commutative
 rings 
\begin_inset CommandInset citation
LatexCommand cite
key "Commutative-Algebra"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

A commutative ring R is a set on which there are two operations defined:
 addition and multiplication, such that 
\begin_inset Formula $0∈R$
\end_inset

 is the identity element of addition and 
\begin_inset Formula $1∈R$
\end_inset

 is the identity element of the multiplication operation.
 For every element 
\begin_inset Formula $a∈R$
\end_inset

 there exists an element 
\begin_inset Formula $−a∈R$
\end_inset

 such that 
\begin_inset Formula $a+(−a)=0$
\end_inset

.
 Furthermore, for every 
\begin_inset Formula $a,b,c∈R$
\end_inset

: 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{align}
\end_layout

\begin_layout Plain Layout

a(bc)&=(ab)c;&&
\backslash
text{(associativity of product)}
\backslash
notag 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

a(b+c)&=ab+ac;&&
\backslash
text{(left associativity of product w.r.t addition)}
\backslash
notag
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

(a+b)c&=ac+bc;&&
\backslash
text{(right associativity of product w.r.t.
 addition)}
\backslash
notag
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

a+(b+c)&=(a+b)+c;&&
\backslash
text{(associativity of addition)}
\backslash
notag
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

a+b&=b+a;&&
\backslash
text{(commutative addition)}
\backslash
notag
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

ab&=ba.&&
\backslash
text{(commutative product)} 
\backslash
notag 
\end_layout

\begin_layout Plain Layout


\backslash
end{align}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

The set of integers 
\begin_inset Formula $\mathbb{Z}$
\end_inset

 is a ring as as well as the set 
\begin_inset Formula $\mathbb{Z}_{m}$
\end_inset

 of integers modulo 
\emph on
m.
 
\emph default
If 
\begin_inset Formula $R$
\end_inset

 is a given commutative ring, then the set of all polynomials in the variable
 
\begin_inset Formula $x$
\end_inset

 whose coefficients are in 
\begin_inset Formula $R$
\end_inset

 forms the polynomial ring, denoted 
\begin_inset Formula $R[x]$
\end_inset

.
 In this work the focus will be on the ring 
\begin_inset Formula $\mathbb{Z}_{m}[x]$
\end_inset

 of polynomials with integer coefficients modulo 
\begin_inset Formula $m$
\end_inset

 and in particular on the polynomial ring 
\begin_inset Formula $\mathbb{Z}_{m}[x]/(x^{n}+1)$
\end_inset

, that is polynomials of degree less than 
\begin_inset Formula $n$
\end_inset

 with coefficients modulo 
\begin_inset Formula $m$
\end_inset

.
\end_layout

\begin_layout Subsection
Basic Notation
\end_layout

\begin_layout Standard
In this Subsection all the mathematical entities that are employed throughout
 this document are exposed.
 
\end_layout

\begin_layout Itemize
\begin_inset Formula $R=\mathbb{Z}[x]/(f(x))$
\end_inset

 is the polynomial ring where 
\begin_inset Formula $f(x)\text{∈}\mathbb{Z}[x]$
\end_inset

 is a monic irreducible polynomial of degree 
\begin_inset Formula $n$
\end_inset

.
 In practice a cyclotomic polynomial
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The minimal polynomial of any 
\begin_inset Formula $n^{th}$
\end_inset

 root of unity over the rationals is a cyclotomic polynomial.
\end_layout

\end_inset

 
\begin_inset Formula $\text{Φ}_{n}(x)$
\end_inset

 of degree 
\emph on
n
\emph default
 is used.
 The most popular choice for expository purposes is to take 
\begin_inset Formula $f(x)=x^{n}+1$
\end_inset

 with 
\begin_inset Formula $n=2^{d}$
\end_inset

.
\end_layout

\begin_layout Itemize
Elements of the ring 
\begin_inset Formula $R$
\end_inset

 will be denoted in lowercase bold, e.g.
 
\begin_inset Formula ${\normalcolor \mathbf{a}}\text{∈}R$
\end_inset

.
 The coefficients of an element 
\begin_inset Formula ${\normalcolor \mathbf{a}}\text{∈}R$
\end_inset

 will be denoted by 
\begin_inset Formula $a_{i}$
\end_inset

, i.e.
 
\begin_inset Formula $\mathbf{a}=\sum_{i=0}^{n-1}a_{i}\cdot x^{i}.$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\parallel\mathbf{a}\parallel_{\infty}=max_{i}\mid a_{i}\mid$
\end_inset

 is the infinity norm.
\end_layout

\begin_layout Itemize
Let 
\begin_inset Formula $q>1$
\end_inset

 be an integer, then 
\begin_inset Formula $\mathbb{Z}_{q}$
\end_inset

 denotes the 
\emph on
set
\emph default
 of integers 
\begin_inset Formula $(\text{−}q/2,q/2].$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $R_{q}$
\end_inset

 is the set of polynomials in 
\begin_inset Formula $R$
\end_inset

 with coefficients in 
\begin_inset Formula $\mathbb{Z}_{q}$
\end_inset

.
\end_layout

\begin_layout Itemize
For each 
\begin_inset Formula $a\text{∈}\mathbb{Z}$
\end_inset

, is denoted by 
\begin_inset Formula $\left[a\right]_{q}$
\end_inset

 the unique integer in 
\begin_inset Formula $\mathbb{Z}_{q}$
\end_inset

 such that 
\begin_inset Formula $\left[a\right]_{q}=a$
\end_inset

 mod 
\begin_inset Formula $q$
\end_inset

.
\end_layout

\begin_layout Itemize

\emph on
t 
\emph default
is an integer called plaintext modulo.
\end_layout

\begin_layout Itemize
The reduction to the interval 
\begin_inset Formula $[0,q)$
\end_inset

 will be denoted as 
\begin_inset Formula $r_{q}(a)$
\end_inset

 (reminder modulo q).
\end_layout

\begin_layout Itemize
Given a probability distribution 
\begin_inset Formula $\mathcal{D}$
\end_inset

, 
\begin_inset Formula $x\longleftarrow\mathcal{D}$
\end_inset

 denotes that 
\begin_inset Formula $x$
\end_inset

 is sampled from 
\begin_inset Formula $\mathcal{D}$
\end_inset

, while for a set S, 
\begin_inset Formula $x\longleftarrow$
\end_inset

 S denotes that 
\begin_inset Formula $x$
\end_inset

 is sampled uniformly from S.
\end_layout

\begin_layout Itemize
The discrete Gaussian distribution 
\begin_inset Formula $D_{\mathbb{Z},σ}$
\end_inset

 over the integers is the probability distribution that assigns a probability
 proportional to 
\begin_inset Newline newline
\end_inset


\begin_inset Formula $exp(\text{−}π|x|^{2}/σ^{2})$
\end_inset

 to each 
\begin_inset Formula $x\text{∈}\mathbb{Z}$
\end_inset

.
 It is used to define a distribution 
\begin_inset Formula $\chi$
\end_inset

 on 
\begin_inset Formula $R$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma$
\end_inset

 is the standard deviation of the discrete Gaussian distribution.
\end_layout

\begin_layout Itemize

\emph on
B 
\emph default
bound on the distribution 
\begin_inset Formula $\chi$
\end_inset

, that is, it is supported on 
\begin_inset Formula $[-B,B]$
\end_inset

.
\end_layout

\begin_layout Subsection
RLWE Problem 
\begin_inset CommandInset label
LatexCommand label
name "subsec:RLWE-Problem"

\end_inset


\end_layout

\begin_layout Standard
Most of HE schemes base their security on the hardness of the Ring-Learning
 With Errors problem.
 The RLWE 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "RLWE"
description "Ring Learnig With Error"

\end_inset

 problem is a ring based version of the LWE problem.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Regev:2005:LLE:1060590.1060603"

\end_inset

 Regev gave a quantum reduction of certain approximate 
\emph on
Shortest Vector Problem
\emph default
 (SVP) 
\begin_inset CommandInset citation
LatexCommand cite
key "Micciancio2011"

\end_inset

 to LWE, i.e.
 if one can solve LWE, then there is a quantum algorithm to solve certain
 approximate SVP.
 Informally, the SVP requires a player to provide the shortest nonzero vector
 in a lattice, given a basis of the lattice and it is known to be an NP-hard
 problem.
 In particular, the asymptotically fastest known algorithms for obtaining
 an approximation to SVP on ideal lattices to within polynomial factors
 require time 
\begin_inset Formula $2^{\text{Ω}(n)}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "eurocrypt-2010-24000"

\end_inset

.
 Thus, the only evidence supporting the conjecture that LWE is as hard as
 SVP is the fact that there are no known quantum algorithms for lattice
 problems that outperform classical algorithms, even though this is probably
 one of the most important open questions in the field of quantum computing.
\end_layout

\begin_layout Definition
(
\series bold
Decision-RLWE
\series default
) Let 
\emph on
n 
\emph default
be a power of 2.
 Let 
\begin_inset Formula $R=\mathbb{Z}[x]/(x^{n}+1)$
\end_inset

, and 
\begin_inset Formula $R_{q}=\mathbb{Z}_{q}[x]/(x^{n}+1)$
\end_inset

 for some integer 
\emph on
q
\emph default
.
 Let 
\emph on

\begin_inset Formula $\mathbf{s}$
\end_inset


\emph default
 be a random element in 
\begin_inset Formula $R_{q}$
\end_inset

 (i.e., 
\begin_inset Formula $\mathbf{s}∈R_{q}$
\end_inset

) and let 
\begin_inset Formula $χ$
\end_inset

 be the distribution on 
\begin_inset Formula $R_{q}$
\end_inset

 obtained by choosing each coefficient of the polynomial from a discrete
 Gaussian distribution over 
\begin_inset Formula $\mathbb{Z}$
\end_inset

.
 Denote by with 
\begin_inset Formula $A_{\mathbf{s},\chi}$
\end_inset

 the distribution obtained by choosing a uniformly random element 
\begin_inset Formula $\mathbf{a}\longleftarrow R_{q}$
\end_inset

 and a noise term 
\begin_inset Formula $\mathbf{e}\longleftarrow\chi$
\end_inset

 and outputting 
\begin_inset Formula $(\mathbf{a},[\mathbf{a}\text{·}\mathbf{s}+\mathbf{e}]_{q})$
\end_inset

.
 The decision-RLWE problem is to distinguish 
\begin_inset Formula $A_{\mathbf{s},\chi}$
\end_inset

 and the uniform distribution 
\begin_inset Formula $U(R_{q}^{2})$
\end_inset

.
\end_layout

\begin_layout Subsection
Encryption Scheme
\begin_inset CommandInset label
LatexCommand label
name "subsec:Encryption-Scheme"

\end_inset


\end_layout

\begin_layout Standard
From the decision problem reported in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:RLWE-Problem"

\end_inset

 it is possible to derive the following encryption scheme originally described
 in the extended version of 
\begin_inset CommandInset citation
LatexCommand cite
key "eurocrypt-2010-24000"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

The plaintext space is taken as 
\begin_inset Formula $R_{t}$
\end_inset

 for some integer 
\begin_inset Formula $t>1$
\end_inset

.
 Let 
\begin_inset Formula $∆=\left\lfloor q/t\right\rfloor $
\end_inset

 and denote with 
\begin_inset Formula $r_{t}(q)=q\;mod\;t$
\end_inset

, it follows that 
\begin_inset Formula 
\begin{equation}
q=∆·t+r_{t}(q),\label{eq:relQDelta}
\end{equation}

\end_inset

 with 
\emph on
q 
\emph default
and 
\emph on
t 
\emph default
that do not have to be prime nor coprime.
 The definition of the scheme mostly follows the one given in 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\mathsf{SecretKeyGen}(\lambda)$
\end_inset

 sample 
\begin_inset Formula $\mathbf{s}\getsχ$
\end_inset

 and output 
\begin_inset Formula $sk=\boldsymbol{s}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\mathsf{PublicKeyGen(sk)}$
\end_inset

 set 
\begin_inset Formula $\boldsymbol{s}=sk$
\end_inset

, sample 
\begin_inset Formula $\boldsymbol{a}\gets R_{q}$
\end_inset

, small error 
\begin_inset Formula $\boldsymbol{e}\getsχ$
\end_inset

 and output 
\begin_inset Formula 
\[
pk=(\boldsymbol{p}_{0},\boldsymbol{p}_{1})\coloneqq([\text{−}(\boldsymbol{a}\text{·}\boldsymbol{s}+\boldsymbol{e})]_{q},\boldsymbol{a})
\]

\end_inset


\begin_inset Formula $\mathsf{EvalateKeyGen(sk,T)}$
\end_inset

 for 
\begin_inset Formula $i=0,...,l=\lfloor log_{T}(q)\rfloor$
\end_inset

 and 
\emph on
T 
\emph default
is a base (independent of 
\emph on
t
\emph default
), sample 
\begin_inset Formula $\boldsymbol{a}_{i}\gets R_{q}$
\end_inset

, 
\begin_inset Formula $\boldsymbol{e}_{i}\gets\chi$
\end_inset

 and output 
\begin_inset Formula 
\[
rlk=\Bigg[\Big([-(\boldsymbol{a}_{i}\text{·}\boldsymbol{s}+\boldsymbol{e}_{i})+T^{i}\cdot\boldsymbol{s}^{2}]_{q},\boldsymbol{a}_{i}\Big):i\in[0..l]\Bigg]
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\emph on
evaluation keys 
\emph default
are used in the relinearization phase which goal is to decrease the size
 of the ciphertext back to (at least) 2 after it has been increased by multiplic
ations.
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\mathsf{Encrypt(pk,\boldsymbol{m})}$
\end_inset

 to encrypt a message 
\begin_inset Formula $\boldsymbol{m}\in R_{t}$
\end_inset

, sample 
\begin_inset Formula $\boldsymbol{u},\boldsymbol{e}_{1},\boldsymbol{e}_{2}\gets\chi$
\end_inset

 and output 
\begin_inset Formula 
\[
ct=(\boldsymbol{c}_{0},\boldsymbol{c}_{1})\coloneqq([\boldsymbol{p}_{0}\text{·}\boldsymbol{u}+\boldsymbol{e}_{1}+\text{∆·}\boldsymbol{m}]_{q},[\boldsymbol{p}_{1}\text{·}\boldsymbol{u}+\boldsymbol{e_{2}}]_{q})
\]

\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\mathsf{Decrypt(sk,ct)}$
\end_inset

 set 
\begin_inset Formula $\boldsymbol{s}=sk$
\end_inset

 and 
\begin_inset Formula $ct=(\boldsymbol{c}_{0},\boldsymbol{c}_{1})$
\end_inset

 and compute 
\begin_inset Formula 
\[
\Bigg[\Biggl\lfloor\frac{t\cdot[\boldsymbol{c}_{0}+\boldsymbol{c}_{1}\cdot\boldsymbol{s}]_{q}}{q}\Biggr\rceil\Biggr]_{t}
\]

\end_inset


\end_layout

\begin_layout Standard
The above scheme can be shown to be semantically secure assuming the hardness
 of RLWE 
\begin_inset CommandInset citation
LatexCommand cite
key "eurocrypt-2010-24000"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Noise
\begin_inset CommandInset label
LatexCommand label
name "subsec:Noise"

\end_inset


\end_layout

\begin_layout Standard
All existing schemes have the common trait that they add a small “noise”
 component during encryption.
 Computing homomorphically on ciphertexts will cause these noises to grow
 up to the point when they become so large that decryption fails.
 In particular the noise growth caused by homomorphic multiplication has
 been the major obstacle to designing efficient schemes 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

.
\end_layout

\begin_layout Definition
(Invariant Noise)
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 Let 
\begin_inset Formula $\mathsf{ct}=(c_{0},c_{1})$
\end_inset

 be a ciphertext encrypting the message 
\begin_inset Formula $m\in R_{t}$
\end_inset

.
 Its invariant noise 
\emph on
v 
\emph default
is the polynomial with the smallest infinity norm such that 
\begin_inset Formula 
\begin{equation}
\frac{t}{q}\mathsf{ct}(s)=\frac{t}{q}(c_{0}+c_{1}s)=m+v+at\label{eq:ct(s)}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset

for some polynomial 
\emph on
a 
\emph default
with integer coefficients
\emph on
.
\end_layout

\begin_layout Lemma

\emph on
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\emph default
The function 
\begin_inset Formula $\mathsf{Decrypt(sk,ct)}$
\end_inset

 as presented in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

 correctly decrypts the ciphertext 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 encrypting a message m, as long as the invariant noise v satisfies
\emph on
 
\begin_inset Formula $||v||<1/2$
\end_inset

.
\begin_inset Newline newline
\end_inset


\emph default
Proof
\emph on
.
 Let 
\begin_inset Formula $\mathsf{ct}=(c_{0},c_{1})$
\end_inset

.
 Using the formula for decryption, for some polynomial 
\emph default
A
\emph on
 with integer coefficients:
\begin_inset Formula 
\begin{align*}
\\
m^{\prime}= & \Bigg[\Biggl\lfloor\frac{t}{q}[c_{0}+c_{1}\cdot s]_{q}\Biggr\rceil\Biggr]_{t}\\
= & \Bigg[\Biggl\lfloor\frac{t}{q}(c+c_{1}\cdot s+Aq)\Biggr\rceil\Bigg]_{t}\\
= & \Bigg[\Biggl\lfloor\frac{t}{q}(c+c_{1}\cdot s)+At\Biggr\rceil\Bigg]_{t}\\
= & \Bigg[\Biggl\lfloor\frac{t}{q}(c+c_{1}\cdot s)\Biggr\rceil\Bigg]_{t}.
\end{align*}

\end_inset


\begin_inset Newline newline
\end_inset

Then by definition of invariant noise in Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ct(s)"

\end_inset

,
\begin_inset Formula 
\[
m^{\prime}=[\lfloor m+v+at\rceil]_{t}=m+\lfloor v\rceil.
\]

\end_inset


\begin_inset Newline newline
\end_inset

Hence decryption is successful as long as 
\emph default
v
\emph on
 is removed by the rounding, i.e.
 if 
\begin_inset Formula $||v||_{\infty}<1/2$
\end_inset

.
\end_layout

\begin_layout Definition
(Noise Budget 
\begin_inset CommandInset label
LatexCommand label
name "def:(Noise-Budget)"

\end_inset

)
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 Let 
\emph on
v 
\emph default
be the invariant noise of a ciphertext 
\emph on

\begin_inset Formula $\mathsf{ct}$
\end_inset

 
\emph default
encrypting a message 
\emph on

\begin_inset Formula $m\in R_{t}$
\end_inset

.
 
\emph default
Then the noise budget of 
\emph on

\begin_inset Formula $\mathsf{ct}$
\end_inset

 
\emph default
is 
\begin_inset Formula $-log_{2}(2||v||_{\infty})$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

In other words, the 
\emph on
(Invariant) Noise Budget (NB) 
\emph default
is the left noise in the ciphertext before decryption fails.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Lemma

\emph on
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 
\emph default
The function 
\begin_inset Formula $\mathsf{Decrypt(sk,ct)}$
\end_inset

 as presented in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

 correctly decrypts the ciphertext 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 encrypting a message m, as long as the noise budget of 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 is positive.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Even a freshly encrypted ciphertext has a non zero amount of noise as stated
 in the following Lemma 10.
\end_layout

\begin_layout Lemma
(Initial Noise)
\emph on

\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 
\emph default
Let 
\begin_inset Formula $\mathsf{ct}=(c_{0},c_{1})$
\end_inset

 be a fresh encryption of a message 
\begin_inset Formula $m\in R_{t}$
\end_inset

.
 The noise v in 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 satisfies 
\begin_inset Formula 
\[
||v||_{\infty}\leq\frac{r_{t}(q)}{q}||m||_{\infty}+\frac{tB}{q}(2n+1).
\]

\end_inset


\end_layout

\begin_layout Subsection
Operations and Noise Growth 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Operations-and-Noise"

\end_inset


\end_layout

\begin_layout Standard
Given the interpretation of the ciphertext 
\begin_inset Formula $ct(\boldsymbol{s})$
\end_inset

 as in Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ct(s)"

\end_inset

 it is possible to derive homomorphic addition 
\begin_inset Formula $\mathsf{ADD}$
\end_inset

 and multiplication 
\begin_inset Formula $\mathsf{MUL}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Addition 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\mathsf{ADD(ct_{1},ct_{2})\coloneqq([ct_{1}[0]+ct_{2}[0]]_{q},[ct_{1}[1]+ct_{2}[1]]_{q})}$
\end_inset


\emph on
 
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset


\emph on
.
\end_layout

\begin_layout Standard
It is possible to show that if 
\begin_inset Formula $\mathsf{ct_{1}\text{ and }ct_{2}}$
\end_inset

 have noise 
\begin_inset Formula $v_{1}\text{\text{ and }}v_{2}$
\end_inset

 respectively, then the noise 
\begin_inset Formula $v_{add}$
\end_inset

 in their sum is 
\begin_inset Formula $v_{add}=v_{1}+v_{2}$
\end_inset

 and satisfies 
\begin_inset Formula $||v_{add}||_{\infty}\leq||v_{1}||_{\infty}+||v_{2}||_{\infty}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Multiplication 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\align left
\begin_inset Formula $\mathsf{MUL(ct_{1,}ct_{2},rlk)}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

: compute 
\begin_inset Formula 
\begin{align*}
\boldsymbol{c}_{0} & =\Bigg[\Biggl\lfloor\frac{t\cdot(ct_{1}[0]\cdot ct_{2}[0])}{q}\Biggr\rceil\Biggr]_{q}\\
\boldsymbol{c}_{1} & =\Bigg[\Biggl\lfloor\frac{t\cdot(ct_{1}[0]\cdot ct_{2}[1]+ct_{1}[1]\cdot ct_{2}[0])}{q}\Biggr\rceil\Biggr]_{q}\\
\boldsymbol{c}_{2} & =\Bigg[\Biggl\lfloor\frac{t\cdot(ct_{1}[1]\cdot ct_{2}[1])}{q}\Biggr\rceil\Biggr]_{q}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The multiplication makes grow the ciphertext size, for this reason a relineariza
tion step is necessary in order to reduce it.
 As showed in 
\begin_inset Formula $\mathsf{RELIN}$
\end_inset

 operation.
 
\begin_inset Newline newline
\end_inset

It is possible to prove that: if 
\begin_inset Formula $\mathsf{ct_{1}}=(x_{0},\ldots,x_{j_{1}})$
\end_inset

 is a ciphertext of size 
\begin_inset Formula $j_{1}+1$
\end_inset

 encrypting 
\begin_inset Formula $m_{1}$
\end_inset

 with noise 
\begin_inset Formula $v_{1}$
\end_inset

, 
\begin_inset Formula $\mathsf{ct_{2}}=(y_{0},\ldots,y_{j_{2}})$
\end_inset

 is a ciphertext of size 
\begin_inset Formula $j_{2}+1$
\end_inset

 encrypting 
\begin_inset Formula $m_{2}$
\end_inset

 with noise 
\begin_inset Formula $v_{2}$
\end_inset

, 
\begin_inset Formula $N_{m_{1}}$
\end_inset

 and 
\begin_inset Formula $N_{m_{2}}$
\end_inset

 are the upper bounds on the number of non-zero terms in the polynomials
 
\begin_inset Formula $m_{1}$
\end_inset

 and 
\begin_inset Formula $m_{2}$
\end_inset

 respectively, then the noise 
\begin_inset Formula $v_{mult}$
\end_inset

 in the product 
\begin_inset Formula $\mathsf{ct_{mult}}$
\end_inset

 satisfies the following bound 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\begin_inset Formula 
\begin{align*}
||v_{mult}||_{\infty}\leq & \Bigg[(N_{m_{1}}+n)||m_{1}||_{\infty}+\frac{nt}{2}\cdot\frac{n^{j_{1}+1}-1}{n-1})\Bigg]||v_{2}||_{\infty}\\
+ & \Bigg[(N_{m_{2}}+n)||m_{2}||_{\infty}+\frac{nt}{2}\cdot\frac{n^{j_{2}+1}-1}{n-1})\Bigg]||v_{1}||_{\infty}\\
+ & 3n||v_{1}||_{\infty}||v_{2}||_{\infty}+\frac{t}{2q}\Bigl(\frac{n^{j_{1}+j_{2}+1}-1}{n-1}\Bigr).
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
Relinearization 
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathsf{RELIN(ct_{mult},rlk)}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

: write 
\begin_inset Formula $\boldsymbol{c}_{2}$
\end_inset

 in base 
\emph on
T, 
\emph default
i.e.
 write 
\begin_inset Formula $\boldsymbol{c}_{2}=\sum_{i=0}^{l}\boldsymbol{c}_{2}^{(i)}T^{i}\;\text{with }\boldsymbol{c}_{2}^{(i)}\in R_{T}$
\end_inset

 and set: 
\begin_inset Formula 
\begin{align*}
\boldsymbol{c}_{0}^{\prime} & =\Bigg[\boldsymbol{c}_{0}+\sum_{i=0}^{l}rlk[i][0]\cdot\boldsymbol{c}_{2}^{(i)}\Bigg]_{q}\\
\boldsymbol{c}_{1}^{\prime} & =\Bigg[\boldsymbol{c}_{1}+\sum_{i=0}^{l}rlk[i][1]\cdot\boldsymbol{c}_{2}^{(i)}\Bigg]_{q}
\end{align*}

\end_inset

 output 
\begin_inset Formula $\mathsf{ct_{relin}=}(\boldsymbol{c}_{0}^{\prime},\boldsymbol{c}_{1}^{\prime})$
\end_inset

.
\begin_inset Newline newline
\end_inset

It is possible to show that if 
\begin_inset Formula $\mathsf{ct_{mult}}$
\end_inset

 is a ciphertext of size 
\emph on
M+1
\emph default
 encrypting 
\emph on
m
\emph default
, and having noise 
\emph on
v
\emph default
, and 
\begin_inset Formula $\mathsf{ct_{relin}}$
\end_inset

 of size 
\emph on
N+1 
\emph default
is the ciphertext encrypting 
\emph on
m
\emph default
, obtained by the relinearization of 
\begin_inset Formula $\mathsf{ct_{mult}}$
\end_inset

 where 
\begin_inset Formula $2\leq N+1\leq M+1$
\end_inset

, then the noise 
\begin_inset Formula $v_{relin}$
\end_inset

 in 
\begin_inset Formula $\mathsf{ct_{relin}}$
\end_inset

 can be bounded as
\begin_inset Newline newline
\end_inset


\begin_inset Formula $||v_{relin}||_{\infty}\leq||v||_{\infty}+\frac{t}{q}(M-N)nB(l+1)T$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Bootstrapping
\end_layout

\begin_layout Standard
It is a procedure that allows to turn a SHE into a FHE, since bootstrapping
 allows to lower the noise before to hit the maximum noise level.
 Gentry's idea of bootstrapping 
\begin_inset CommandInset citation
LatexCommand cite
key "Gentry:2009:FHE:1536414.1536440"

\end_inset

 consists in running the decryption 
\begin_inset Formula $\mathsf{SH.Decrypt}$
\end_inset

 in the encrypted domain, i.e.
 homomorphically.
 The result of this operation produces the encryption of the same message,
 but with noise of a fixed size.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand cite
key "journals/iacr/ArmknechtBCGJRS15"

\end_inset

(Bootstrappable).
 A C-evaluation scheme is called 
\emph on
boostrappable 
\emph default
if it is able to homomorphically evaluate its own decryption circuit plus
 one additional multiplication.
 
\begin_inset Newpage newpage
\end_inset

The bootstrapping works as follows 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/AcarAUC17"

\end_inset

: first, it is assumed that two different public and secret key pairs are
 generated, 
\begin_inset Formula $(pk1,sk1)$
\end_inset

 and 
\begin_inset Formula $(pk2,sk2)$
\end_inset

.
 The message 
\emph on
m 
\emph default
is encrypted 
\begin_inset Formula $c=\mathsf{Encrypt}(pk1,m)$
\end_inset

 and the secret key is encrypted too 
\begin_inset Formula $\mathsf{Encrypt}(pk1,sk1)$
\end_inset

.
 Since the obtained SHE scheme (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

) can evaluate its own decryption algorithm homomorphically, the noisy ciphertex
t is decrypted homomorphically using 
\begin_inset Formula $\mathsf{Encrypt}(pk1,sk1)$
\end_inset

.
 Then, the result is encrypted using a different public key 
\begin_inset Formula $pk2$
\end_inset

, 
\begin_inset Newline newline
\end_inset

i.e.
 
\begin_inset Formula $\mathsf{Encrypt}(pk2,\mathsf{Decrypt}(\mathsf{Encrypt}(pk1,sk1),c))$
\end_inset


\begin_inset Formula $=\mathsf{Encrypt}(pk2,m).$
\end_inset


\end_layout

\begin_layout Subsection
Operations with plaintext 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Operations-with-plaintext"

\end_inset


\end_layout

\begin_layout Standard
There are two other important operations:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathsf{AddPlain}(ct,m_{add})$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathsf{MultiplyPlain}($
\end_inset


\begin_inset Formula $ct,m_{mul})$
\end_inset


\end_layout

\begin_layout Standard
that can be seen as a particular case of the 
\begin_inset Formula $\mathsf{ADD(ct_{1},ct_{2})}$
\end_inset

 and 
\begin_inset Formula $\mathsf{MUL(}$
\end_inset


\begin_inset Formula $\mathsf{ct_{1,}ct_{2},rlk)}$
\end_inset

.
 They can hugely improve performance and significantly decrease the noise
 budget consumption when performing addition and multiplication operations.
 They are useful in the case the operands are a given ciphertext 
\emph on
ct 
\emph default
encrypting a plaintext polynomial 
\emph on
m
\emph default
 and an unencrypted plaintext polynomial 
\begin_inset Formula $m_{add}\text{ or }m_{mul}$
\end_inset

 that does not need to be protected.
 The following Lemma 12 and Lemma 13 show mathematically how it is possible
 to perform these operations and which are the advantages in terms of grow
 of noise that they can bring with respect to 
\begin_inset Formula $\mathsf{ADD\text{ and }\mathsf{MUL}}$
\end_inset

.
\begin_inset Newline newline
\end_inset

These operations leverage the 
\emph on
malleability 
\emph default
property that belongs by design to the homomorphic encryption schemes, as
 described in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Limitations-of-Homomorphic"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsubsection*
Plain Multiplication
\end_layout

\begin_layout Lemma

\emph on
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\emph default
(
\noun on
multiply plain
\noun default
) Let 
\begin_inset Formula $\mathsf{ct}=(x_{0},x_{1})$
\end_inset

 be a ciphertext encrypting 
\begin_inset Formula $m_{1}$
\end_inset

 with noise 
\begin_inset Formula $v$
\end_inset

, and let 
\begin_inset Formula $m_{2}$
\end_inset

 be a plaintext polynomial.
 Let 
\begin_inset Formula $N_{m_{2}}$
\end_inset

 be an upper bound on the number of non-zero terms in the polynomial 
\begin_inset Formula $m_{2}$
\end_inset

.
 Let 
\begin_inset Formula $\mathsf{ct_{pmult}}$
\end_inset

 denote the ciphertext obtained by plain multiplication of 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 with 
\begin_inset Formula $m_{2}$
\end_inset

.
 Then the noise in the plain product 
\begin_inset Formula $\mathsf{ct_{pmult}}$
\end_inset

 is 
\begin_inset Formula $v_{pmult}=m_{2}v$
\end_inset

, and can be bounded as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
||v_{pmult}||_{\infty}\leq N_{m_{2}}||m_{2}||_{\infty}\,||v||_{\infty}.
\]

\end_inset


\emph on
Proof
\emph default
.
 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 By definition
\emph on
 
\begin_inset Formula $ct_{pmult}=(m_{2}x_{0},m_{2}x_{1})$
\end_inset

.
 
\emph default
Hence for some polynomials 
\begin_inset Formula $a,a^{\prime}$
\end_inset

 with integer coefficients
\emph on
,
\begin_inset Formula 
\begin{align*}
\frac{t}{q}\mathsf{ct_{pmult}}(s) & =\frac{t}{q}(m_{2}x_{0}+m_{2}x_{1}s)\\
= & m_{2}\frac{t}{q}(x_{0}+x_{1}s)\\
= & m_{2}\frac{t}{q}ct(s)\\
= & m_{2}(m_{1}+v+at)\text{ (see Eq. \ref{eq:ct(s)}})\\
= & m_{1}m_{2}+m_{2}v+m_{2}at\\
= & [m_{1}m_{2}]_{t}+m_{2}v+(m_{2}a-a^{\prime})t,
\end{align*}

\end_inset


\emph default
where in the last line has been used 
\begin_inset Formula $[m_{1}m_{2}]_{t}=m_{1}m_{2}+a^{\prime}t$
\end_inset

.
 Hence the noise is 
\begin_inset Formula $v_{pmult}=m_{2}v$
\end_inset

 and can be bounded as 
\begin_inset Formula 
\[
||v_{pmult}||_{\infty}\leq N_{m_{2}}||m_{2}||_{\infty}\,||v||_{\infty}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsubsection*
Plain Addition
\end_layout

\begin_layout Lemma

\emph on
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\emph default
(
\noun on
add plain) 
\noun default
Let 
\begin_inset Formula $\mathsf{ct}=(x_{0},x_{1})$
\end_inset

 be a ciphertext encrypting 
\begin_inset Formula $m_{1}$
\end_inset

 with noise 
\begin_inset Formula $v$
\end_inset

, and let 
\begin_inset Formula $m_{2}$
\end_inset

 be a plaintext polynomial.
 Let 
\begin_inset Formula $\mathsf{ct_{padd}}$
\end_inset

 denote the ciphertext obtained by plain addition of 
\begin_inset Formula $\mathsf{ct}$
\end_inset

 with 
\begin_inset Formula $m_{2}$
\end_inset

.
 Then the noise in 
\begin_inset Formula $\mathsf{ct_{padd}}$
\end_inset

 is 
\begin_inset Formula $v_{padd}=v-\frac{r_{t}(q)}{q}m_{2}$
\end_inset

, and the bound is 
\begin_inset Formula 
\[
||v_{padd}||_{\infty}\leq||v||_{\infty}+\frac{r_{t}(q)}{q}||m_{2}||_{\infty}.
\]

\end_inset

Proof
\emph on
.
 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 By definition of plain addition 
\begin_inset Formula $\mathsf{ct_{padd}=}(x_{0}+\Delta m_{2},x_{1})$
\end_inset

.
 Hence for some polynomials 
\begin_inset Formula $a,a^{\prime}$
\end_inset

 with integer coefficients
\emph default
, 
\begin_inset Formula 
\begin{align*}
\frac{t}{q}\mathsf{ct_{padd}}(s) & =\frac{t}{q}(x_{0}+\Delta m_{2}+x_{1}s)\\
= & \frac{\Delta t}{q}m_{2}+\frac{t}{q}(x_{0}+x_{1}s)\\
= & \frac{\Delta t}{q}m_{2}+\frac{t}{q}ct(s)\\
= & m_{1}+v+\frac{q-r_{t}(q)}{q}m_{2}+at\text{ (see Eq.\ref{eq:relQDelta})}\\
= & m_{1}+m_{2}+v-\frac{r_{t}(q)}{q}m_{2}+at\\
= & [m_{1}+m_{2}]_{t}+v-\frac{r_{t}(q)}{q}m_{2}+(a-a^{\prime})t,
\end{align*}

\end_inset


\begin_inset Newline newline
\end_inset


\emph on
where in the last line has been used 
\begin_inset Formula $[m_{1}+m_{2}]_{t}=m_{1}+m_{2}+a^{\prime}t$
\end_inset

.
 Hence the noise is 
\emph default

\begin_inset Formula $v_{padd}=v-\frac{r_{t}(q)}{q}m_{2}$
\end_inset

 
\emph on
and can be bounded as 
\emph default

\begin_inset Formula 
\[
||v_{padd}||_{\infty}\leq||v||_{\infty}+\frac{r_{t}(q)}{q}||m_{2}||_{\infty}.
\]

\end_inset


\end_layout

\begin_layout Lemma
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsection
Encoding
\begin_inset CommandInset label
LatexCommand label
name "subsec:Encoding"

\end_inset


\end_layout

\begin_layout Standard
In Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

 is shown that plaintext elements in the BFV scheme are polynomials in 
\begin_inset Formula $R_{t}$
\end_inset

 and homomorphic operations on ciphertexts are reflected in the plaintext
 side as corresponding operations in the ring 
\begin_inset Formula $R_{t}$
\end_inset

.
 Thus it is important to find a mapping between integers (or real numbers)
 and polynomials in 
\begin_inset Formula $R_{t}$
\end_inset

 in an appropriate way in order to make applicable HE in the real world.
 Since no non-trivial subset of 
\begin_inset Formula $\mathbb{Z}$
\end_inset

 is closed under additions and multiplications, it is needed to settle for
 something that does not respect an arbitrary number of homomorphic operations.
 It is then the responsibility of the evaluating party to be aware of the
 type of encoding that is used, and perform only operations such that the
 underlying plaintexts throughout the computation remain in the image of
 the encoding map 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
 In other words a number must be 
\emph on
encoded.
 
\end_layout

\begin_layout Subsubsection*
Integer Encoding
\begin_inset CommandInset label
LatexCommand label
name "par:Integer-Encoding"

\end_inset


\end_layout

\begin_layout Standard
Given an integer 
\emph on
a
\emph default
 it is required to choose a base 
\emph on
S 
\emph default
and to form the (up to 
\begin_inset Formula $n$
\end_inset

-bits) base-
\emph on
S
\emph default
 expansion of 
\begin_inset Formula $|a|$
\end_inset

, say 
\begin_inset Formula $(a_{n-1}x^{n-1}+\ldots+a_{1}x+a_{0}).$
\end_inset

 When 
\begin_inset Formula $S=2$
\end_inset

 , 
\begin_inset Formula $-(2^{n}-1)\leq a\leq2^{n}-1$
\end_inset

 and the expansion is a binary expansion, when 
\begin_inset Formula $S>2$
\end_inset

, for the base-
\emph on
S 
\emph default
expansion, the coefficients are chosen from the symmetric set 
\begin_inset Formula $[\text{−}(S\text{−}1)/2,...,(S\text{−}1)/2]$
\end_inset

, since there is a unique representation with at most 
\emph on
n 
\emph default
coefficients for each integer in 
\begin_inset Formula $[\text{−}(S^{n}−1)/2,(S^{n}\text{−}1)/2]$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Formula 
\[
\mathtt{IntEncode}(a,S)=sign(a)\cdot(a_{n-1}x^{n-1}+\ldots+a_{1}x+a_{0})
\]

\end_inset


\begin_inset Newline newline
\end_inset

Decoding can fail for two reasons: 
\end_layout

\begin_layout Enumerate
if a reduction modulo the plaintext modulus 
\emph on
t 
\emph default
occurs, i.e., during homomorphic operations some coefficients in the underlying
 encoded plaintext become greater than the plaintext modulus 
\emph on
t
\end_layout

\begin_layout Enumerate
if a reduction modulo the polynomial modulus 
\begin_inset Formula $x^{n}+1$
\end_inset

 occurs, i.e., during homomorphic multiplications the degree of the underlying
 encoded plaintext become greater than the degree of the polynomial modulus
\end_layout

\begin_layout Standard
If any of these reductions happens, decoding yields an incorrect result,
 but no indications of these events are given until the final decryption.
\end_layout

\begin_layout Subsubsection*
Fractional Encoding
\begin_inset CommandInset label
LatexCommand label
name "subsec:Fractional-Encoding"

\end_inset


\end_layout

\begin_layout Standard
Real numbers can be encoded as integers if properly scaled and rescaled
 back after decryption or it is possible to encode real numbers as fixed
 precision numbers.
 Just like the integer encoding (Paragraph 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Integer-Encoding"

\end_inset

 above), the fractional encoding is parametrized by an integer base 
\begin_inset Formula $S\geq2$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Bioinformatics"

\end_inset

.
 It works by first encoding the integer part with an Integer Encoding, then
 the fractional part is codified in the same base-
\emph on
S, n 
\emph default
is added to each exponent of the fractional part and it is converted in
 a polynomial by changing the base 
\emph on
S 
\emph default
into the variable 
\begin_inset Formula $x$
\end_inset

.
 Next each sign of the fractional part is flipped.
 For example, consider 
\begin_inset Formula $S=2\text{ and }r=5.8125$
\end_inset

 which has finite binary expansion 
\begin_inset Formula $5.875=2^{2}+2^{0}+2^{-1}+2^{-2}+2^{-4}.$
\end_inset

 Its integer part is encoded as 
\begin_inset Formula $\mathtt{IntEncode}(5,S=2)=x^{2}+1$
\end_inset

, while its fractional part is encoded as 
\begin_inset Formula $\mathtt{FractionEncode}(0.875,S=2)=-x^{n-1}-x^{n-2}-x^{n-4}$
\end_inset

, thus 
\begin_inset Formula $\mathtt{FractionEncode}(5.875,S=2)=-x^{n-1}-x^{n-2}-x^{n-4}+x^{2}+1$
\end_inset

.
 More formally, for any rational number 
\emph on
r 
\emph default
with finite base-S expansion 
\begin_inset Formula 
\begin{align*}
\mathtt{FractionEncode}(r,S) & =sign(r)\cdot[\mathtt{IntEncode}(\lfloor|r|\rfloor,S)]+\\
 & +\mathtt{FractionEncode}(|r|-\lfloor|r|\rfloor,S)]
\end{align*}

\end_inset

Some rational numbers have not a finite base-
\emph on
S 
\emph default
expansion, thus in order to truncate them it is important to fix 
\begin_inset Formula $n_{i}$
\end_inset

 bits for the integer part and 
\begin_inset Formula $n_{f}$
\end_inset

 bits for the fractional part, such that 
\begin_inset Formula $n_{i}+n_{f}\leq n.$
\end_inset


\begin_inset Newline newline
\end_inset

Decoding can fail for two reasons:
\end_layout

\begin_layout Enumerate
if any of the coefficients of the underlying plaintext polynomials wrap
 around the plaintext modulus 
\emph on
t 
\emph default
the result after decoding is likely to be incorrect, just as in the case
 of the integer encoding Paragraph 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Integer-Encoding"

\end_inset


\end_layout

\begin_layout Enumerate
if during homomorphic multiplications the fractional part of the underlying
 plaintext polynomial expands down towards the integer part, and the integer
 part expands up towards the fractional part then these different parts
 get mixed up.
\end_layout

\begin_layout Section
Convolutional Neural Networks: A Brief 
\begin_inset Newline newline
\end_inset

Overview 
\begin_inset CommandInset label
LatexCommand label
name "sec:Convolutional-Neural-Networks"

\end_inset


\end_layout

\begin_layout Standard
Convolutional Neural Networks (CNNs) is a class of deep, feed-forward artificial
 neural networks that are applied to analyze visual imagery.
 Feed-forward is the name of the classical architectures of a neural network
 that is a computing model whose layered structure resembles the networked
 structure of neurons in the brain, with layers of connected nodes.
 A neural network can learn from data—so it can be trained to recognize
 patterns, classify data, and forecast future events.
 The term "deep" usually refers to the number of hidden layers in the neural
 network.
 Traditional neural networks only contain 2-3 hidden layers, while deep
 networks can have as many as 150.
 This structure enables CNNs to extract features directly from images.
 The relevant features are not pre-trained; they are learned while the network
 trains on a collection of images.
 This automated feature extraction makes deep learning models highly accurate
 for computer vision tasks such as object classification and eliminate the
 need for manual feature extraction.
 Every hidden layer increases the complexity of the learned image features.
 CNNs exploit spatial locality by enforcing a local connectivity pattern
 between neurons of adjacent layers.
 The architecture thus ensures that the learnt "filters" produce the strongest
 response to a spatially local input pattern.
 Stacking many such layers leads to non-linear filters that become increasingly
 global (i.e.
 responsive to a larger region of pixel space) so that the network first
 creates representations of small parts of the input, then from them assembles
 representations of larger areas.
 Filters are applied to each training image at different resolutions, and
 the output of each convolved image is used as the input to the next layer.
 The filters can start as very simple features, such as brightness and edges,
 and increase in complexity to features that uniquely define the object.
 
\begin_inset Newline newline
\end_inset

Employed layers can belong to one of the following groups:
\end_layout

\begin_layout Itemize
layers which role is to learn the representation and extract the learned
 features from the input images
\end_layout

\begin_layout Itemize
layers which role is to classify the input feature maps
\end_layout

\begin_layout Standard
Layers of the first type are modules composed by multiple convolutional
 and sub-sampling (pooling) layers, that, respectively, extract the features
 and reduce their dimensionality and are followed by an activation function.
 Layers of the second type can be viewed as a classical feed-forward neural
 network.
 These modules are described more in detail in the following part of this
 Section.
 
\end_layout

\begin_layout Subsubsection*
Convolutional Layer
\end_layout

\begin_layout Standard
From the Latin 
\emph on
convolvere
\emph default
, “to convolve” means to roll together.
 For mathematical purposes, a convolution is the integral measuring how
 much two functions overlap as one passes over the other.
 One can think of a convolution as a way of mixing two functions by multiplying
 them.
 The 
\emph on
convolutional layer
\emph default
 is the core building block of a CNN.
 The layer's parameters consist of a set of learnable filters (or kernels),
 which have a small receptive field
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The area, coming from a previous layer, that goes in input to a neuron.
\end_layout

\end_inset

, but extend through the full depth of the input volume.
 During the forward pass, each filter is convolved across the width and
 height of the input volume, computing the dot product between the entries
 of the filter and the input and producing a 2-dimensional activation map
 of that filter.
 As a result, the network learns filters that activate when it detects some
 specific type of feature at some spatial position in the input.
\end_layout

\begin_layout Subsubsection*
Pooling Layer (or Sub-Sampling)
\end_layout

\begin_layout Standard
It is common to periodically insert a 
\emph on
pooling layer
\emph default
 between successive convolutional layers in a CNN architecture.
 A pooling layer, has the role of summarizing a matrix of neighboring pixels
 into one in the resulting image.
 The "summarization" can be done by taking the largest value from one patch
 of neighbor pixels (
\emph on
max pooling
\emph default
), by taking the average of them (
\emph on
average pooling
\emph default
) or by taking their sum (
\emph on
sum pooling
\emph default
).
 The pooling function is computed on a matrix of pixels, then the subsequent
 matrix to which that function is applied has it center at a certain distance
 (called 
\emph on
stride)
\emph default
 from the previous one’s center.
 The intuition is that the exact location of a feature is less important
 than its rough location relative to other features.
 This layer serves to progressively reduce the spatial size of the representatio
n, to reduce the number of parameters and amount of computation in the network,
 and hence to also control overfitting
\begin_inset Foot
status open

\begin_layout Plain Layout
The overfitting issue does not allow to the CNN to generalize well when
 analyzing new unseen data, thus the CNN performances decrease during testing
 with respect to training.
\end_layout

\end_inset

.
 The pooling layer operates independently on every depth slice of the input
 and resizes it spatially.
 
\end_layout

\begin_layout Subsubsection*
Batch Normalization Layer
\end_layout

\begin_layout Standard
A 
\emph on
batch normalization 
\emph default
layer normalizes the output of a previous activation layer by subtracting
 the batch mean and dividing by the batch standard deviation.
 This layer increases the stability of the neural network, since it acts
 as a regularizer, it reduces overfitting, and allows to use higher learning
 rate during training 
\begin_inset CommandInset citation
LatexCommand cite
key "BN"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Activation Function
\end_layout

\begin_layout Standard
The 
\emph on
activation functions
\emph default
 basically decide whether a neuron should be activated or not as input in
 subsequent computations and involve a non-linear transformation of the
 input signal.
 There are different types of activation functions, as the 
\emph on
Rectified Linear Unit
\emph default
 (ReLU), the hyperbolic tangent or the sigmoid, but the ReLu is the most
 widely used since it has been empirically proven to be much faster and
 to achieve a small training error 
\begin_inset CommandInset citation
LatexCommand cite
key "Krizhevsky:2012:ICD:2999134.2999257"

\end_inset

.
 The function computed by the ReLu is 
\begin_inset Formula $f(x)=max(0,x)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Fully Connected Layer
\end_layout

\begin_layout Standard
A 
\emph on
fully connected
\emph default
 layer is usually put after several convolutional and pooling layers and
 it is similar to a regular feed-forward neural network, since the receptive
 field of a neuron in a fully connected layer are all the neurons of the
 previous layer.
 The activation of a neuron in this layer can be computed with a matrix
 multiplication for a matrix of weights, followed by a bias offset.
\end_layout

\begin_layout Subsubsection*
Softmax
\end_layout

\begin_layout Standard
The 
\emph on
softmax 
\emph default
layer is usually placed at the end of a Convolutional Neural Network, after
 the last fully-connected layer that has exactly a number of neurons equal
 to that of classes.
 The softmax function squeezes the outputs for each class between 0 and
 1 and also divides by the sum of the outputs.
 This essentially gives the probability of the input being in a particular
 class.
 It can be defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma(z)_{j}=\frac{e^{z_{j}}}{\sum_{k=1}^{K}e^{z_{k}}},\;for\;j=1,...,K
\]

\end_inset


\end_layout

\begin_layout Subsection
Approximations For Homomorphic Encryption 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Approximations-For-HE"

\end_inset


\end_layout

\begin_layout Standard
Since homomorphic encryption supports only additions and multiplications,
 only polynomial functions can be computed in a straightforward way.
 Moreover, due to the increased complexity in computing circuits with nested
 multiplications, it is desired to restrict the computation to low-degree
 polynomials 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy"

\end_inset

.
 Max pooling cannot be computed directly since the max-function is non-polynomia
l.
 However, powers of it can be approximated due to the relation 
\begin_inset Formula $max(x_{1},...,x_{n})=\text{lim}_{d\to\infty}(\sum_{i}x_{i}^{d})^{1/d}$
\end_inset

.
 The degree 
\emph on
d 
\emph default
should be kept reasonably small, the smallest meaningful value 
\emph on
d=1 
\emph default
returns a scalar multiple of the 
\emph on
average pooling 
\emph default
function.
 It is also possible to compute the average pooling function by multiplying
 for the inverse of the input number of neurons 
\emph on
n
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Bioinformatics"

\end_inset


\emph on
.
 
\emph default
The sigmoid, the softmax and the ReLu activation functions are non-polynomial
 functions.
 The solution of 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/XieBFGLN14"

\end_inset

 was to approximate these functions with low-degree polynomials, but another
 possible solution can consist in using the lowest-degree non-linear polynomial
 function, which is the square function 
\begin_inset Formula $sqr(z)\coloneqq z^{2}$
\end_inset

, since it can be a good tradeoff between having a non-linear transformation,
 as required by the training algorithm, and the need to keep the degree
 of the polynomials small, to make the homomorphic encryption parameters
 feasible.
 Fortunately, the convolutional and the fully connected layer can be directly
 implemented, because they can be seen as weighted-sum functions that involve
 only additions and multiplications.
 Moreover during testing, the multiplications here are between precomputed
 weights and the additions involve precomputed biases and the values of
 the feeding layer.
 Since the weights and the biases are not encrypted, it is possible to use
 the more efficient plain multiplication and plain addition operations,
 as is described in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-with-plaintext"

\end_inset

.
\end_layout

\begin_layout Subsection
Convolutional Neural Networks In Literature
\begin_inset CommandInset label
LatexCommand label
name "subsec:Convolutional-Neural-Networks in Lit"

\end_inset


\end_layout

\begin_layout Standard
The most recent Convolutional Neural Networks have been designed for the
 Image Large Scale Visual Recognition Challenge.
\begin_inset Newline newline
\end_inset

In 2012 the AlexNet 
\begin_inset CommandInset citation
LatexCommand cite
key "Krizhevsky:2012:ICD:2999134.2999257"

\end_inset

 designed by Krizhevsky, Sutskever, and Hinton, won the competition.
 AlexNet introduced innovative techniques to solve the overfitting, as 
\emph on
Principal Component Analysis
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
It is a statistical method that converts a set of possibly correlated variables
 in a lower dimensional set of linearly uncorrelated variables, called principal
 components.
\end_layout

\end_inset

 
\emph default
and 
\emph on
dropout 
\emph default
that consists in ignoring randomly chosen neurons during the training phase,
 to reduce the possibility of learning correlations among the neurons themselves.
\begin_inset Newline newline
\end_inset

In 2014 the VGG 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/SimonyanZ14a"

\end_inset

 designed by Simonyan and Zisserman focused on empirical examination of
 the effects on the CNN accuracy of the depth of convolutional layers.
 With respect to the AlexNet, in VGG the convolutions are expanded by observing
 that two 3x3 convolutions are equivalent to a 5x5 one and that three 3x3
 convolutions are equivalent to a 7x7 one.
 Furthermore, by locating a ReLU after such 3x3 convolutional layers, the
 CNN will learn a more discriminative function, with a smaller number of
 parameters.
\begin_inset Newline newline
\end_inset

The OverFeat 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/SermanetEZMFL13"

\end_inset

, designed by Sermanet et al.
 in 2013, deals with the problem of localization useful for the classification
 task.
\begin_inset Newline newline
\end_inset

Other important CNNs are the GoogLeNet 
\begin_inset CommandInset citation
LatexCommand cite
key "43022"

\end_inset

 designed by Szegedy et al.
 in 2014 and the the ResNet 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/HeZRS15"

\end_inset

, designed by He et al.
 in 2015.
 
\end_layout

\begin_layout Chapter
State of the Art
\begin_inset CommandInset label
LatexCommand label
name "chap:State-of-the-Art"

\end_inset


\end_layout

\begin_layout Standard
This Chapter focuses on studies of methods for Privacy-Preserving Machine
 Learning and on other related interesting applications of homomorphic encryptio
n in different fields (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Other-related-works"

\end_inset

).
\begin_inset Newline newline
\end_inset

These works are divided in two categories that are based on one of these
 two scenarios:
\end_layout

\begin_layout Enumerate
There are multiple data providers whose data must be commonly protected
 (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Multiple-Data-Providers"

\end_inset

)
\end_layout

\begin_layout Enumerate
There is a single data provider (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Single-Data-Provider"

\end_inset

)
\end_layout

\begin_layout Standard
In both cases their data are sent to an outsourced server which should make
 some computations but which is supposed to be a 
\emph on
curious-but-honest
\emph default
 server; i.e., the server carries out the result of computations faithfully,
 but it may try to learn as much as possible about the inputs and/or outputs
 of the computation.
 The processed data can be sent back to the data provider/s or to a third
 party, a data analyst, that is allowed to decrypt the result.
\end_layout

\begin_layout Section
Multiple Data Providers 
\begin_inset CommandInset label
LatexCommand label
name "sec:Multiple-Data-Providers"

\end_inset


\end_layout

\begin_layout Standard
A possible approach to preserve privacy while examining data on outsourced
 untrusted party is to use secure 
\emph on
Multi-Party Computation (MPC) 
\emph default
techniques 
\begin_inset CommandInset citation
LatexCommand cite
key "Goldreich98securemulti-party"

\end_inset

, which are focused on establishing a communication protocol between the
 parties involved, such that if the parties follow it they will end with
 the desired results while protecting the security and privacy of their
 respective assets.
\begin_inset Newline newline
\end_inset

All the following works have in common the fact that they use relatively
 simple HE schemes, that is, additively or multiplicative HE that allow
 to perform homomorphically only one of these two operations.
 In those cases HE as RSA 
\begin_inset CommandInset citation
LatexCommand cite
key "Rivest1978"

\end_inset

 and El-Gamal 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/tit/Elgamal85"

\end_inset

, that are multiplicative homomorphic or Paillier 
\begin_inset CommandInset citation
LatexCommand cite
key "Paillier"

\end_inset

 that is additively homomorphic are usually used (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:History-of-HE"

\end_inset

).
 
\begin_inset Newline newline
\end_inset

Barni et al.
 (2016) in 
\begin_inset CommandInset citation
LatexCommand cite
key "Barni2006APP"

\end_inset

 propose an iterative method to allow the privacy preserving forward phase
 on a neural network.
 The data owner encrypts the data and sends them to the server.
 The server computes an inner product between the data and the weights of
 the first layer, and sends the result to the data owner.
 The data owner decrypts, applies the non-linear transformation, and encrypts
 the result before sending it back to the server.
 The server can apply the second layer and send the output back to the data
 owner.
 The process continues until all the layers have been computed.
 However, in 2007 Orlandi et al.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Orlandi:2007:ONN:1340430.1340439"

\end_inset

 have shown that this process leaks information of the weights to the data
 owner and therefore propose a method to obscure the weights.
 
\begin_inset Newline newline
\end_inset

Kuri et al.
 (2017) in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/ssci/Kuri0OOAP0M17"

\end_inset

 use additively homomorphic encryption in combination with Extreme Learning
 Machine (ELM).
 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "ELM"
description "Extreme Learning Machines"

\end_inset

 ELM is a feedforward neural network where connection weights from the input
 layer to the hidden layer are randomly generated and the connection weights
 from the hidden layer to the output layer are learned analytically 
\begin_inset CommandInset citation
LatexCommand cite
key "inverse"

\end_inset

.
 In particular they focus on a single hidden layer feedforward neural network
 (SLFN) and provide both training and testing algorithm on homomorphically
 encrypted data.
 Due to its simple structure ELM has relatively fast learning speed and
 higher accuracy as a nonlinear classifier and since only one homomorphic
 addition is performed, the computational overhead added is quite small.
 However, this simplicity does not allow to accomplish more complex tasks,
 such as object recognition in images as it is possible to do with CNNs.
\begin_inset Newline newline
\end_inset

Le Trieu Phong et al.
 (2017) in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/iacr/PhongAHWM17"

\end_inset

 propose a privacy-preserving deep learning system in which many learning
 participants perform neural network-based deep learning over a combined
 dataset of all, without actually revealing the participants’ local data
 to a central server.
 They revisit the previous work in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/ccs/ShokriS15"

\end_inset

 and point out that local data information may be actually leaked to an
 honest-but-curious server, then they move on to fix that problem via building
 an enhanced system that also keeps accuracy intact.
 Each learning participant is also a data provider and has a local copy
 of the neural network to train.
 The proposed system aims at training the weights utilizing multiple data
 sources and gradient-encrypted Asynchronous Stochastic Gradient Descent
 (ASGD).
 There is a global weight vector 
\begin_inset Formula $W_{global}$
\end_inset

, initialized randomly.
 At each iteration, replicas of the neural network (one for each participant),
 are run over local dataset, and the corresponding local gradient vector
 
\begin_inset Formula $G_{local}$
\end_inset

 is sent to the server.
 For each 
\begin_inset Formula $G_{local}$
\end_inset

, the server then updates the global parameters 
\begin_inset Formula $W_{global}:=W_{global}-\alpha\cdot G_{local}$
\end_inset

 with 
\begin_inset Formula $\alpha$
\end_inset

 learning rate.
 The updated global parameters are broadcast to all the replicas, which
 then use them to replace their old weight parameters, until a minimum for
 a pre-defined cost function is reached.
 As showed in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Gradients-encrypted-Asynchronous"

\end_inset

, to ensure privacy, additively homomorphic encryption is used and the updating
 formula becomes 
\begin_inset Formula $E(W_{global}):=E(W_{global})+E(-\alpha\cdot G_{local})$
\end_inset

 and to ensure integrity of the homomorphic ciphertext, each client uses
 a secure channel such as TLS/SSL to communicate the homomorphic ciphertexts
 to the server.
 To use the power of parallel computation when the server has multiple processin
g units 
\begin_inset Formula $PU_{1},…,PU_{npu}$
\end_inset

, ASGD splits the weight vector 
\emph on
W
\emph default
 and gradient vector
\emph on
 G
\emph default
 into 
\begin_inset Formula $n_{pu}$
\end_inset

 parts, so that each processing unit 
\begin_inset Formula $PU_{i}$
\end_inset

 computes the update rule 
\begin_inset Formula $W_{i}=W_{i}-G_{i}$
\end_inset

.
\begin_inset Newline newline
\end_inset

The participants jointly set up the public key 
\begin_inset Formula $pk$
\end_inset

 and secret key 
\begin_inset Formula $sk$
\end_inset

 for an additively homomorphic encryption scheme.
 The secret key 
\begin_inset Formula $sk$
\end_inset

 is kept confidential against the cloud server, but is known to all learning
 participants.
 Each participant establishes a TLS/SSL secure channel, different from each
 other, to communicate and protect the integrity of the homomorphic ciphertexts.
 The downloads and uploads of the encrypted parts of 
\begin_inset Formula $W_{global}$
\end_inset

 can be asynchronous in two aspects: the participants are independent with
 each other; and the processing units are also independent with each other.
 However protecting the gradients against the cloud server comes with the
 cost of increased communication between the learning participants and the
 cloud server.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename Img/MPC.png
	display false
	scale 45
	clip

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Gradients-encrypted Asynchronous SGD for privacy-preserving deep learning,
 with a curious cloud server and N honest participants.
 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/iacr/PhongAHWM17"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:Gradients-encrypted-Asynchronous"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Saeed Samet et al.
 (2012) in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/dke/SametM12"

\end_inset

 focus their work on training ELM networks when data is vertically or horizontal
ly distributed among parties (data owners), using as sub-protocols secure
 multi-party multiplication and secure multi-party addition.
 The model (i.e.
 the network) is securely constructed and distributed among the parties
 involved.
 Indeed, at the end of the learning protocol the parties can jointly use
 the model on target data to predict the corresponding output.
 This seems to be a different approach with respect to the the two previously
 presented works (
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/ssci/Kuri0OOAP0M17"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/iacr/PhongAHWM17"

\end_inset

) where there was always a central entity (server/cloud) designated to aggregate
 partial results coming form the different parties.
 They also prove that their secure multi-party multiplication as well as
 secure multi-party addition are secure against collusion attacks
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The operations that combine several data to produce a new copy.
 The operations include averaging, replacement, linear combination, etc.
\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "CollusionAtt"

\end_inset

 (if up to 
\begin_inset Formula $n-1$
\end_inset

 parties are implicated in the attack) and can be used over public channels.
 The problem with this protocol is that the time needed for training increases
 with the number of parties involved.
 
\end_layout

\begin_layout Section
Single Data Provider
\begin_inset CommandInset label
LatexCommand label
name "sec:Single-Data-Provider"

\end_inset


\end_layout

\begin_layout Standard
Graepel et al.
 (2013) 
\begin_inset CommandInset citation
LatexCommand cite
key "Graepel:2012:MCM:2482419.2482421"

\end_inset

 suggest a way to adapt machine learning algorithms, as classification,
 in order to train them over encrypted data.
 Therefore, for homomorphic encryption limitations, they are forced to use
 functions that learn low degree polynomials.
 As a result, most of the algorithms proposed are of the linear discrimination
 type and therefore for many tasks they do not deliver the same level of
 accuracy as neural networks are capable of.
\begin_inset Newline newline
\end_inset

Yoshinori Aono et al.
 (2016) in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/codaspy/AonoHPW16"

\end_inset

 have proposed a homomorphism-aware logistic regression via approximation
 of the logarithm in the cost function to minimize, with a polynomial of
 degree 
\emph on
k 
\emph default
(e.g.
 
\emph on
k
\emph default
=2).
 Since HE ensures data secrecy, 
\emph on
differential privacy 
\emph default
is added to the model to ensure also output privacy.
 
\end_layout

\begin_layout Paragraph*

\emph on
Differential privacy
\end_layout

\begin_layout Standard
is a technique that aims to maximize the accuracy of queries from statistical
 databases
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Here, the term statistical database means a set of data that are collected
 under the pledge of confidentiality for the purpose of producing statistics
 that, by their production, do not compromise the privacy of those individuals
 who provided the data
\end_layout

\end_inset

 while measuring impact on individuals whose information is in the database.
 Intuitively it can be explained by saying that if there are two datasets
 
\begin_inset Formula $D_{1}$
\end_inset

 and 
\begin_inset Formula $D_{2}$
\end_inset

 that differ on a single element (i.e., the data of one person), a given different
ially private algorithm will behave approximately the same on both datasets.
 More formally,
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(
\begin_inset Formula $\epsilon-$
\end_inset

Differential Privacy 
\begin_inset CommandInset citation
LatexCommand cite
key "Dwork:2014:AFD:2693052.2693053"

\end_inset

) A randomized mechanism M, that answers to queries on a database, provides
 ε-differential privacy, if, for all databases 
\begin_inset Formula $D_{1}$
\end_inset

 and 
\begin_inset Formula $D_{2}$
\end_inset

 which differ by at most one element, and for any 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula 
\[
\frac{Pr[M(D_{1})=t]}{Pr[M(D_{2})=t]}\text{≤}e^{ε}.
\]

\end_inset

It has been shown in 
\begin_inset CommandInset citation
LatexCommand cite
key "10.1007/11681878_14"

\end_inset

 that if a mechanism satisfies ε-differential privacy, then an adversary
 who knows the private value of all the individuals in the dataset, except
 for one single individual, cannot figure out the private value of the unknown
 individual, with sufficient confidence, from the responses of the mechanism
 M.
 ε-differential privacy is therefore a very strong notion of privacy 
\begin_inset CommandInset citation
LatexCommand cite
key "Chaudhuri:2008:PLR:2981780.2981817"

\end_inset

.
\begin_inset Newline newline
\end_inset

In 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/codaspy/AonoHPW16"

\end_inset

 to add 
\begin_inset Formula $\epsilon$
\end_inset

-differential privacy they change the computation done at the server side.
 Namely, the server generates Laplace noises, encrypts and sums them to
 its computation.
 The result is that the data analyst (or data provider), finds, after decryption
, exactly the Laplace-perturbed coefficients of the cost function.
 Even if good results are obtained in the experimental result in terms of
 F-score and AUC (Area Under The Curve) measure, differential privacy in
 addition to the encryption decreases the performances of the classifier,
 this imply that the usage of really large datasets is needed in order to
 mitigate the effect of noise introduced by differential privacy.
\begin_inset Newline newline
\end_inset

One of the most important works that is considered to be the first and unique
 example of application of HE to CNNs is the one presented by Dowlin et
 al.
 (2016) 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy"

\end_inset

.
 The difference with respect all the other works is given by the fact that
 CNNs are really powerful classification machine learning model and are
 way more complex than ELM or logistic regression.
 They propose a method to convert pre-trained neural networks to CryptoNets,
 neural networks that can be applied to encrypted data.
 This work focuses only on the inference stage and the assumption is that
 the cloud (that has to perform the prediction) already has the model.
 CryptoNets are able to make predictions on encrypted data coming from a
 data provider on an outsourced server that provides back to the data owner
 the results of computation, still in an encrypted form.
 The data owner then is able to decrypt the results and access to the unencrypte
d prediction.
 In this sense the purpose of this work is similar to the one of this thesis,
 however they do not provide an open source library for CNNs that works
 homomorphically on encrypted data that can reproduce their work and they
 do not focus on the estimate of optimal parameters for the HE conversion
 of the CNN, even if this is an important starting point to achieve better
 performances.
 Another difference is the fact that they apply batching techniques in order
 to pack more input data in the same ciphertext, using the Chinese Reminder
 Theorem (CRT) 
\begin_inset CommandInset citation
LatexCommand cite
key "Commutative-Algebra"

\end_inset

 to perform Single Instruction Multiple Data (SIMD) operations 
\begin_inset CommandInset citation
LatexCommand cite
key "HomomorphicEvalAESCircuit"

\end_inset

.This gives good throughput but relatively poor latency in terms of predictions
 per hour.
 
\end_layout

\begin_layout Section
Other related works 
\begin_inset CommandInset label
LatexCommand label
name "sec:Other-related-works"

\end_inset


\end_layout

\begin_layout Standard
One of the first attempt made to speed up the computation proposed in CryptoNets
 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy"

\end_inset

, as presented in the previous Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Single-Data-Provider"

\end_inset

, has been made by Yizhi Wang et al.
 (2018) in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:conf/iscas/WangLW18b"

\end_inset

.
 In particular they propose an hardware solution, by providing a dedicated
 convolution core architecture for the most complex convolutional layers
 of CryptoNets on the basis of Fan-Vercauteren (FV) HE scheme 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

.
 They propose a simplified modular multiplication algorithm suitable for
 CryptoNets that enable to simplify and reduce dramatically hardware complexity.
 Compared to a well optimized version CPU implementation of CryptoNets,
 their proposed architecture is 
\begin_inset Formula $11.9\times$
\end_inset

 faster while consuming a power of 
\begin_inset Formula $537mW$
\end_inset

.
\begin_inset Newline newline
\end_inset

Zhenyong Zhang et al.
 (2018) in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kalman"

\end_inset

 propose the application of HE for secure Kalman Filter state estimation
 in cyber-physical systems.
 In their scenario, the data providers are multiple sensors that send their
 measurements to an outsourced estimator node in charge of computing the
 Kalman Filter prediction.
 The goal of using HE is to protect data against confidentiality attacks
 in the communication network or at the estimator node.
 They consider that sensor measurements are valid but they can be overheard
 during communications.
 Furthermore, they assume a curious-but-honest estimator; i.e., the estimator
 carries out the estimation faithfully, but it may try to learn as much
 as possible about the inputs and/or outputs of the estimation.
 They use RSA since there is only the need of a multiplicative homomorphic
 encryption.
\end_layout

\begin_layout Chapter
Parameters Estimation Methodology
\begin_inset CommandInset label
LatexCommand label
name "chap:Methodology"

\end_inset


\end_layout

\begin_layout Standard
In this Chapter the encryption parameters required by the BFV HE scheme
 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BFV"

\end_inset

) will be presented in a more detailed way and the relations that exist
 among them will be analyzed (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

).
 The problem of transposing a plain CNN in the HE world and thus of finding
 appropriate encryption parameters, that this work aims to solve, will be
 exposed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

, and in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Optimization-Problem"

\end_inset

 the problem will be described in a more formal manner, through a mathematical
 optimization problem.
 The solution proposed involves the implementation of a heuristic and will
 be explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic:-Binary-Search"

\end_inset

.
\end_layout

\begin_layout Section
Encryption Parameters
\begin_inset CommandInset label
LatexCommand label
name "sec:Encryption-Parameters"

\end_inset


\end_layout

\begin_layout Standard
The choice of encryption parameters is crucial since it significantly affects
 the performance, capabilities, and security of the encryption scheme.
 Some choices of parameters may be insecure, give poor performance, yield
 ciphertexts that will not work with any homomorphic operations, or a combinatio
n of all of these.
 In Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:notation"

\end_inset

 there is a list of the most important parameters of the BFV encryption
 scheme, that has been explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BFV"

\end_inset

 and below it is explained which are the relations that these parameters
 have each other.
\begin_inset Float table
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\paragraph_spacing double
\begin_inset Caption Standard

\begin_layout Plain Layout
Notation used
\begin_inset CommandInset label
LatexCommand label
name "tab:notation"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top" width="7cm">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size footnotesize
Parameter
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size footnotesize
Description
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
q
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
Modulus in the ciphertext space
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
t
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
Modulus in the plaintext space
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
n
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
A power of 2
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

Before to encrypt a number it must be encoded as a plaintext polynomial
 as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

.
 Indeed in BFV the plaintext space is 
\begin_inset Formula $R_{t}=\mathbb{Z}_{t}[x]/(x^{n}+1)$
\end_inset

, that is, polynomials of degree less than 
\emph on
n
\emph default
 with coefficients modulo 
\emph on
t
\emph default
.
 Thus, it is important that the coefficients of the polynomials appearing
 throughout the computations never experience coefficients larger than the
 plaintext modulus
\emph on
 t
\emph default
, otherwise the decryption procedure will lead to incorrect results.
 
\begin_inset Newline newline
\end_inset

The 
\series bold
plaintext modulus 
\emph on
t
\series default
 
\emph default
in the BFV scheme can be any positive integer.
 There is not a prescribed plaintext polynomial that is better than others,
 because it depends on the calculi (i.e.
 in the considered case, on the structure of the CNN) and data that is needed
 to perform.
 Nevertheless, it is not easy to understand which is the maximum infinity
 norm of a polynomial that is reached throughout the computations, but it
 is a key point not to lose integrity of the expected result.
 The plaintext modulus influences also the so called Noise budget NB, 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "NB"
description "Noise Budget"

\end_inset

 that has been presented in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Noise"

\end_inset

.
 As explained before, the NB determines the number of operations one can
 perform on a ciphertext (multiplications, additions, exponentiations, both
 with another ciphertext or plaintext) without compromising the final result.
 More precisely, the value of the NB in a freshly encrypted ciphertext,
 given in Definition 
\begin_inset CommandInset ref
LatexCommand ref
reference "def:(Noise-Budget)"

\end_inset

 can be approximated by the following formula: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
NB\backsim log_{2}(\textrm{coeff\_modulus (q)}/\textrm{plain\_modulus (t)) (bits)}\label{eq:NOISE_BUDGET}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset

The polynomial 
\begin_inset Formula $(x^{n}+1)$
\end_inset

 is the 
\series bold
polynomial modulus
\series default
, where
\series bold
 
\emph on
n
\series default
\emph default
 is a power of 2.
 Indeed as explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BFV"

\end_inset

, the discrete Gaussian distribution 
\begin_inset Formula $D_{\mathbb{Z},\sigma}$
\end_inset

 is used to define a distribution 
\begin_inset Formula $\chi$
\end_inset

 on 
\begin_inset Formula $R$
\end_inset

.
 The distribution 
\begin_inset Formula $\chi$
\end_inset

 is in general not as simple as just sampling coefficients according to
 
\begin_inset Formula $D_{\mathbb{Z},\sigma}$
\end_inset

.
 However, for the polynomial 
\begin_inset Formula $(x^{n}+1)$
\end_inset

 where 
\series bold
\emph on
n
\series default
\emph default
 is a power of 2, 
\begin_inset Formula $\chi$
\end_inset

 can indeed be defined as 
\begin_inset Formula $D_{\mathbb{Z},\sigma}^{n}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

, from which is possible to sample in a more efficient way.
 Increasing
\emph on
 n
\emph default
 significantly decreases performances since operations are performed over
 polynomials of bigger degree.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

If the polynomial modulus is held fixed, then the choice of the 
\series bold
coefficient modulus 
\emph on
q
\series default
 
\emph default
affects: the noise budget in a freshly encrypted ciphertext (see Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:NOISE_BUDGET"

\end_inset

) and the security level (see Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

).
 In general it is possible to take as 
\emph on
q 
\emph default
any integer as long as it is not too large to cause security problems.
 In Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 are showed the upper bounds on the bit length of 
\emph on
q 
\emph default
with respect to a given security level 
\begin_inset Formula $\lambda$
\end_inset

 and a polynomial modulus degree 
\emph on
n, 
\emph default
assuming the standard deviation of the discrete Gaussian distribution 
\begin_inset Formula $\sigma$
\end_inset

 to be the default value of 
\begin_inset Formula $3.19≈8/2π$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptoeprint:2012:144"

\end_inset

.
 These values are retrieved according to the most recent homomorphic encryption
 security standards.
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 shows that using a larger
\emph on
 n
\emph default
 allows for a larger 
\emph on
q
\emph default
 to be used without decreasing the security level, which in turn increases
 the noise ceiling and thus allows for larger 
\emph on
t
\emph default
 to be used.
 For this reason, decreasing 
\emph on
q 
\emph default
with all the other parameters held fixed, only increases the security level.
 
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\paragraph_spacing double
\begin_inset Caption Standard

\begin_layout Plain Layout
Default pairs (n, q) for 128-bit, 192-bit, and 256-bit 
\begin_inset Formula $\lambda$
\end_inset

-security levels.
\begin_inset CommandInset label
LatexCommand label
name "tab:Default-pairs-(n,q)"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Bit-length of 
\emph on
q
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\emph on
n
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
128-bit security
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
192-bit security
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
256-bit security
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1024
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
27 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
19
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
14
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2048
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
54 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
37
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
29
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4096
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
109 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
75
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
58
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8192
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
218 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
152
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
118
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
16384
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
438 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
300
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
237
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
32768
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
881
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
600
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
476
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset

On the other hand, given a certain 
\emph on
q
\emph default
, choosing a big 
\emph on
t
\emph default
 allows to reach bigger infinity norm for polynomials during the computation,
 but at the same time decreases the initial NB and thus the possibility
 to evaluate a longer circuit (number of operations) on input data.
 Indeed, each operation performed adds a certain amount of noise to the
 initial ciphertext and the NB in a freshly encrypted number is the max
 amount of noise is it possible to add, as detailed in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Noise"

\end_inset

.
 Note that the NB computed is a pessimistic estimate and not a precise computed
 value and that the NB consumed depends not only on the type of operation
 performed (multiplication rather than addition), but also on the encryption
 parameters 
\emph on
q
\emph default
 and 
\emph on
t
\emph default
 chosen.
\end_layout

\begin_layout Section
Problem Formulation 
\begin_inset CommandInset label
LatexCommand label
name "sec:Problem-Formulation"

\end_inset


\end_layout

\begin_layout Standard
The task of preserving privacy of data provider while its data are processed
 by an outsourced CNN on a server can be achieved in different ways.
 Given that HE is used to guarantee the privacy of data, there can be two
 possibilities:
\end_layout

\begin_layout Enumerate
One can train the CNN from scratch on plain publicly available datasets
 or take a publicly available pre-trained CNN.
 In the latter case the CNN must be transformed in a way that allows to
 compute only polynomial functions, to be compliant with the operations
 that it will be able to perform on encrypted data (as explained in Subsection
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximations-For-HE"

\end_inset

).
 Then one can encode the CNN and send it to the server along with the parameters
 
\emph on
n, t
\emph default
 and 
\emph on
q
\emph default
 used for the encoding.
 The encoded network can then be used to make prediction on encrypted data,
 provided that they are encrypted with the same encryption parameters.
\end_layout

\begin_layout Enumerate
The data provider can encrypt its data and send them to the server.
 The server trains a CNN directly on encrypted data.
\end_layout

\begin_layout Standard
The second option could look simpler than the first one, but it would require
 to run the backward propagation algorithm homomorphically on the encrypted
 data, that is a really computational intensive process.
 Moreover, since only polynomial functions could be used and thus functions
 like rectified linear and sigmoid functions should be omitted, some derivatives
 could become unbounded.
 This could lead to strange behavior when running the gradient descent algorithm
 during the backward propagation step, especially for deeper nets it would
 sometimes blow up or overfit.
\begin_inset Newline newline
\end_inset

The first option becomes the more promising way to follow and basically
 require the steps in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximation-steps-CNN"

\end_inset

.
 At each step the accuracy of the original CNN can decrease by a factor
 
\begin_inset Formula $\epsilon\geq0$
\end_inset

, since it is gradually changed and HE parameters are introduced, but it
 becomes able to guarantee the privacy of the processed data.
 
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Transformation steps of the pre-trained CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:Approximation-steps-CNN"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Img/process.pdf
	display false
	scale 44

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Description

\noun on
step
\series bold

\begin_inset space ~
\end_inset

1
\begin_inset space ~
\end_inset

Approximation
\begin_inset space ~
\end_inset


\series default
(optional): 
\noun default
If the CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 in input contains non-polynomial functions, it is 
\emph on
approximated
\emph default
 with only polynomial functions as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximations-For-HE"

\end_inset

 and the approximated CNN 
\begin_inset Formula $\varPhi$
\end_inset

 is eventually retrained.
\end_layout

\begin_layout Description

\noun on
step
\series bold

\begin_inset space ~
\end_inset

2
\series default

\begin_inset space ~
\end_inset

Encoding: 
\noun default
The approximated 
\begin_inset Formula $\varPhi$
\end_inset

 is 
\emph on
encoded
\emph default
 as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

 provided that optimal encryption parameters 
\emph on
n, t
\emph default
 and 
\emph on
q 
\emph default
are found, otherwise one should return to 
\noun on
step 1
\noun default
 to find a smaller and different CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

.
 This step outputs 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 that is an encoded network under parameters 
\emph on
n, t
\emph default
 and 
\emph on
q
\emph default
.
 In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Optimization-Problem"

\end_inset

 this step will be explained in detail.
\end_layout

\begin_layout Description

\noun on
step
\series bold
\noun default

\begin_inset space ~
\end_inset

3
\series default
\noun on

\begin_inset space ~
\end_inset

Testing: 
\noun default
The encoded 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 is ready to be 
\emph on
tested
\emph default
 and thus make predictions on encrypted data.
\end_layout

\begin_layout Section
Optimization Problem 
\begin_inset CommandInset label
LatexCommand label
name "sec:Optimization-Problem"

\end_inset


\end_layout

\begin_layout Standard
Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

 gives a hint of how difficult it is, in general, to find valid encryption
 parameters.
 This becomes even more difficult if the field of application of the HE
 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "HE "
description "Homomorphic Encryption"

\end_inset

 is the one of Deep Learning and CNNs 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "CNN"
description "Convolutional Neural Network"

\end_inset

 where there are many nested computations to perform (i.e., the depth of the
 circuit to compute on input data is generally high) and the number of parameter
s (i.e., weights) that composes the CNN's model is huge as shown in 
\begin_inset CommandInset citation
LatexCommand cite
key "Alippi:2018:MCN:3207947.3207995"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

If 
\emph on

\begin_inset Formula $I$
\end_inset


\emph default
 is a 
\begin_inset Formula $r\times c\times d$
\end_inset

 input image of 
\emph on
r 
\emph default
rows, 
\emph on
c
\emph default
 columns and 
\emph on
d 
\emph default
channels (e.g.
 
\emph on
d=
\emph default
3 for RGB images and 
\emph on
d=1 
\emph default
for grey-scale images), 
\begin_inset Formula $y\in\varPsi=\{w_{1},...,w_{\varPsi}\}$
\end_inset

 is the output of the CNN representing the multi-class classification of
 image 
\emph on
I
\emph default
 and 
\begin_inset Formula $\varPhi$
\end_inset

 is the approximated pre-trained model of a CNN, defined as 
\begin_inset Formula $y=\varPhi(I)$
\end_inset

, there are two objectives that can be defined and must be pursued:
\end_layout

\begin_layout Enumerate
Transform the approximated CNN's pre-trained model 
\begin_inset Formula $\varPhi$
\end_inset

 in 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 (
\emph on
encoding
\emph default
), such that the transformed 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 is able to accomplish the same classification task of the original 
\begin_inset Formula $\Phi$
\end_inset

 but on encrypted input data 
\emph on
Enc(I).
\end_layout

\begin_layout Enumerate
Find suitable encryption parameters 
\emph on
n, t, 
\emph default
and 
\emph on
q 
\emph default
that allow to perform this transformation
\emph on
 
\emph default
in an optimal way.
\end_layout

\begin_layout Standard
Since homomorphic encryption supports only additions and multiplications
 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximations-For-HE"

\end_inset

), only polynomial functions can be computed in a straightforward way, thus
 the transformation of 
\begin_inset Formula $\varPhi$
\end_inset

 in 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 can be achieved if 
\begin_inset Formula $\varPhi$
\end_inset

 contains only polynomial functions.
 The transformation of 
\begin_inset Formula $\varPhi$
\end_inset

 in 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 consists basically in an encoding of all the parameters 
\begin_inset Formula $\theta$
\end_inset

 of 
\begin_inset Formula $\varPhi$
\end_inset

, i.e., each 
\begin_inset Formula $\theta$
\end_inset

 becomes 
\begin_inset Formula $\tilde{\theta}$
\end_inset

 that is, a polynomial in the plaintext space 
\begin_inset Formula $R_{t}$
\end_inset

.
 The encoding methodology has been explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

.
 For this reason the model 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 is not encrypted, but only encoded, and most of the operations can be performed
, in a more efficient way, as 
\noun on
plain multiplications 
\noun default
and 
\noun on
plain additions 
\noun default
(see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-and-Noise"

\end_inset

)
\noun on
.
 
\noun default

\begin_inset Newline newline
\end_inset

More formally, the previous two objectives can be seen as the output of
 a function 
\emph on
f
\emph default
 that, given the CNN's model 
\begin_inset Formula $\varPhi$
\end_inset

, the plain input dataset 
\emph on
D 
\emph default
such that 
\begin_inset Formula $I\in D$
\end_inset

 with its corresponding classifications 
\emph on
Y
\emph default
 given by the model, the set of allowed coefficient modulus 
\emph on

\begin_inset Formula $Q_{set}$
\end_inset

, 
\emph default
the upper bound for the degree 
\begin_inset Formula $n$
\end_inset

 of the polynomial modulus 
\begin_inset Formula $N_{max}$
\end_inset

 , the range of values in which the plaintext modulus 
\emph on
t 
\emph default
can vary 
\begin_inset Formula $T_{range}$
\end_inset

 and the desirable level of security 
\begin_inset Formula $\lambda$
\end_inset

; provides the CNN's model 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 encoded with the optimal 
\emph on
n, q 
\emph default
and 
\emph on
t 
\emph default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\widetilde{\varPhi}{}_{n,q,t}=f(\varPhi,D,Y,N_{max},Q_{set},T_{range},\lambda)
\]

\end_inset

Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Transformation"

\end_inset

 shows an approximated CNN 
\begin_inset Formula $\varPhi$
\end_inset

 with 
\emph on
l 
\emph default
layers, where 
\begin_inset Formula $\phi_{\theta_{i}}^{(i)}$
\end_inset

 with 
\begin_inset Formula $i=1,...,l$
\end_inset

 is the function with parameters 
\begin_inset Formula $\theta_{i}$
\end_inset

 computed in the 
\emph on
i-
\emph default
th layer, that receives as input the computation of the previous layer 
\begin_inset Formula $i-1$
\end_inset

.
 Below 
\begin_inset Formula $\varPhi$
\end_inset

 there is 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

, that is the CNN transformed by the function 
\emph on
f
\emph default
 as explained before.
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Img/trs2.pdf
	display false
	scale 60
	clip

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
General structure of a CNN 
\begin_inset Formula $\varPhi$
\end_inset

 and below its transformation in 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 in the encryption world accomplished by function 
\emph on
f.
\emph default

\begin_inset CommandInset label
LatexCommand label
name "fig:Transformation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The function 
\emph on
f
\emph default
 can be modeled by the 
\begin_inset CommandInset ref
LatexCommand nameref
reference "OptimizationProblem1"

\end_inset

 1.The first term of the objective function is the prediction error of the
 encoded CNN 
\begin_inset Formula $\widetilde{\varPhi}$
\end_inset

, that can cause a significant loss in accuracy with respect to the one
 of the original model 
\begin_inset Formula $\varPhi$
\end_inset

.
 There is also the need to find the minimal 
\emph on
n, q
\emph default
 and 
\emph on
t 
\emph default
that preserve the original accuracy of the model in order to introduce the
 smallest possible performance's overhead in terms of memory and computational
 complexities required by the encoded model 
\begin_inset Formula $\widetilde{\varPhi}$
\end_inset

.
 One can set parameters 
\begin_inset Formula $\alpha,\gamma,\delta,\beta$
\end_inset

 depending on its needs and the application field of the CNN.
 For example 
\begin_inset Formula $\alpha$
\end_inset

 can be set to be small if a bigger prediction error is tolerated.
 
\begin_inset Newline newline
\end_inset

These parameters are subject to a number of constraints given by the BFV
 HE scheme that has been previously described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:BFV"

\end_inset

.
\begin_inset Newline newline
\end_inset

In detail, as mentioned before in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

 the plaintext modulus 
\emph on
t 
\emph default
must be smaller than the coefficient modulus 
\emph on
q
\emph default
 (Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:tleq}
\end_layout

\end_inset

) and 
\emph on
q 
\emph default
must be at least two (Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:biggerthan2}
\end_layout

\end_inset

).
 Constraint in Eq.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:infNorm}
\end_layout

\end_inset

 is of crucial importance as written in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

 and requires that the infinity norm of every generic computation in 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 , both internal to a single layer or at the end of it, and thus the encrypted
 polynomial that represent this result, never exceed the plaintext modulus
 
\emph on
t.

\emph default
 Constraint in Eq.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:TOTAL_NBB}
\end_layout

\end_inset

 refers to the one introduced in Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:NOISE_BUDGET"

\end_inset

 and states that the NB in the freshly encrypted image must be sufficiently
 large to support all the operations performed by each layer in 
\begin_inset Formula $\widetilde{\varPhi}$
\end_inset

, thus the NB consumed by each computation that depends itself by the encryption
 parameters selected.
 Constraint in Eq.
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:Q2}
\end_layout

\end_inset

 is referred to the security of the encryption since the total bit count
 of 
\begin_inset Formula $q$
\end_inset

 must be smaller than the upper bound (UB) showed in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 for a given security level 
\begin_inset Formula $\lambda$
\end_inset

 and polynomial modulus degree 
\emph on
n.

\emph default
 The last constraint 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:N}
\end_layout

\end_inset

 states that
\emph on
 n
\emph default
 must be a power of 
\begin_inset Formula $2$
\end_inset

.
\begin_inset Newline newline
\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box ovalbox
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout
Optimization problem 1 
\begin_inset CommandInset label
LatexCommand label
name "OptimizationProblem1"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{align}   
\end_layout

\begin_layout Plain Layout

 &
\backslash
min_{n,q,t} 
\backslash
;    
\end_layout

\begin_layout Plain Layout


\backslash
begin{aligned}[t]     
\end_layout

\begin_layout Plain Layout

  &
\backslash
alpha 
\backslash
sum_i^{D}(y_i-
\backslash
tilde{y_i})^2 + 
\backslash
gamma{t} + 
\backslash
delta{n} + 
\backslash
beta q    
\end_layout

\begin_layout Plain Layout


\backslash
end{aligned} 
\backslash
notag 
\backslash

\backslash
     
\end_layout

\begin_layout Plain Layout

&
\backslash
text{subject to} 
\backslash
notag 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:tleq}  
\end_layout

\begin_layout Plain Layout

& t<q 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:biggerthan2}   
\end_layout

\begin_layout Plain Layout

& q
\backslash
geq 2 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:infNorm}
\end_layout

\begin_layout Plain Layout

& t > 
\backslash
max{||p||_{
\backslash
infty}} 
\backslash
;
\backslash
;
\backslash
text{with } p 
\backslash
in R_t 
\backslash
text{ and generic intermediate result of } 
\backslash
tilde{
\backslash
varPhi}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:TOTAL_NBB}
\end_layout

\begin_layout Plain Layout

& 
\backslash
log_2{(
\backslash
frac{q}{t})} > 
\backslash
sum_{i=1}^lNB_{n,q,t}(
\backslash
phi^{(i)}_{
\backslash
tilde{
\backslash
theta_i}}) 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:Q2}
\end_layout

\begin_layout Plain Layout

& log_2q
\backslash
leq UB(
\backslash
lambda,n)
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:N} 
\end_layout

\begin_layout Plain Layout

& n=2^d 
\backslash
; s.t.
 
\backslash
;d
\backslash
in N  
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

& t,q,n 
\backslash
in 
\backslash
mathbb N 
\backslash
notag 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

& 
\backslash
alpha, 
\backslash
beta, 
\backslash
gamma , 
\backslash
delta 
\backslash
geq 0 
\backslash
notag
\end_layout

\begin_layout Plain Layout


\backslash
end{align}
\end_layout

\end_inset


\end_layout

\end_inset

The real hard problem to solve is the exact calculus of the right term of
 constraint in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:infNorm}
\end_layout

\end_inset

 that is valid for every possible input data.
 Indeed each operation in the model 
\begin_inset Formula $\widetilde{\varPhi}$
\end_inset

 on an input polynomial 
\emph on
p
\emph default
 causes a grow of the initial infinity norm of 
\emph on
p
\emph default
, but since operations are performed homomorphically (i.e., the polynomial
 in input is encoded first as a polynomial in 
\begin_inset Formula $R_{t}$
\end_inset

, as described in Subsection 
\begin_inset CommandInset ref
LatexCommand eqref
reference "subsec:Encoding"

\end_inset

, and then is encrypted as a polynomial in 
\begin_inset Formula $R_{q}$
\end_inset

 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

)), only after decryption is achievable to understand if a reduction modulo
 
\emph on
t 
\emph default
has occurred, since the result is different from the expected one.
 One can observe that it is possible to estimate the grow of such infinity
 norm by considering the specific operation to perform (e.g.
 addition) and considering the shape of the two polynomials in input, before
 to encrypt them.
 However, this approach can be useful only if a very small number of operations
 should be evaluated on the input ciphertext and this is not the case of
 CNNs, because otherwise this estimate would be so rough that no valid plaintext
 modulus 
\emph on
t 
\emph default
would be found, as will be informally explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

.
 Moreover, if it is not possible to find a valid 
\emph on
t
\emph default
, then it is impossible to satisfy the constraint in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:TOTAL_NBB}
\end_layout

\end_inset

.
\begin_inset Newline newline
\end_inset

This leads to the impossibility of writing in a closed form the constraints
 in 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:infNorm}
\end_layout

\end_inset

 and 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:TOTAL_NBB}
\end_layout

\end_inset

 and suggests the need to find an alternative solution for the problem that
 function 
\emph on
f 
\emph default
should solve
\emph on
.
\end_layout

\begin_layout Section
Heuristic: Binary Search Of Plaintext Modulus 
\begin_inset CommandInset label
LatexCommand label
name "sec:Heuristic:-Binary-Search"

\end_inset


\end_layout

\begin_layout Standard
The idea is to implement a heuristic method able to find a suboptimal plaintext
 modulus 
\emph on

\begin_inset Formula $\tilde{t}$
\end_inset

, 
\emph default
that approximates the optimal 
\emph on
t 
\emph default
with a certain error 
\begin_inset Formula $\epsilon$
\end_inset

.
 
\begin_inset Newline newline
\end_inset

The heuristic is a sort of binary search that gets as inputs: the model
 
\begin_inset Formula $\varPhi$
\end_inset

, a number of 
\begin_inset Formula $K\subseteq|D|$
\end_inset

 images to test, where 
\emph on
D 
\emph default
is the entire test set, an ordered list 
\begin_inset Formula $t_{list}$
\end_inset

 of possible plaintext moduli 
\emph on
t
\emph default
 with two indexes pointing to the minimum and maximum value of that list,
 a security parameter 
\begin_inset Formula $\lambda$
\end_inset

 and a tentative starting big coefficient modulus 
\begin_inset Formula $q_{0}$
\end_inset

.
 It recursively tests the number in the middle of the two boundaries as
 
\emph on
t
\emph default
.
 By testing, it is intended the execution on the CNN's model 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 of the forward phase on 
\emph on
K 
\emph default
images sampled uniformly from the dataset 
\emph on
D 
\emph default
as showed by the pseudocode 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Test-plaintext-modulus"

\end_inset

.
 If the testing for a given 
\emph on
t 
\emph default
is successful, that is
\emph on
 
\begin_inset Formula $\tilde{y_{i}}=y_{i}$
\end_inset

 
\emph default
foreach 
\begin_inset Formula $i=0,...,K$
\end_inset

, where 
\begin_inset Formula $\tilde{y_{i}}$
\end_inset

 is the decrypted prediction given by the encoded
\emph on
 
\emph default
CNN 
\begin_inset Formula $\widetilde{\varPhi}{}_{n,q,t}$
\end_inset

 for image 
\emph on
i
\emph default
 (i.e., 
\begin_inset Formula $\tilde{y_{i}}=Dec(\tilde{\varPhi}_{n,t,q}(Enc(I_{i})))$
\end_inset

) and 
\begin_inset Formula $y_{i}$
\end_inset

 is the prediction of the plain CNN 
\begin_inset Formula $\varPhi$
\end_inset

 for the same input image 
\emph on
i
\emph default
 or if the starting NB in the ciphertext is not sufficient to carry out
 the entire computation util the final layer,
\emph on
 
\emph default
the search continues on the left interval, to find if it exists, a smaller
 plaintext modulus.
 This is done because if the testing is successful the heuristic wants to
 find the smallest possible 
\emph on
t, 
\emph default
while if the noise budget is insufficient, by decreasing 
\emph on
t 
\emph default
the noise budget is increased (see Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:NOISE_BUDGET"

\end_inset

).
 Instead, if exists an image 
\emph on
i
\emph default
 such that 
\emph on

\begin_inset Formula $\tilde{y_{i}}\neq y_{i}$
\end_inset


\emph default
, i.
 e., there is a misprediction with respect to the original CNN 
\begin_inset Formula $\varPhi$
\end_inset

, the search continues on the right interval.
 Note that if the search is performed only on the powers of two, i.e.
 
\begin_inset Formula $t_{list}=[2,2^{2},2^{3}..,2^{59}]$
\end_inset

, for the formula of the NB Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:NOISE_BUDGET"

\end_inset

, the initial amount of NB changes significantly between different runs
 of the binary search, while if the search is carried on all integers i.e.,
 
\begin_inset Formula $t_{list}=[2,3,4..,2^{59}]$
\end_inset

 the difference in NB between successive runs of the algorithm is not really
 significant.
 Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Plain-Modulus-Binary"

\end_inset

 shows the pseudocode of the described binary search, while Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Test-plaintext-modulus"

\end_inset

 describes in detail how the testing is performed.
 
\begin_inset Newline newline
\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
Require{Model $
\backslash
varPhi$, sorted list $t_{list}$ of possible plain modulus $t$, five integers
 $t_{min}$ and $t_{max}$ s.t.
 $T_{range}=[t_{list}[t_{min}],t_{list}[t_{max}]]$, secuity level $
\backslash
lambda$, given upper bound for the coefficient modulus $q_0$, number of
 $K$ images to test} 
\backslash
Ensure{Plain modulus $
\backslash
tilde{t}$ or NOT
\backslash
_FOUND
\backslash
_T }
\end_layout

\begin_layout Plain Layout


\backslash
Function{search
\backslash
_t}{$
\backslash
varPhi,t_{list},t_{min},t_{max},
\backslash
lambda,q_0,K$}
\end_layout

\begin_layout Plain Layout

	
\backslash
If{$t_{max}-t_{min}=1$} 
\backslash
Comment{Base Case}
\end_layout

\begin_layout Plain Layout

    	
\backslash
State{$test
\backslash
gets$ TEST
\backslash
_PLAIN
\backslash
_MOD($
\backslash
varPhi,t_{list}[t_{min}],
\backslash
lambda,q_0,K$)}
\end_layout

\begin_layout Plain Layout

    	
\backslash
If{$test$=SUCCESS}
\end_layout

\begin_layout Plain Layout

        	
\backslash
State{
\backslash
Return{$t_{list}[t_{min}]$}}
\end_layout

\begin_layout Plain Layout

        
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

        
\backslash
If{$test$=OUT
\backslash
_OF
\backslash
_BUDGET}
\end_layout

\begin_layout Plain Layout

        	
\backslash
State{
\backslash
Return{NOT
\backslash
_FOUND
\backslash
_T}}
\end_layout

\begin_layout Plain Layout

        
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

        
\backslash
If{TEST
\backslash
_PLAIN
\backslash
_MOD($
\backslash
varPhi,t_{list}[t_{max}],
\backslash
lambda,q_0,K$)=SUCCESS}
\end_layout

\begin_layout Plain Layout

        	
\backslash
State{
\backslash
Return{$t_{list}[t_{max}]$}}
\end_layout

\begin_layout Plain Layout

        
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

        
\backslash
State{
\backslash
Return{NOT
\backslash
_FOUND
\backslash
_T}}
\end_layout

\begin_layout Plain Layout

    
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

    
\backslash
State{$t_{index}
\backslash
gets t_{min}+(t_{max}-t_{min})/2$}
\end_layout

\begin_layout Plain Layout

    
\backslash
State{$test
\backslash
gets$ TEST
\backslash
_PLAIN
\backslash
_MOD($
\backslash
varPhi,t_{list}[t_{index}],
\backslash
lambda,q_0,K$)}
\end_layout

\begin_layout Plain Layout

    
\backslash
If{$test$=SUCCESS or $test$=OUT
\backslash
_OF
\backslash
_BUDGET} 
\backslash
Comment{Go Left}
\end_layout

\begin_layout Plain Layout

    	
\backslash
State{$t_{smaller}
\backslash
gets$ SEARCH
\backslash
_T($
\backslash
varPhi,t_{list},t_{min},t_{max}-1,
\backslash
lambda,q_0,K$)}
\end_layout

\begin_layout Plain Layout

       	
\backslash
If{$t_{smaller}>0$} 
\backslash
Comment{smaller p
\backslash
_mod found}
\end_layout

\begin_layout Plain Layout

    		
\backslash
State{
\backslash
Return{$t_{smaller}$}}
\end_layout

\begin_layout Plain Layout

     	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

     	
\backslash
If{$test$=SUCCESS}
\backslash
Comment{smaller p
\backslash
_mod not found, prev ok}
\end_layout

\begin_layout Plain Layout

    		
\backslash
State{
\backslash
Return{$t_{list}[t_{index}]$}}
\end_layout

\begin_layout Plain Layout

     	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

     
\backslash
State{
\backslash
Return{NOT
\backslash
_FOUND
\backslash
_T
\backslash
Comment{smaller p
\backslash
_mod not found, prev not ok}}}
\end_layout

\begin_layout Plain Layout

     
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

     
\backslash
If{$t_{index}
\backslash
geq t_{max}$} 
\backslash
Comment{p
\backslash
_mod needed $
\backslash
notin T_{range}$ }
\end_layout

\begin_layout Plain Layout

     	
\backslash
State{
\backslash
Return{NOT
\backslash
_FOUND
\backslash
_T}}
\end_layout

\begin_layout Plain Layout

      
\backslash
EndIf
\end_layout

\begin_layout Plain Layout

    
\backslash
State{
\backslash
Return{SEARCH
\backslash
_T($
\backslash
varPhi,t_{list},t_{min}+1,t_{max},
\backslash
lambda,q_0,K$)}} 
\backslash
Comment{Go Right}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Plaintext Modulus Binary Search
\begin_inset CommandInset label
LatexCommand label
name "alg:Plain-Modulus-Binary"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
algdef{SE}[VARIABLES]{Variables}{EndVariables}    {
\backslash
algorithmicvariables}    {
\backslash
algorithmicend
\backslash
 
\backslash
algorithmicvariables} 
\backslash
algnewcommand{
\backslash
algorithmicvariables}{
\backslash
textbf{global variables}} 
\end_layout

\begin_layout Plain Layout


\backslash
algblock[TryCatchFinally]{try}{endtry} 
\backslash
algcblockdefx[TryCatchFinally]{TryCatchFinally}{catch}{endtry} 	[1]{
\backslash
textbf{catch} #1} 	{
\backslash
textbf{end try}}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\end_layout

\begin_layout Plain Layout


\backslash
Variables
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$Y$} 
\backslash
Comment{predicions given by model $
\backslash
varPhi$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$D$} 
\backslash
Comment{dataset}
\end_layout

\begin_layout Plain Layout


\backslash
EndVariables
\end_layout

\begin_layout Plain Layout


\backslash
Require{Model $
\backslash
varPhi$, four integers plain modulus to test $t_{test}$, secuity level $
\backslash
lambda$, upper bound for the coefficient modulus $q_0$, number of $K$ images
 to test} 
\end_layout

\begin_layout Plain Layout


\backslash
Ensure{SUCCESS, OUT
\backslash
_OF
\backslash
_BUDGET or MISPREDICTED}
\end_layout

\begin_layout Plain Layout


\backslash
Function{test
\backslash
_plain
\backslash
_mod}{$
\backslash
varPhi,t_{test},
\backslash
lambda,q_0,K$}
\end_layout

\begin_layout Plain Layout


\backslash
State{$t 
\backslash
gets t_{test}$}  
\backslash
Comment{set encryption parameters}
\end_layout

\begin_layout Plain Layout


\backslash
State{$q 
\backslash
gets q_0$}
\end_layout

\begin_layout Plain Layout


\backslash
State{$n 
\backslash
gets 
\backslash
lambda(q_0)$}
\end_layout

\begin_layout Plain Layout


\backslash
State{$sk 
\backslash
gets$ GEN
\backslash
_SEC
\backslash
_KEY($n,q,t$)}
\end_layout

\begin_layout Plain Layout


\backslash
State{$pk 
\backslash
gets$ GEN
\backslash
_PUB
\backslash
_KEY($sk$)}
\end_layout

\begin_layout Plain Layout


\backslash
State{$
\backslash
tilde{
\backslash
varPhi} 
\backslash
gets$ ENCODE($
\backslash
varPhi,n,t$)} 
\backslash
Comment{Transform each $
\backslash
theta_i$ in $
\backslash
tilde{
\backslash
theta_i}$}
\end_layout

\begin_layout Plain Layout


\backslash
For{$i 
\backslash
gets 0
\backslash
;{
\backslash
bf to }
\backslash
; K$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$I 
\backslash
gets$ RANDOMLY
\backslash
_SAMPLE
\backslash
_AT
\backslash
_UNIFORM($D$)}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$Enc(I) 
\backslash
gets$ ENCRYPT(ENCODE($I,n,t),pk$)} 
\end_layout

\begin_layout Plain Layout

	
\backslash
try
\end_layout

\begin_layout Plain Layout

		
\backslash
State{$Enc(y_i)
\backslash
gets$ $
\backslash
tilde{
\backslash
varPhi}(Enc(I))$)} 
\backslash
Comment{Forward}
\end_layout

\begin_layout Plain Layout

    
\backslash
catch{Out
\backslash
_Of
\backslash
_Budget
\backslash
_Exception}   
\end_layout

\begin_layout Plain Layout

		 
\backslash
State{
\backslash
Return{OUT
\backslash
_OF
\backslash
_BUDGET} }
\end_layout

\begin_layout Plain Layout


\backslash
endtry
\end_layout

\begin_layout Plain Layout

	
\backslash
State{$
\backslash
tilde{y_i} 
\backslash
gets$ DECRYPT($Enc(y_i),sk$)}
\end_layout

\begin_layout Plain Layout

	
\backslash
If{$
\backslash
tilde{y_i} 
\backslash
neq y_i$}
\end_layout

\begin_layout Plain Layout

	
\backslash
State{
\backslash
Return{MISPREDICTED}}
\end_layout

\begin_layout Plain Layout

	
\backslash
EndIf
\end_layout

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\begin_layout Plain Layout


\backslash
State{
\backslash
Return{SUCCESS}}
\end_layout

\begin_layout Plain Layout


\backslash
EndFunction
\end_layout

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Test plaintext modulus 
\begin_inset CommandInset label
LatexCommand label
name "alg:Test-plaintext-modulus"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Plain-Modulus-Binary"

\end_inset

 is able to find a parameter 
\emph on

\begin_inset Formula $\tilde{t}$
\end_inset


\emph default
 for every given CNN in input if a subdivision as in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-Search-Cases"

\end_inset

 (a) is possible for the numbers in the given range.
 The found 
\emph on

\begin_inset Formula $\tilde{t}$
\end_inset

 
\emph default
lies in the 
\noun on
success 
\noun default
interval and tends to be as close as possible to the optimal 
\emph on
t.

\emph default
 The case of Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-Search-Cases"

\end_inset

 (b) instead, shows the worst scenario where is not found any valid 
\emph on

\begin_inset Formula $\tilde{t}$
\end_inset


\emph default
 .
 The only possible solution is to increase the stating 
\begin_inset Formula $q_{0}$
\end_inset

, so to reduce the 
\noun on
out of budget interval 
\noun default
and run again the binary search, to bring back to case (a).
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename Img/bsok.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(a) Optimal case
\end_layout

\begin_layout Plain Layout
\noindent
\align left
\begin_inset Graphics
	filename Img/bsko.pdf

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
(b) Worst case
\end_layout

\begin_layout Plain Layout
\paragraph_spacing double
\begin_inset Caption Standard

\begin_layout Plain Layout
Binary Search Cases
\begin_inset CommandInset label
LatexCommand label
name "fig:Binary-Search-Cases"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Practical Considerations About The Proposed Methodology
\begin_inset CommandInset label
LatexCommand label
name "chap:Practical-Methodology"

\end_inset


\end_layout

\begin_layout Standard
In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

 the encryption parameters with their relationships have been described
 form a theoretical point of view depending on the underling BFV scheme
 that has been considered.
\begin_inset Newline newline
\end_inset

In Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-Encryption-Parameters"

\end_inset

 of this Chapter these parameters will be considered with respect to the
 practical implementation of the BFV scheme given by the Simple Encryption
 Arithmetic Library (SEAL 2.3.1) (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SEAL"

\end_inset

).
 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "SEAL"
description "Simple Encrypted Arithmetic Library"

\end_inset

 Moreover, in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-optimization-problem"

\end_inset

, the parameters estimation problem presented in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Optimization-Problem"

\end_inset

 will be revisited according to the other constraints imposed by the practical
 application of the BFV HE scheme.
\end_layout

\begin_layout Section
Simple Encrypted Arithmetic Library (SEAL 2.3.1) 
\begin_inset CommandInset label
LatexCommand label
name "sec:SEAL"

\end_inset


\end_layout

\begin_layout Standard
The Simple Encrypted Arithmetic Library is written in the C++ language and
 implements the BFV encryption scheme by offering primitives to handle operation
s, encryption and decryption procedures.
 However, the library differs in some aspects form the original BFV scheme.
 Indeed the bootstrapping operation (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-and-Noise"

\end_inset

) is not implemented, for this reason the number of operations that is possible
 to perform on a ciphertext is not unlimited as in a Fully HE scheme but
 it depends on the encryption parameters chosen as in a Somewhat HE scheme.
 Moreover in SEAL, the compactness property (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Classification-of-Homomorphic"

\end_inset

) is lost since ciphertexts can be of arbitrary length (at least two) and
 not of fixed length as in the original BFV scheme.
 SIMD techniques to perform batching and operations ciphertext-plaintext
 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-with-plaintext"

\end_inset

) are allowed.
 Finally there are some constraints on the encryption parameters as described
 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-Encryption-Parameters"

\end_inset

.
\end_layout

\begin_layout Section
Practical Encryption Parameters
\begin_inset CommandInset label
LatexCommand label
name "sec:Practical-Encryption-Parameters"

\end_inset


\end_layout

\begin_layout Standard
The 
\series bold
plaintext modulus 
\emph on
t
\series default
 
\emph default
in SEAL can be any positive integer at least 2 and at most 60 bits length,
 thus 
\begin_inset Formula $2\leq t\leq2^{59}$
\end_inset

.
 
\begin_inset Newline newline
\end_inset

In the 
\series bold
polynomial modulus
\series default
 
\begin_inset Formula $(x^{n}+1)$
\end_inset


\emph on
, 
\series bold
n
\series default
\emph default
 is a power of 2 as described before.
 
\begin_inset Newline newline
\end_inset

For performance reasons in SEAL the
\series bold
 coefficient modulus 
\emph on
q
\series default
 
\emph default
is a product of multiple small primes 
\begin_inset Formula $q_{1}\times...\times q_{k}$
\end_inset

 , even if taking these 
\begin_inset Formula $q_{k}$
\end_inset

 to be of special form does not provide any additional performance improvement.
 Therefore, it is possible to choose a set of arbitrary primes regarding
 their requirements as long as they are at most 60-bits long and 
\begin_inset Formula $q_{i}=1\;(mod\;2n)\;\text{for }i\in\{1,2,...,k\}$
\end_inset

.
 For this reason the bit length of 
\emph on
q 
\emph default
as referred in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 is equal to 
\series bold

\begin_inset Formula ${\normalcolor \sum_{i=1}^{k}log_{2}(q_{i})}$
\end_inset

.
 
\series default
These parameters are listed in the Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:SEALnotation"

\end_inset


\series bold
.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\paragraph_spacing double
\begin_inset Caption Standard

\begin_layout Plain Layout
Notation used in SEAL 
\begin_inset CommandInset label
LatexCommand label
name "tab:SEALnotation"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top" width="7cm">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size footnotesize
Parameter
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size footnotesize
Description
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size footnotesize
Name in SEAL
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
q
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
Modulus in the ciphertext space of the form q1 × ...
 × qk, where qi are prime
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family sans
\size footnotesize
coeff_modulus
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
t
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
Modulus in the plaintext space
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\family sans
\size footnotesize
plain_modulus
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
n
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size footnotesize
A power of 2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Practical Optimization Problem 
\begin_inset CommandInset label
LatexCommand label
name "sec:Practical-optimization-problem"

\end_inset


\end_layout

\begin_layout Standard
The 
\begin_inset CommandInset ref
LatexCommand nameref
reference "OptimizationProblem1"

\end_inset

 1 presented in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Optimization-Problem"

\end_inset

 must be changed according to the new and more detailed description of the
 parameters of Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-Encryption-Parameters"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

The new formulation is given in Optimization Problem 2.
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box ovalbox
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout
Optimization Problem 2 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{align}   
\end_layout

\begin_layout Plain Layout

 &
\backslash
min_{n,q,t} 
\backslash
;    
\end_layout

\begin_layout Plain Layout


\backslash
begin{aligned}[t]     
\end_layout

\begin_layout Plain Layout

  &
\backslash
alpha 
\backslash
sum_i^{D}(y_i-
\backslash
tilde{y_i})^2 + 
\backslash
gamma{t} + 
\backslash
delta{n} + 
\backslash
beta q    
\end_layout

\begin_layout Plain Layout


\backslash
end{aligned} 
\backslash
notag 
\backslash

\backslash
     
\end_layout

\begin_layout Plain Layout

&
\backslash
text{subject to} 
\backslash
notag 
\backslash

\backslash
    
\end_layout

\begin_layout Plain Layout

& t<q 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout

& q
\backslash
geq 2 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:between}  
\end_layout

\begin_layout Plain Layout

& 2
\backslash
leq t 
\backslash
leq 2^{59} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:infinityNorm}
\end_layout

\begin_layout Plain Layout

& t > 
\backslash
max{||p||_{
\backslash
infty}} 
\backslash
;
\backslash
;
\backslash
text{with } p 
\backslash
in R_t 
\backslash
text{ and generic intermediate result of } 
\backslash
tilde{
\backslash
varPhi}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:TOTAL_NB}
\end_layout

\begin_layout Plain Layout

& 
\backslash
log_2{(
\backslash
frac{q}{t})} > 
\backslash
sum_{i=1}^lNB_{n,q,t}(
\backslash
phi^{(i)}_{
\backslash
tilde{
\backslash
theta_i}}) 
\backslash

\backslash
 
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:q1} 
\end_layout

\begin_layout Plain Layout

& q=
\backslash
prod_{i=1}^k q_i
\backslash
; s.t.
 
\backslash
; q_i= 1
\backslash
:(mod
\backslash
,2n)
\backslash
; 
\backslash
textmd{and}
\backslash
; q_i 
\backslash
; 
\backslash
text{prime} 
\backslash
;
\backslash
forall{i=1,...,k}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:q2}
\end_layout

\begin_layout Plain Layout

& 
\backslash
sum_{i=1}^k
\backslash
log_2q_i
\backslash
leq UB(
\backslash
lambda,n)
\backslash

\backslash
   
\end_layout

\begin_layout Plain Layout


\backslash
label{eq:n} 
\end_layout

\begin_layout Plain Layout

& n=2^d 
\backslash
; s.t.
 
\backslash
;d
\backslash
in N 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
label{eq:d} 
\end_layout

\begin_layout Plain Layout

&d
\backslash
geq 10
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

& t,q,n 
\backslash
in 
\backslash
mathbb N 
\backslash
notag 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

& 
\backslash
alpha, 
\backslash
beta, 
\backslash
gamma, 
\backslash
delta 
\backslash
geq 0 
\backslash
notag
\end_layout

\begin_layout Plain Layout


\backslash
end{align}
\end_layout

\end_inset


\end_layout

\end_inset

These practical parameters are subject to a number of additional constraints
 given by the practical implementation of the BFV HE scheme 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

In detail, as mentioned before in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-Encryption-Parameters"

\end_inset

 the plaintext modulus 
\emph on
t 
\emph default
is constrained to be an integer number between 
\begin_inset Formula $2$
\end_inset

 and 
\begin_inset Formula $2^{59}$
\end_inset

 (Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:between}
\end_layout

\end_inset

 ).
 Constraint in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:q1}
\end_layout

\end_inset

 refers to the practical shape of 
\emph on
q 
\emph default
to implement efficient modular arithmetic and to use David Harvey’s algorithm
 for Number-Theoretic Transform (NTT) 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "NTT"
description "Number-Theoretic Transform"

\end_inset

 as described in 
\begin_inset CommandInset citation
LatexCommand cite
key "DBLP:journals/corr/abs-1205-2926"

\end_inset

.
 Constraint in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:q2}
\end_layout

\end_inset

 is changed with respect to the one in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:Q2}
\end_layout

\end_inset

 according to the the redefined shape of 
\emph on
q, 
\emph default
which length is now given by the sum of the bits of each 
\begin_inset Formula $q_{k}$
\end_inset

 that compose 
\emph on
q.

\emph default
 Constraint in Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:d}
\end_layout

\end_inset

 is given to have a degree 
\emph on
n 
\emph default
of the polynomial modulus of at least 
\begin_inset Formula $1024$
\end_inset

, in order to have a correspondent upper bound of bits of 
\emph on
q 
\emph default
(see Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

) that allow to have a starting NB greater than zero for at least some plaintext
 moduli 
\emph on
t.

\emph default
 
\end_layout

\begin_layout Chapter
CrCNN:A CNN Library Based On Homomorphic Encryption
\begin_inset CommandInset label
LatexCommand label
name "chap:CrCNN:A-CNN-Library"

\end_inset


\end_layout

\begin_layout Standard
This Chapter will focus on the description of the developed Crypto Convolutional
 Neural Network (CrCNN) library 
\begin_inset CommandInset citation
LatexCommand cite
key "CrCNN"

\end_inset

.
 This library is the first example of tool that allows to build CNNs able
 to make predictions homomorphically over encrypted images.
 Indeed, even if in literature (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Single-Data-Provider"

\end_inset

) there is an example of implementation of a CNN that makes prediction on
 HE data 
\begin_inset CommandInset citation
LatexCommand cite
key "cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy"

\end_inset

, no one until now has released a tool that gives the possibility to reproduce,
 at least conceptually, this kind of result.
 The purpose of this library is to provide the building blocks to make experimen
ts regarding the application of the HE to the field of Deep Learning, in
 particular on the CNNs.
 
\begin_inset Newline newline
\end_inset

The CNN's layers provided by this library will be presented in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Structure"

\end_inset

.
 CrCNN satisfies these two main requirements:
\end_layout

\begin_layout Description
Requirement
\begin_inset space ~
\end_inset

1 Import the pre-trained model of a CNN and encode it (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

).
\end_layout

\begin_layout Description
Requirement
\begin_inset space ~
\end_inset

2 Make predictions using the encoded CNN over encrypted data.
\end_layout

\begin_layout Section
Structure And Main Functionalities 
\begin_inset CommandInset label
LatexCommand label
name "sec:Structure"

\end_inset


\end_layout

\begin_layout Standard
The CrCNN is a library written in the C++ language and built on top of SEAL
 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SEAL"

\end_inset

).
 SEAL can be considered as the "assembly" language of this library since
 it provides all the primitives to perform calculi on encrypted data.
 The library mainly leverages the datatypes presented in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab: datatypes"

\end_inset

.
 
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\paragraph_spacing onehalf
\begin_inset Caption Standard

\begin_layout Plain Layout
Main datatypes of CrCNN 
\begin_inset CommandInset label
LatexCommand label
name "tab: datatypes"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Datatype
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Description
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{Ciphertext}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
 a SEAL (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SEAL"

\end_inset

) 
\begin_inset Formula $\mathsf{\mathtt{Ciphertext}}$
\end_inset

 object 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{Plaintext}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
a SEAL (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SEAL"

\end_inset

) 
\begin_inset Formula $\mathsf{\mathtt{Plaintext}}$
\end_inset

 object 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{ciphertext3D}}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
 cube of 
\begin_inset Formula $\mathsf{\mathtt{Ciphertext}}$
\end_inset

 objects
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{ciphertext2D}}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
two dimensional matrix of 
\begin_inset Formula $\mathsf{\mathtt{Ciphertext}}$
\end_inset

 objects
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathtt{\mathsf{\mathtt{plaintext4D}}}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
four dimensional matrix of 
\begin_inset Formula $\mathsf{\mathtt{Plaintext}}$
\end_inset

 objects
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{plaintext2D}}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
two dimensional matrix of 
\begin_inset Formula $\mathsf{\mathtt{Plaintext}}$
\end_inset

 objects
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mathsf{\mathtt{floatCube}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
 cube of floats
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\series bold
Requirement 1
\series default
 is implemented by the 
\begin_inset Formula $\mathtt{CnnBuilder}$
\end_inset

 class that leverages the 
\emph on
Builder design pattern
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "gamma1994design"

\end_inset

.
 CrCNN implements most of CNN layers that are allowed under HE constraints
 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximations-For-HE"

\end_inset

).
 These layers allow to accomplish 
\series bold
Requirement 2.
\end_layout

\begin_layout Paragraph*
\begin_inset Formula $\mathtt{Layer}$
\end_inset

s 
\end_layout

\begin_layout Standard
The abstract class 
\begin_inset Formula $\mathtt{Layer}$
\end_inset

 include some of the methods that each derived class must implement, among
 which the most important one is the 
\begin_inset Formula $\mathtt{forward}$
\end_inset

 method that allows to perform the different operations according to the
 layer in order to compute the predicted class of an input 
\begin_inset Formula $\mathtt{ciphertext3D}$
\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UML"

\end_inset

 shows which are the implemented layers.
 For the most computationally intensive layers (i.e., 
\begin_inset Formula $\mathtt{Convolutional,Fully}$
\end_inset

 
\begin_inset Formula $\mathtt{Connected\;\text{and }Square}$
\end_inset

 
\begin_inset Formula $\mathtt{Layer}$
\end_inset

) there is the possibility to run the 
\begin_inset Formula $\mathtt{forward}$
\end_inset

 by splitting the computational load between different 
\begin_inset Formula $\mathtt{threads}$
\end_inset

, as showed by Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UML"

\end_inset

.
 
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Img/Layers.pdf
	display false
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
UML of Layers' inheritance structure 
\begin_inset CommandInset label
LatexCommand label
name "fig:UML"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

 The division operation is implemented as a multiplication for the inverse
 of the divisor.
 The only difference between the 
\begin_inset Formula $\mathtt{PoolingLayer}$
\end_inset

 and is derived class 
\begin_inset Formula $\mathtt{AvgPoolingLayer}$
\end_inset

 is that in the former the pooling operation is 
\begin_inset Formula $f(x)=\sum_{i=1}^{N}x_{i}$
\end_inset

 while in the latter 
\begin_inset Formula $f_{avg}(x)=\frac{1}{N}\sum_{i=1}^{N}x_{i}$
\end_inset

, where 
\begin_inset Formula $x$
\end_inset

 is the ciphertext value from a local pooling region and N is the 
\begin_inset Formula $\mathtt{filterSize}$
\end_inset

.
 If one wants to reduce the number of multiplications executed in the CNN
 and accepts a more rude computation one must select the 
\begin_inset Formula $\mathtt{PoolingLayer}$
\end_inset

, otherwise the 
\begin_inset Formula $\mathtt{AvgPoolingLayer}$
\end_inset

 should be used.
\end_layout

\begin_layout Paragraph*
\begin_inset Formula $\mathtt{\mathtt{CnnBuilder}}$
\end_inset

 
\end_layout

\begin_layout Standard
is the class responsible for encoding (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) a pre-trained CNN.
 Given the file of the pre-trained model and the structure of the network,
 this class is able to transform each weight of the original model (i.e.,
 of float type) into a Plaintext object and thus to initialize each layer
 in the network.
 The only requirement is that the saved network has a 
\begin_inset Formula $\mathtt{<key,value>}$
\end_inset

 structure where each 
\begin_inset Formula $\mathtt{key}$
\end_inset

 represents the 
\begin_inset Formula $\mathtt{name}$
\end_inset

 of the layer and the 
\begin_inset Formula $\mathtt{value}$
\end_inset

 contains the weights to encode.
 By using the 
\begin_inset Formula $\mathtt{save/loadPlaintextParameters}$
\end_inset

 methods implemented by each layer, the 
\begin_inset Formula $\mathtt{CnnBuilder}$
\end_inset

 is also able to write and read a previously encoded CNN.
 It supports the import of a PyTorch CNN's model.
\end_layout

\begin_layout Paragraph*
\begin_inset Formula $\mathtt{Globals}$
\end_inset

 
\end_layout

\begin_layout Standard
is a set of functions that contains all the routines for the encryption
 and decryption of the images and for the setting of the encryption 
\emph on
context
\emph default
 (i.e., parameters and keys).
 It is mandatory to set such a context before calling any function related
 to the CrCNN library.
 This list collects some of the functions of 
\begin_inset Formula $\mathtt{Globals}$
\end_inset

:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathtt{\mathsf{\mathtt{ciphertext3D\;encryptImage(vector<float>image,int\;zd,int\;}}}$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $\mathtt{xd,int\;yd)}$
\end_inset

: this function encrypts an image stored as a vector of floats and returns
 a reshaped encrypted image of dimensions 
\begin_inset Formula $\mathtt{xd\times yd\times zd}$
\end_inset

.
 In practice, a pixel (i.e., a slot of the input vector) is first encoded
 as a polynomial and then transformed into a 
\begin_inset Formula $\mathsf{\mathtt{Ciphertext}}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathsf{\mathtt{ciphertext3D\;encryptAndSaveImage(vector<float>image,int\;}}$
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Formula $\mathtt{zd,int\;xd,int\;yd,string\;file_{-}name)}$
\end_inset

: this function performs the same task of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathtt{encryptImage}$
\end_inset

, but it also saves the encrypted image in
\begin_inset Newline newline
\end_inset

 
\begin_inset Formula $\mathtt{file_{-}name}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathtt{ciphertext3D\;loadEncryptedImage(int\;zd,int\;xd,int\;yd,}$
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Formula $\mathtt{string\;file_{-}name)}$
\end_inset

: this function loads a previously encrypted and saved image into a 
\begin_inset Formula $\mathtt{ciphertext3D}$
\end_inset

 of dimensions 
\begin_inset Formula $\mathtt{xd\times yd\times zd}.$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathsf{\mathtt{floatCube\;decryptImage(ciphertext3D\;encrypted_{-}image)}}$
\end_inset

: this function decrypts an then decode (i.e.
 transforms a polynomial into a number) an 
\begin_inset Formula $\mathtt{encrypted_{-}image}$
\end_inset

 and then stores it into a cube of floats of the same dimensions of the
 
\begin_inset Formula $\mathtt{ciphertext3D}$
\end_inset

 in input.
\end_layout

\begin_layout Chapter
Experimental Results
\begin_inset CommandInset label
LatexCommand label
name "chap:Experimental-Results"

\end_inset


\end_layout

\begin_layout Standard
This Chapter focuses on the practical conversion of a plain pre-trained
 CNN in a network able to make predictions on encrypted images.
 
\begin_inset Newline newline
\end_inset

The goal of this Chapter is to show how it is possible to implement the
 methodology proposed in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Methodology"

\end_inset

, considering also the aspect introduced in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Practical-Methodology"

\end_inset

, and to display the associated results by computing the metrics reported
 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

.
 In particular two case studies that consider two different CNNs, trained
 on the same MNIST dataset (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:MNIST-Dataset"

\end_inset

) will be reported.
 In practice Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

 focuses on a 9-layers CNN, while Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-2"

\end_inset

 focuses on a smaller 6-layers CNN.
 For each case study, the metamorphosis of the starting plain CNN along
 all the steps described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

 and reported in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximation-steps-CNN"

\end_inset

 will be followed and the loss of accuracy caused by this procedure will
 be tracked.
 
\begin_inset Newline newline
\end_inset

The heuristic proposed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic:-Binary-Search"

\end_inset

 will be tested and compared with other methodologies (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

) and, for case study 1 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

, the algorithm will be examined considering its speed to converge to a
 reliable result (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Binary-Search-Results"

\end_inset

).
 
\begin_inset Newline newline
\end_inset

The performances of the CrCNN library described in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:CrCNN:A-CNN-Library"

\end_inset

 will be reported.
\end_layout

\begin_layout Section
Experimental Setup
\end_layout

\begin_layout Standard
All the experiments reported in this Chapter have been executed on a 40-cores
 Intel Xeon CPU E5-2640 @ 2.40GHz with 128GB of RAM DIMM Synchronous @ 2400MHz.
 SEAL 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

 and CrCNN (see Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:CrCNN:A-CNN-Library"

\end_inset

) libraries have been compiled with gcc-6.4.0 and executed on Ubuntu 16.04
 with kernel version 4.4.0.
\begin_inset Newline newline
\end_inset

PyTorch library 
\begin_inset CommandInset citation
LatexCommand cite
key "pytorch"

\end_inset

 has been used for the trainings of the starting CNNs 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 in both case studies (Sections 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-2"

\end_inset

) and the approximated CNN 
\begin_inset Formula $\varPhi$
\end_inset

 in case study 1 (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:STEP-1"

\end_inset

).
\end_layout

\begin_layout Section
MNIST Dataset 
\begin_inset CommandInset label
LatexCommand label
name "sec:MNIST-Dataset"

\end_inset


\end_layout

\begin_layout Standard
The Modified National Institute of Standards and Technology (MNIST) dataset
 
\begin_inset CommandInset citation
LatexCommand cite
key "MNIST"

\end_inset

 is a large dataset of handwritten digits images.
 It is a combination of two of NIST's databases: Special Database 1 and
 Special Database 3.
 The former consist of digits written by high school students and the latter
 consists of digits written by employees of the United States Census Bureau.
 The original NIST's dataset has been mixed, and thus modified, because
 the creators felt that since NIST's training dataset was taken from American
 Census Bureau employees, while the testing dataset was taken from American
 high school students, it was not well-suited for machine learning experiments.
 Furthermore, the black and white images from NIST has been normalized to
 fit into a 
\begin_inset Formula $28\times28$
\end_inset

 pixel bounding box and anti-aliased.
 The anti-aliasing has introduced grayscale levels.
 The MNIST database is commonly used for training and testing various machine
 learning algorithms and it contains 60000 training images and 10000 testing
 images.
 In all the reported experiments the MNIST dataset has been normalized,
 by first dividing each pixel for 255, then subtracting the mean and finally
 by dividing for the images standard deviation.
 
\end_layout

\begin_layout Section
Heuristic comparisons and metrics
\begin_inset CommandInset label
LatexCommand label
name "sec:Heuristic-metrics"

\end_inset


\end_layout

\begin_layout Standard
The Binary Search Heuristic described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic:-Binary-Search"

\end_inset

 is essentially used to find the best plaintext modulus parameter 
\emph on
t
\emph default
, given in input a certain polynomial modulus degree 
\emph on
n
\emph default
, a ciphertext modulus 
\emph on
q 
\emph default
and a set of images to test
\emph on
.
 
\emph default
Additionally to what explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic:-Binary-Search"

\end_inset

, it is possible to set a 
\emph on
maximum number of re-encryption steps
\emph default
 that one can accept to perform during the forward phase as input of the
 Binary Search.
 This increases the probability to find feasible encryption parameters and
 thus to fall in the best case (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Binary-Search-Cases"

\end_inset

(a)).
 The binary search eventually outputs also the best point in the CNN where
 to perform this/these re-encryption step/s.
 This methodology has the following main three goals:
\end_layout

\begin_layout Enumerate
Find a plaintext modulus 
\emph on
t 
\emph default
that, in combination with the given 
\emph on
q, 
\emph default
allows to have a sufficient initial noise budget in the ciphertext to carry
 out the entire computations provided by the CNN (i.e., the forward on an
 encrypted image).
 This constraint depends only on the number of computations performed and
 not on the input data, as explained by the Eq.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
eqref{eq:TOTAL_NB}
\end_layout

\end_inset

 in the Optimization Problem in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-optimization-problem"

\end_inset

.
\end_layout

\begin_layout Enumerate
Find a plaintext modulus 
\emph on
t 
\emph default
that is bigger than the maximum infinity norm the polynomial in the underlying
 ciphertext data reaches during computations, as explained by Eq.
 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
eqref{eq:infinityNorm}
\end_layout

\end_inset

 in the Optimization Problem in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Practical-optimization-problem"

\end_inset

.
 This constraint depends on the encrypted input data and on how it combines
 through operations with the fixed encoded weights of the CNN.
\end_layout

\begin_layout Enumerate
Find the 
\series bold
minimal
\series default
 plaintext modulus 
\emph on
t 
\emph default
that satisfies the previous two constraints.
 Indeed, by fixing 
\emph on
t
\emph default
 there is the possibility to decrease 
\emph on
q 
\emph default
and, under the constraints defined in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

, also decrease the degree of the polynomial 
\emph on
n
\emph default
.
 This, on the one hand has the drawback of decreasing the initial noise
 budget in a ciphertext, but if there is the possibility to put a re-encryption
 step that brings back the level of the noise budget to the starting one,
 the effect of this negative aspect can be mitigated; on the other hand
 this gives the advantage of dealing with polynomial of a lower degree and
 thus speeding up computations and using less memory.
\end_layout

\begin_layout Standard
Since it is an heuristic, there are no exact theoretical guarantees on the
 optimality of the solution found, thus one can be interested in understanding
 the performances of this methodology in comparison to other alternatives.
 There can be two other possibilities:
\end_layout

\begin_layout Enumerate
Choose a random plaintext modulus 
\emph on
t 
\emph default
in the allowed range.
 However, in this case the "goodness" of 
\emph on
t 
\emph default
has really poor guarantees, since it can depend on the experience in the
 field of the homomorphic encryption, on the knowledge of the complexity
 of the operations performed in the CNN and on the lack that the user performing
 the choice has.
 
\end_layout

\begin_layout Enumerate
Use the automatic parameters selection tool offered by the SEAL 2.3.1 library,
 which can help the user in determining optimal encryption parameters for
 certain use-cases 
\begin_inset CommandInset citation
LatexCommand cite
key "SEALManual"

\end_inset

.
 Essentially, given the circuit to compute on encrypted data (i.e., the series
 of operations on a ciphertext) this tool builds a graph of the computation
 instead of actually calculating it and tries to estimate the grow of infinity
 norm and noise so to find appropriate overall parameters.
 The ciphertext in input is also simulated in the sense that it is represented
 as a polynomial with a certain initial infinity norm and a maximum number
 of nonzero coefficients.
 This tool consists of two parts: a 
\begin_inset Formula $\mathtt{Simulator}$
\end_inset

 component that simulates noise growth in homomorphic operations using precomput
ed estimates based on the type of operation, and a 
\begin_inset Formula $\mathtt{Chooser}$
\end_inset

 component, which estimates the growth of the coefficients in the underlying
 plaintext polynomials, and uses 
\family typewriter
Simulator
\family default
 to simulate noise growth.
 The problem is that, for example, given an addition operation and two polynomia
ls 
\begin_inset Formula $p_{1}\text{\;{and}\;}p_{2}$
\end_inset

 to sum with infinity norm respectively 
\begin_inset Formula $a_{1}\text{\;{and}\;}a_{2}$
\end_inset

 the infinity norm of the result 
\begin_inset Formula $p_{3}=p_{1}+p_{2}$
\end_inset

 is computed as 
\begin_inset Formula $||p_{3}||_{\infty}=a_{1}+a_{2}$
\end_inset

 that is a really pessimistic case, since it is true only if coefficients
 
\begin_inset Formula $a_{1}\text{\;{and}\;}a_{2}$
\end_inset

 are associated to the same power in their respective polynomials 
\begin_inset Formula $p_{1}\text{\;{and}\;}p_{2}$
\end_inset

.
 It is important to underline the fact that this estimate is used also to
 compute the noise added to the resulting polynomial and thus it will induce
 a rough computation also in the growth of the noise in the ciphertext.
 Moreover this automatic parameter selection is only designed to work with
 polynomial codifying an integer number (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Integer-Encoding"

\end_inset

) and thus it is not suitable in the case one wishes to make computations
 on polynomial that encode fractional numbers (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Fractional-Encoding"

\end_inset

) as in the case of CNNs.
\end_layout

\begin_layout Standard
In order to test the goodness of the proposed Binary Search Heuristic and
 thus of the outputted encryption parameters the following metric is introduced.
 If 
\begin_inset Formula $D$
\end_inset

 is the testing set, 
\begin_inset Formula $y_{i}$
\end_inset

 is the prediction of the CNN for image 
\emph on
i 
\emph default
and 
\begin_inset Formula $y_{true}$
\end_inset

 is the true class of image 
\emph on
i, 
\emph default
the classification error 
\begin_inset Formula $\epsilon$
\end_inset

 is 
\begin_inset Formula 
\[
\epsilon=\frac{1}{|D|}\cdot\sum_{i\in|D|}(\mathbb{I}(y_{i}\neq y_{true})).
\]

\end_inset

Then 
\begin_inset Formula $\epsilon_{\varPhi}$
\end_inset

 and 
\begin_inset Formula $\epsilon_{\tilde{\varPhi}}$
\end_inset

 define respectively the classification error of the plain-approximated
 
\begin_inset Formula $\varPhi$
\end_inset

 and the encoded 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 CNN, where 
\begin_inset Formula 
\[
\epsilon_{\tilde{\varPhi}}=\epsilon_{\varPhi}+\frac{1}{|D|}\cdot\sum_{i\in|D|}(\mathbb{I}(y_{i}\neq\tilde{y}_{i})),
\]

\end_inset

and 
\begin_inset Formula $\tilde{y}_{i}$
\end_inset

 is the prediction given by the encoded CNN 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 for the encrypted image 
\emph on
i.

\emph default
 The term 
\begin_inset Formula $\frac{1}{|D|}\cdot\sum_{i\in|D|}(\mathbb{I}(y_{i}\neq\tilde{y}_{i}))$
\end_inset

 is the error that can be added to the encoded model by non-optimal encryption
 parameters.
 Thus the relative testing error 
\begin_inset Formula 
\begin{equation}
\epsilon_{\Delta}=\epsilon_{\varPhi}-\epsilon_{\tilde{\varPhi}}\geq0\label{eq:relative-testing-error}
\end{equation}

\end_inset

 is equal to zero if the parameters found by the binary search are optimal,
 because they do not decrease the performances of the encoded CNN 
\begin_inset Formula $\tilde{\varPhi}$
\end_inset

 with respect to the plain-approximated version 
\begin_inset Formula $\varPhi$
\end_inset

.
\end_layout

\begin_layout Section
Case Study 1: 9-Layers CNN 
\begin_inset CommandInset label
LatexCommand label
name "sec:Case-Study-1"

\end_inset


\end_layout

\begin_layout Standard
This case study considers the application of the methodology proposed in
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Methodology"

\end_inset

 on a starting pre-trained CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 with 9 layers.
 Its structure before the approximation step (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximation-steps-CNN"

\end_inset

) is the following:
\end_layout

\begin_layout Enumerate

\emph on
Convolution Layer: 
\emph default
The input image is 
\begin_inset Formula $28\times28\times1$
\end_inset

.
 The convolution has 
\begin_inset Formula $20$
\end_inset

 kernels of size 
\begin_inset Formula $5\times5$
\end_inset

 with a stride of 
\begin_inset Formula $2\times2$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $12\times12\times20.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Average Pooling Layer: 
\emph default
This layer has windows of dimension 
\begin_inset Formula $2\times2\times1$
\end_inset

 with a stride of 
\begin_inset Formula $1\times1$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $11\times11\times20.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Batch Normalization Layer: 
\emph default
This layer normalizes separately each dimension in input and makes it have
 mean 0 and variance 1.
 
\end_layout

\begin_layout Enumerate

\emph on
Convolution Layer: 
\emph default
The convolution has 
\begin_inset Formula $50$
\end_inset

 kernels of size 
\begin_inset Formula $3\times3$
\end_inset

 with a stride of 
\begin_inset Formula $2\times2$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $5\times5\times50$
\end_inset

.
\end_layout

\begin_layout Enumerate

\emph on
ReLu Activation Layer: 
\emph default
This layer applies the ReLu function to each input node.
\end_layout

\begin_layout Enumerate

\emph on
Average Pooling Layer: 
\emph default
This layer has windows of dimension 
\begin_inset Formula $2\times2\times1$
\end_inset

 with a stride of 
\begin_inset Formula $1\times1$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $4\times4\times50.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Batch Normalization Layer: 
\emph default
This layer normalizes separately each dimension in input and makes it have
 mean 0 and variance 1.
\end_layout

\begin_layout Enumerate

\emph on
Fully Connected Layer: 
\emph default
This layer fully connects the incoming 
\begin_inset Formula $4\cdot4\cdot50=800$
\end_inset

 nodes to the outgoing 500 nodes.
\end_layout

\begin_layout Enumerate

\emph on
Fully Connected Layer: 
\emph default
This layer fully connects the incoming 500 nodes to the outgoing 10 nodes.
\end_layout

\begin_layout Subsection
STEP 1: Approximation 
\begin_inset CommandInset label
LatexCommand label
name "subsec:STEP-1"

\end_inset


\end_layout

\begin_layout Standard
During the 
\emph on
approximation 
\emph default
(
\noun on
step 1 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) phase the CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 becomes 
\begin_inset Formula $\varPhi$
\end_inset

.
 The structure of 
\begin_inset Formula $\varPhi$
\end_inset

 is the same of 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 except for Layer 5, where the ReLu Activation is substituted with the 
\emph on
Square Activation Layer 
\emph default
that squares the value at each input node.
 The CNN 
\begin_inset Formula $\varPhi$
\end_inset

 is trained again.
\end_layout

\begin_layout Subsection
STEP 2: Encoding
\begin_inset CommandInset label
LatexCommand label
name "subsec:STEP-2:-Encoding"

\end_inset


\end_layout

\begin_layout Standard
In the 
\emph on
encoding 
\emph default
(
\noun on
step 2 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) phase the Binary Search algorithm described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic:-Binary-Search"

\end_inset

 is run in order to find suitable encryption parameters 
\emph on
n, t 
\emph default
and 
\emph on
q 
\emph default
(see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Encryption-Parameters"

\end_inset

).
 This step is described in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

.
 The algorithm finds two sets of possible encryption parameters, then each
 weight in 
\begin_inset Formula $\varPhi$
\end_inset

 is encoded as a fixed precision floating point number as described in the
 Fractional Encoding part of Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

 using 
\begin_inset Formula $n_{i}=64\text{ bits for the integr part, }n_{f}=32$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 bits for the fractional part and a base 
\begin_inset Formula $S=3.$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 The two produced encoded network 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t}$
\end_inset

, for the two sets of parameters found have the same structure of the one
 in input but they are able to predict over encrypted data, provided that
 images are encrypted using the same 
\emph on
n, t 
\emph default
and 
\emph on
q 
\emph default
(see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

).
 The encoding of each CNN and the encryption of the data is achieved through
 the appropriate methods of the CrCNN library described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Structure"

\end_inset

.
 
\end_layout

\begin_layout Subsection
STEP 3: Testing
\end_layout

\begin_layout Standard
The
\emph on
 testing 
\emph default
(
\noun on
step 3 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) is executed over all the 10000 test images of the MNIST Dataset.
 The parameters found by the Binary Search are valid under the assumption
 that a re-encryption step is introduced (as explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

) .
 The results of this testing for the two encoded networks, is detailed in
 Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

.
\end_layout

\begin_layout Subsection
Heuristic metrics and comparison results
\begin_inset CommandInset label
LatexCommand label
name "sec:Heuristic-results-and"

\end_inset


\end_layout

\begin_layout Standard
The usage of the automatic parameter selection tool of SEAL, explained in
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

 and applied on the approximated CNN (i.e., on the computations that this
 model provides) described in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:STEP-1"

\end_inset

, outputs that there are no valid encryption parameters.
 This shows that this methodology, that overestimates the encryption parameters
 needed, is not suitable in the case there are many computations to perform
 as in a CNN, since it is unable to find any valid result, as written in
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances"

\end_inset

.
 
\begin_inset Newline newline
\end_inset

The heuristic binary search can be run on a subset of the testing set (
\noun on
Partial
\noun default
 run) or on the entire testing set (
\noun on
Full
\noun default
 run).
 
\begin_inset Newline newline
\end_inset

The Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances"

\end_inset

 shows the results of the testing on the whole testing set 
\begin_inset Formula $D$
\end_inset

 of 10000 images, and in particular it shows the relative testing error
 
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset

 (see Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:relative-testing-error"

\end_inset

), the time in seconds for a forward on an encrypted image 
\begin_inset Formula $Time_{FW}$
\end_inset

 and the initial noise budget 
\begin_inset Formula $NB$
\end_inset

 in bits for the 9-layers network 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t}$
\end_inset

 encoded with two different sets of parameters.
 
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\size small
Column Binary Search shows the encoded 9-layers CNN performances at the
 varying of the plaintext modulus 
\emph on
t
\emph default
.
 Each 
\emph on
t 
\emph default
is obtained with a different number of images tested in the heuristic.
\begin_inset Newline newline
\end_inset

Column SEAL tool shows the results of the SEAL automatic encryption parameters
 selection tool for the same 9-layers CNN.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Heuristic-performances"

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Binary Search 
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
SEAL tool
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\noun on
Partial
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\noun on
Full
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t=2^{29}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t=2^{30}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not Found
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7/10000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Time_{FW}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69.07
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70.63
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $NB$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
69
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
68
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description

\noun on
Partial
\noun default
 column shows the result with the plaintext modulus 
\begin_inset Formula $t=2^{29}$
\end_inset

 obtained by running the binary search only on 40 randomly sampled images
 with the following settings: 
\begin_inset Formula $n=4096\text{ and }q=\{q_{1}=36028797005856769,\;q_{2}=18014398492704769\},$
\end_inset

 where 
\begin_inset Formula $\sum_{i=1}^{2}log_{2}q_{i}=log_{2}q_{1}+log_{2}q_{2}=55+54=109$
\end_inset

 that is compliant with the security standards described in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 for 128-bit security.
 The maximum number of re-encryption steps is set to one.
\begin_inset Newline newline
\end_inset

 The details of the 
\noun on
partial
\noun default
 binary search
\emph on
 
\emph default
run are given in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Binary-Search-Results"

\end_inset

.
 
\end_layout

\begin_layout Description

\noun on
Full
\noun default
\color black
 column shows the result with the plaintext modulus 
\color inherit

\begin_inset Formula $t=2^{30}$
\end_inset

 obtained by running the binary search on the whole testing dataset of 10000
 images and setting the same 
\emph on
n 
\emph default
and 
\emph on
q 
\emph default
and maximum number of re-encryptions of the 
\noun on
partial 
\noun default
case.
\end_layout

\begin_layout Standard
The network encoded with the 
\begin_inset Formula $n,q\text{ and }t=2^{29}$
\end_inset

 given by the 
\noun on
partial 
\noun default
binary search can be seen as the
\series bold
 suboptimal
\series default
 encoded CNN (i.e.
 with a suboptimal plaintext modulus 
\emph on
t
\emph default
), because the relative testing error 
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset

 on the whole dataset is greater than zero, while the CNN encoded with the
 
\begin_inset Formula $n,q\text{ and }t=2^{30}$
\end_inset

 given by the 
\noun on
full 
\noun default
binary search can be seen as the 
\series bold
optimal
\series default
 encoded CNN (i.e.
 with an optimal plaintext modulus 
\emph on
t
\emph default
) for the given dataset, because the relative testing error on the whole
 dataset is equal to zero.
\begin_inset Newline newline
\end_inset

The results reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances"

\end_inset

 show that the suboptimal 
\begin_inset Formula $t=2^{29}$
\end_inset

 found by running the binary search on the 0.4% of the entire testing dataset
 is not far form the optimal plaintext modulus 
\begin_inset Formula $t=2^{30}$
\end_inset


\emph on
.
 
\emph default
The suboptimal 
\begin_inset Formula $t=2^{29}$
\end_inset

 causes a decrease in accuracy with respect to the plain non-encoded CNN
 
\begin_inset Formula $\varPhi$
\end_inset

 of only 0.07%, since the encoded model 
\begin_inset Formula $\tilde{\varPhi}_{n=4096,q=\{q_{1},q_{2}\},t=2^{29}}$
\end_inset

 mispredicts only 7 of 10000 images more than the non-encoded 
\begin_inset Formula $\varPhi$
\end_inset

.
 Indeed 
\begin_inset Formula $\varPhi$
\end_inset

 has an accuracy of the 97% while the accuracy of 
\begin_inset Formula $\tilde{\varPhi}_{n=4096,q=\{q_{1},q_{2}\},t=2^{29}}$
\end_inset

 is of 96.93%.
 This decrease in performances can be considered negligible considering
 that, the time needed to obtain that result for the binary search, is of
 about 4 hours, that is significantly less than the time needed to run the
 heuristic on the entire test dataset as in the 
\noun on
full 
\noun default
version, that is 250 times greater.
 As expected the forward time on an image does not meaningfully change at
 the varying of the plaintext modulus, this can be explained considering
 that the polynomial modulus degree is kept the same in the two versions
 (i.e., 
\begin_inset Formula $n=4096$
\end_inset

) and it is what mostly affect the computational time, since it determines
 the maximum degree of the polynomial with which computations are performed.
 The difference of 1.56 s in the two versions of the CNN can be due to the
 fact that the re-encryption step is put in two different points.
 Indeed, the noise budget of a ciphertext in input to the optimal CNN has
 one bit less than the suboptimal one.
 This means that the re-encryption step in the optimal CNN is slower since
 it has more data to re-encrypt than the re-encryption in the suboptimal
 CNN, because in the former it is put before the sub-sampling step performed
 by the Average Pooling Layer (i.e.
 before layer 6), while in the latter it is put soon after the Average Pooling
 layer (i.e.
 after layer 6).
\end_layout

\begin_layout Subsection

\noun on
Partial
\noun default
 Binary Search Results
\begin_inset CommandInset label
LatexCommand label
name "sec:Binary-Search-Results"

\end_inset


\end_layout

\begin_layout Standard
In this Subsection and in the following (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

), the focus is on the CNN 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t=2^{29}}$
\end_inset

 encoded with the parameters given by the 
\noun on
partial 
\noun default
binary search run, because it is the network that in a real use-case one
 would have chosen.
 Indeed, it is impractical to make an exhaustive run of the binary search
 on the entire testing dataset just to choose the exact plaintext modulus,
 as in the case of the 
\noun on
full 
\noun default
binary search run.
 Thus in reality, one would have accepted a small testing error, in change
 of finding suitable encryption parameters in a reasonable time.
 
\begin_inset Newline newline
\end_inset

The results of the 
\noun on
partial
\noun default
 Binary Search Heuristic introduced in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

 are showed by the plot in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:scatterPlot"

\end_inset

 and are obtained using the following input parameters:
\end_layout

\begin_layout Itemize
Pre-trained approximated model 
\begin_inset Formula $\varPhi$
\end_inset

 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:STEP-1"

\end_inset

).
\end_layout

\begin_layout Itemize
Sorted list of possible plaintext moduli 
\begin_inset Formula $t_{list}=[2^{1},2^{2},...,2^{59}]$
\end_inset

, with 
\begin_inset Formula $t_{min}=23$
\end_inset

 and 
\begin_inset Formula $t_{max}=33$
\end_inset

, that is, the plaintext modulus 
\emph on
t 
\emph default
can be a power of two between 
\begin_inset Formula $2^{24}$
\end_inset

 and 
\begin_inset Formula $2^{34}.$
\end_inset


\end_layout

\begin_layout Itemize
Security level 
\begin_inset Formula $\lambda$
\end_inset

 of 128 bits.
\end_layout

\begin_layout Itemize
Coefficient modulus 
\begin_inset Formula $q_{0}$
\end_inset

 is set as the default value given by the SEAL library for a degree of the
 polynomial modulus 
\begin_inset Formula $n=4096$
\end_inset

 and the security level 
\begin_inset Formula $\lambda=128$
\end_inset

 bits.
\end_layout

\begin_layout Itemize
Maximum number of re-encryption steps is set to 1.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Img/BSplot.png
	display false
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Maximum and average plain modulus found by the Binary Search for increasing
 number of images tested 
\begin_inset Formula $(K)$
\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "fig:scatterPlot"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The algorithm is run for 10 times and at each run a number of 
\begin_inset Formula $K$
\end_inset

 randomly sampled images of 2, 4, 8, 16, 32 (batch size) is tested.
 In the end there are 10 samples (i.e.
 obtained plaintext moduli) and in total 
\begin_inset Formula $10\times\text{batch size }$
\end_inset

 images are tested for each batch size.
 The plot shows the logarithm in base 2 of the maximum and the average value
 of the plaintext modulus obtained for a given batch size.
 One can notice that just using a batch size of 4 images and thus testing
 40 randomly sampled images, the binary search is able to find the suboptimal
 plaintext modulus 
\begin_inset Formula $t=2^{29}$
\end_inset

, as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

.
 The binary search sets the point in the CNN for the re-encryption as the
 point before Layer 7, as showed by Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Testing-times"

\end_inset

.
 The average result found increases with the batch size.
 Indeed, for a batch size of 8 images the mean of the 
\emph on
t
\emph default
 found is greater than 
\begin_inset Formula $2^{28}$
\end_inset

.
 Thus, for approximation to the next power of two, if the mean should have
 been considered as an estimator for 
\begin_inset Formula $t,$
\end_inset

 the output would still have been 
\begin_inset Formula $t=2^{29}$
\end_inset

.
 However, in this case the maximum plaintext modulus found is the best estimator
, since the goal is to determine the maximum infinity norm of a polynomial
 during computations and this depends on the input data as explained in
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

.
\end_layout

\begin_layout Subsection
Analysis Of The Suboptimal CNN 
\begin_inset CommandInset label
LatexCommand label
name "sec:AnalysisSuboptimalCNN"

\end_inset


\end_layout

\begin_layout Subsubsection
Timings and noise 
\end_layout

\begin_layout Standard
The 
\emph on
testing 
\emph default
of the encoded CNN 
\begin_inset Formula $\tilde{\varPhi}_{n=4096,q=\{q_{1},q_{2}\},t=2^{29}}$
\end_inset

 using the CrCNN library gives the following results in terms of timings.
 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Encryption.
 Each input image is 
\begin_inset Formula $28\times28\times1$
\end_inset

 (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:MNIST-Dataset"

\end_inset

) and it is encrypted as a 
\begin_inset Formula $\mathsf{ciphertext3D}$
\end_inset

 (see method 
\begin_inset Formula $\mathsf{encryptImage}$
\end_inset

 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Structure"

\end_inset

) where each pixel is a ciphertext.
 It takes on average 2.74 seconds to encrypt an image.
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Decryption.
 The decryption procedure (see method 
\begin_inset Formula $\mathsf{decryptImage}$
\end_inset

 in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Structure"

\end_inset

) gets as input a 
\begin_inset Formula $1\times10\times1$
\end_inset

 
\begin_inset Formula $\mathsf{ciphertext3D}$
\end_inset

 and outputs a 
\begin_inset Formula $\mathsf{floatCube}$
\end_inset

 of the same dimensions.
 It takes on average 0.02 seconds to compute this decryption.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\paragraph_spacing onehalf
\begin_inset Caption Standard

\begin_layout Plain Layout
Testing times of the suboptimal 9-layers 
\begin_inset Formula $\tilde{\varPhi}_{n=4096,q=\{q_{1,},q_{2}\},t=2^{29}}$
\end_inset

 and noise budget consumption in the input data (encrypted with the same
 parameters) through layers 
\begin_inset CommandInset label
LatexCommand label
name "tab:Testing-times"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align left
\begin_inset Tabular
<lyxtabular version="3" rows="11" columns="5">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Layer #
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Operation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Threads' #
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Time(s)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
NB
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Convolution 
\begin_inset Formula $(5\times5\times20)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
20
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
30.73
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
69
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 2
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Average Pooling 
\begin_inset Formula $(2\times2\times1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
2.45
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
64
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 3
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Batch Normalization 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
2.03
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
61
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 4
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Convolution 
\begin_inset Formula $(3\times3\times50)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
50
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
7.89
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
59
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 5
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Square
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
50
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
0.65
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
53
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 6
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Average Pooling 
\begin_inset Formula $(2\times2\times1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
0.76
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
13
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Re-encryption
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Decryption+Encryption
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
3.20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 7
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Batch Normalization
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
0.68
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
69
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 8
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Fully Connected 
\begin_inset Formula $(800,500)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
40
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
18.23
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
67
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 9
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Fully Connected 
\begin_inset Formula $(500,10)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
50
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
2.45
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
59
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset

The timings reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Testing-times"

\end_inset

 are obtained by running the forward on an encrypted image.
 Since the CrCNN library (see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Structure"

\end_inset

) allows to split the computational load, for some layers this possibility
 is used to obtain better performances.
 The Convolution Layer 1 is run with 20 threads in parallel, this means
 that each thread performs a single one dimensional convolution with a kernel
 of dimensions 
\begin_inset Formula $5\times5$
\end_inset

.
 The Convolution Layer 4 is run with 50 threads in parallel and this means
 that each thread performs one convolution of dimensions 
\begin_inset Formula $3\times3$
\end_inset

 over an input image of 
\begin_inset Formula $11\times11\times20.$
\end_inset

 The Square Layer 5 is run with 50 threads and this means that each one
 of them computes the operation over one channel in input.
 For the Fully Connected Layer 8 each thread performs the operation over
 20 input neurons (i.e.
 800/40), while in the last Fully Connected Layer each thread performs the
 operation over 10 (i.e.
 500/50) input neurons.
 
\begin_inset Newline newline
\end_inset

 The most computationally intensive layers remain the two Convolution Layers
 and the first Fully Connected Layer, while the re-encryption step does
 not affect too much the forward execution time.
 
\begin_inset Newline newline
\end_inset

The Noise Budget column reports the amount of noise budget, expressed in
 bits, in input to the corresponding layer/ re-encryption step and shows
 that the Square Layer 5 is the one that consumes most of the budget.
 This is an expected result since a ciphertext by ciphertext multiplication
 is performed and, as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Operations-and-Noise"

\end_inset

, it is less efficient than a ciphertext by plaintext multiplication that
 is performed most of the times in the CNN (i.e., Convolution and in Fully
 Connected layers).
\end_layout

\begin_layout Subsubsection
Accuracy Tracking Through Transformation's Steps
\end_layout

\begin_layout Standard
During the transformation's steps the CNN is subject to redefinitions that
 could cause a loss in accuracy as already exposed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

 and Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

.
 Indeed in the approximation step the ReLu is substituted with a Square
 function and this introduces some errors in the CNN, since negative neurons
 are not truncated to be zero as the ReLu does but become small numbers
 around zero.
 The Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CNN's-accuracy-mutation"

\end_inset

 shows that this approximation step causes the starting accuracy of 98%
 to decrease of 1 point percentage, that is not a big performance's loss.
 The last transformation step that involves the encoding, and thus the applicati
on of the CNN to encrypted images, slightly affects performances.
 This implies that the suboptimal parameter 
\begin_inset Formula $t=2^{29}$
\end_inset

 found by the 
\noun on
partial 
\noun default
Binary Search run is close to the best value that it is possible to find
 with the given dataset (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

).
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\paragraph_spacing onehalf
\begin_inset Caption Standard

\begin_layout Plain Layout
9-layers CNN's accuracy mutation 
\begin_inset CommandInset label
LatexCommand label
name "tab:CNN's-accuracy-mutation"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Accuracy 9-layers CNN
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Starting 
\begin_inset Formula $\breve{\varPhi}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Approximated 
\begin_inset Formula $\varPhi$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Encoded 
\begin_inset Formula $\tilde{\varPhi}_{n=4096,q=\{q_{1},q_{2}\},t=2^{29}}$
\end_inset

 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
98%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
97%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
96.93%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Case Study 2: 6-Layers CNN
\begin_inset CommandInset label
LatexCommand label
name "sec:Case-Study-2"

\end_inset


\end_layout

\begin_layout Standard
This case study considers the application of the methodology proposed in
 Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Methodology"

\end_inset

 on a starting pre-trained CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 with 6 layers.
 This CNN is simpler than the 9-layers CNN considered in the previous case
 study (Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

).
 Its structure before the approximation step (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Approximation-steps-CNN"

\end_inset

) is the following:
\end_layout

\begin_layout Enumerate

\emph on
Convolution Layer: 
\emph default
The input image is 
\begin_inset Formula $28\times28\times1$
\end_inset

.
 The convolution has 
\begin_inset Formula $32$
\end_inset

 kernels of size 
\begin_inset Formula $5\times5$
\end_inset

 with a stride of 
\begin_inset Formula $1\times1$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $24\times24\times32.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Average Pooling Layer: 
\emph default
This layer has windows of dimension 
\begin_inset Formula $2\times2\times1$
\end_inset

 with a stride of 
\begin_inset Formula $2\times2$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $12\times12\times32.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Convolution Layer: 
\emph default
The convolution has 
\begin_inset Formula $64$
\end_inset

 kernels of size 
\begin_inset Formula $5\times5$
\end_inset

 with a stride of 
\begin_inset Formula $1\times1$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $8\times8\times64.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Average Pooling Layer: 
\emph default
This layer has windows of dimension 
\begin_inset Formula $2\times2\times1$
\end_inset

 with a stride of 
\begin_inset Formula $2\times2$
\end_inset

.
 The output of this layer is therefore 
\begin_inset Formula $4\times4\times64.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
Fully Connected Layer: 
\emph default
This layer fully connects the incoming 
\begin_inset Formula $4\cdot4\cdot64=1024$
\end_inset

 nodes to the outgoing 512 nodes.
\end_layout

\begin_layout Enumerate

\emph on
Fully Connected Layer: 
\emph default
This layer fully connects the incoming 512 nodes to the outgoing 10 nodes.
\end_layout

\begin_layout Subsection
STEP 1: Approximation 
\begin_inset CommandInset label
LatexCommand label
name "subsec:STEP-1-1"

\end_inset


\end_layout

\begin_layout Standard
For this 6-layers CNN the 
\emph on
approximation 
\emph default
(
\noun on
step 1 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) phase is unnecessary since it already contains only layers with polynomial
 functions.
 Thus this step is skipped and the structure of the approximated 
\begin_inset Formula $\varPhi$
\end_inset

 coincides with the one of the starting CNN 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

.
\end_layout

\begin_layout Subsection
STEP 2: Encoding
\end_layout

\begin_layout Standard
The 
\emph on
encoding 
\emph default
(
\noun on
step 2 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) is exactly the same of the previous case study (Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:STEP-2:-Encoding"

\end_inset

), since the Binary Search finds two sets of possible encryption parameters
 and each weight in 
\begin_inset Formula $\varPhi$
\end_inset

 is encoded as a fixed precision floating point number as described in the
 Fractional Encoding part of Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encoding"

\end_inset

 using 
\begin_inset Formula $n_{i}=64\text{ bits for the integr part, }n_{f}=32$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 bits for the fractional part and a base 
\begin_inset Formula $S=3.$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 The two produced encoded network 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t}$
\end_inset

, for the two sets of parameters found have the same structure of the one
 in input but they are able to predict over encrypted data, provided that
 images are encrypted using the same 
\emph on
n, t 
\emph default
and 
\emph on
q 
\emph default
(see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Encryption-Scheme"

\end_inset

).
 
\end_layout

\begin_layout Subsection
STEP 3: Testing
\end_layout

\begin_layout Standard
Also for this CNN the
\emph on
 testing 
\emph default
(
\noun on
step 3 
\noun default
see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Problem-Formulation"

\end_inset

) is executed over all the 10000 test images of the MNIST Dataset.
 The parameters found by the Binary Search are valid under the assumption
 that a re-encryption step is introduced (as explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

).
 The results of this testing for the two encoded networks, is detailed in
 Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Heuristic-resultsTiny"

\end_inset

.
\end_layout

\begin_layout Subsection
Heuristic metrics and comparison results 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Heuristic-resultsTiny"

\end_inset


\end_layout

\begin_layout Standard
The automatic parameter selection tool of SEAL explained in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-metrics"

\end_inset

 is applied on the approximated 6-layers CNN (i.e., on the computations that
 this model provides) described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-2"

\end_inset

, but also in this case no valid parameters are found, as reported in Table
 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances-1"

\end_inset

.
\begin_inset Newline newline
\end_inset

Also in this case study the heuristic binary search is run on a subset of
 the testing set (
\noun on
Partial
\noun default
 run) and on the entire testing set (
\noun on
Full
\noun default
 run), however the plaintext modulus 
\emph on
t 
\emph default
is searched in the powers of two between 
\begin_inset Formula $2^{10}$
\end_inset

 and 
\begin_inset Formula $2^{20}$
\end_inset

 because this CNN has less layers and thus the infinity norm of a polynomial
 during the overall computation has less possibility to grow further than
 
\begin_inset Formula $2^{20}$
\end_inset

.
\begin_inset Newline newline
\end_inset

The Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances-1"

\end_inset

 describes the results of the testing on the whole testing set 
\begin_inset Formula $D$
\end_inset

 of 10000 images, and in particular it shows the relative testing error
 
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset

 (see Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:relative-testing-error"

\end_inset

), the time in seconds for a forward on an encrypted image 
\begin_inset Formula $Time_{FW}$
\end_inset

 and the initial noise budget 
\begin_inset Formula $NB$
\end_inset

 in bits for the 6-layers network 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t}$
\end_inset

 encoded with two different sets of parameters.
 
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\size small
Column Binary Search shows the encoded 6-layers CNN performances at the
 varying of the plaintext modulus 
\emph on
t
\emph default
.
 Each 
\emph on
t
\emph default
 is obtained with a different number of images tested in the heuristic.
\begin_inset Newline newline
\end_inset

Column SEAL tool shows the results of the SEAL automatic encryption parameters
 selection tool for the same 6-layers CNN.
 
\begin_inset CommandInset label
LatexCommand label
name "tab:Heuristic-performances-1"

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Binary Search 
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
SEAL tool
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\noun on
Partial
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\noun on
Full
\series default
\noun default
 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t=2^{16}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t=2^{18}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not Found
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15/10000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Time_{FW}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35.58
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
35.55
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $NB$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
26
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Not defined
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Description

\noun on
Partial
\noun default
 column shows the result with the plaintext modulus 
\begin_inset Formula $t=2^{16}$
\end_inset

 obtained by running the binary search only on 40 randomly sampled images
 with the following settings: 
\begin_inset Formula $n=2048\text{ and }q=18014398492704769,$
\end_inset

 where 
\begin_inset Formula $log_{2}q=54$
\end_inset

 that is compliant with the security standards described in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Default-pairs-(n,q)"

\end_inset

 for 128-bit security.
 The maximum number of re-encryption steps is set to one.
 The binary search puts the allowed re-encryption step before layer 5.
 The network encoded with these parameters can be seen as the 
\series bold
suboptimal
\series default
 encoded CNN (i.e.
 with a suboptimal plaintext modulus 
\emph on
t
\emph default
), because the relative testing error 
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset

 (see Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:relative-testing-error"

\end_inset

) on the whole dataset 
\emph on
D 
\emph default
is greater than zero.
\end_layout

\begin_layout Description

\noun on
Full
\noun default
\color black
 column shows the result with the plaintext modulus 
\color inherit

\begin_inset Formula $t=2^{18}$
\end_inset

 obtained by running the binary search on the whole testing dataset of 10000
 images and setting the same 
\emph on
n 
\emph default
and 
\emph on
q 
\emph default
and maximum number of re-encryptions of the 
\noun on
partial 
\noun default
case.
 The binary search puts the allowed re-encryption step before layer 5, at
 the same point of the 
\noun on
partial 
\noun default
case.
 The network encoded with these parameters can be seen as the 
\series bold
optimal
\series default
 encoded CNN (i.e.
 with an optimal plaintext modulus 
\emph on
t
\emph default
) for the given dataset, because the relative testing error 
\begin_inset Formula $\epsilon_{\Delta}$
\end_inset

 on the whole dataset is equal to zero.
\end_layout

\begin_layout Standard
The results reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Heuristic-performances-1"

\end_inset

 show that the suboptimal 
\begin_inset Formula $t=2^{16}$
\end_inset

 found by running the binary search on the 0.4% of the entire testing dataset
 is not far form the optimal (for the given dataset) plaintext modulus 
\begin_inset Formula $t=2^{18}$
\end_inset


\emph on
.
 
\emph default
The suboptimal 
\begin_inset Formula $t=2^{16}$
\end_inset

 causes a decrease in accuracy with respect to the plain non-encoded CNN
 
\begin_inset Formula $\varPhi$
\end_inset

 of 0.15%, since the encoded model 
\begin_inset Formula $\tilde{\varPhi}_{n=2048,q,t=2^{16}}$
\end_inset

 mispredicts only 15 of 10000 images more than the non-encoded 
\begin_inset Formula $\varPhi$
\end_inset

.
 Indeed 
\begin_inset Formula $\varPhi$
\end_inset

 has an accuracy of the 90% while the accuracy of 
\begin_inset Formula $\tilde{\varPhi}_{n=2048,q,t=2^{16}}$
\end_inset

 is of 89.85%.
 This decrease in performances can be considered negligible considering
 that the time needed to obtain that suboptimal plaintext modulus for the
 binary search is of less than 2 hours, that is significantly less than
 the time needed to run the heuristic on the entire test dataset as in the
 
\noun on
full 
\noun default
version, that is 250 times greater.
 The re-encryption step is set in both the two versions of the binary search
 at the same level, that is before layer 5.
 As explained in the previous case study in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

 the varying of the plaintext modulus does not affect a lot the forward
 time, since it is the polynomial modulus degree that mostly influences
 it.
 This is also demonstrated by the fact that the forward time needed by this
 6-layers CNN (i.e., 35.58 s) is about one half of the one needed by the 9-layers
 CNN (i.e., 69.07 s see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Heuristic-results-and"

\end_inset

).
 Indeed, even if the 6-layers network is shorter than the 9-layers network
 (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

), it is composed of more convolutional filters and bigger fully connected
 layers, that are considered the mostly computationally intensive layers
 as showed in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

.
 However, in the 6-layers CNN all these heavy computations are performed
 with polynomials of a smaller degree, thus they are considerably accelerated.
\end_layout

\begin_layout Subsection
Analysis Of The Suboptimal CNN 
\begin_inset CommandInset label
LatexCommand label
name "sec:AnalysisSuboptimalCNN-1"

\end_inset


\end_layout

\begin_layout Standard
This analysis focuses on the suboptimal 6-layers CNN 
\begin_inset Formula $\tilde{\varPhi}_{n,q,t=2^{16}}$
\end_inset

 encoded with the parameters given by the 
\noun on
partial 
\noun default
binary search run, because it is the network that in a real use-case one
 would have chosen, since it is impractical to make an exhaustive run of
 the binary search on the entire testing dataset just to choose the exact
 plaintext modulus, as in the case of the 
\noun on
full 
\noun default
binary search run.
\end_layout

\begin_layout Subsubsection
Timings and noise 
\end_layout

\begin_layout Standard
The 
\emph on
testing 
\emph default
of the encoded CNN 
\begin_inset Formula $\tilde{\varPhi}_{n=2048,q,t=2^{16}}$
\end_inset

 using the CrCNN library gives the following results in terms of timings.
 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Encryption.
 It takes on average 1.26 seconds to encrypt pixel by pixel (as explained
 in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

) a 
\begin_inset Formula $28\times28\times1$
\end_inset

 image.
 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Decryption.
 The decryption procedure (as explained in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

) takes on average 0.005 seconds.
\end_layout

\begin_layout Standard
Both encryption and decryption take about half of the time needed with the
 parameters in the previous case study (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

).
 This is due to the fact that the polynomial modulus degree 
\emph on

\begin_inset Formula $n=2048$
\end_inset

 
\emph default
is
\emph on
 
\emph default
halved with respect to the previous case study, where 
\begin_inset Formula $n=4096.$
\end_inset


\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\paragraph_spacing onehalf
\begin_inset Caption Standard

\begin_layout Plain Layout
Testing times of the suboptimal 6-layers 
\begin_inset Formula $\tilde{\varPhi}_{n=2048,q,t=2^{16}}$
\end_inset

 and noise budget consumption in the input data (encrypted with the same
 parameters) through layers 
\begin_inset CommandInset label
LatexCommand label
name "tab:Testing-times-1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align left
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="5">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Layer #
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Operation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Threads' #
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
Time(s)
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
\size small
NB
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Convolution 
\begin_inset Formula $(5\times5\times32)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
32
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
3.35
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 2
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Average Pooling 
\begin_inset Formula $(2\times2\times1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1.22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
23
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 3
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Convolution 
\begin_inset Formula $(5\times5\times64)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
64
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
23.88
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 4
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Average Pooling 
\begin_inset Formula $(2\times2\times1)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
0.39
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Re-encryption
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Decryption+Encryption
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
1.77
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 5
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Fully Connected 
\begin_inset Formula $(1024,512)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
42
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
4.34
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Layer 6
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Fully Connected 
\begin_inset Formula $(512,10)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
42
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
0.62
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset

The timings reported in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Testing-times-1"

\end_inset

 are obtained by running the forward on an encrypted image.
 The Convolution Layer 1 is run with 32 threads in parallel, this means
 that each thread performs a single one dimensional convolution with a kernel
 of dimensions 
\begin_inset Formula $5\times5$
\end_inset

.
 The Convolution Layer 3 is run with 64 threads in parallel and this means
 that each thread performs one convolution of dimensions 
\begin_inset Formula $5\times5$
\end_inset

 over an input image of 
\begin_inset Formula $12\times12\times32.$
\end_inset

 In the Fully Connected Layer 5, 41 threads perform the operations over
 24 input neurons (i.e.
 1024/42), while one thread executes the operations on the remaining 
\begin_inset Formula $1024/42+1024\%42=24+16=40$
\end_inset

 input neurons, while in the last Fully Connected Layer all the threads
 except one perform the operations over 12 (i.e.
 512/42) input neurons and one of them executes the operations on the remaining
 20 input neurons.
 
\begin_inset Newline newline
\end_inset

The most computationally intensive layer is the second Convolution Layer,
 since there are 64 filters to compute, and this result confirms the one
 found in the previous case study in Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

.
\begin_inset Newline newline
\end_inset

The Noise Budget column reports the amount of noise budget, expressed in
 bits, in input to the corresponding layer/ re-encryption step.
 The second Convolution and the first Fully Connected layers consume about
 8 bits of noise budget, since there many ciphertext by plaintext multiplication
s and ciphertext by ciphertext additions.
 However, there is no layer that performs the heaviest operation, in terms
 of noise budget consumption, that is the ciphertext by ciphertext multiplicatio
n, as in the case of the Square layer (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:AnalysisSuboptimalCNN"

\end_inset

) and this decreases significantly the amount of noise budget needed to
 carry out the entire computation.
 
\end_layout

\begin_layout Subsubsection
Accuracy Tracking Through Transformation's Steps
\end_layout

\begin_layout Standard
The approximation step is skipped since it is unnecessary, thus the accuracy
 of the starting CNN 
\series bold

\begin_inset Formula $\breve{\varPhi}$
\end_inset


\series default
 is equal to the accuracy of the approximated
\series bold
 
\series default
CNN 
\begin_inset Formula $\varPhi$
\end_inset

, because 
\begin_inset Formula $\breve{\varPhi}$
\end_inset

 is trivially equal to 
\begin_inset Formula $\varPhi$
\end_inset

.
 
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\paragraph_spacing onehalf
\begin_inset Caption Standard

\begin_layout Plain Layout
6-layers CNN's accuracy mutation 
\begin_inset CommandInset label
LatexCommand label
name "tab:CNN's-accuracy-mutation-1"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Accuracy 6-layers CNN
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Starting 
\begin_inset Formula $\breve{\varPhi}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Approximated 
\begin_inset Formula $\varPhi$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Encoded 
\begin_inset Formula $\tilde{\varPhi}_{n=2048,q,t=2^{16}}$
\end_inset

 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
90%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
89.85%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset

The Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CNN's-accuracy-mutation-1"

\end_inset

 shows that the last and unique transformation step that involves the encoding
 and thus the application of the CNN to encrypted images slightly affect
 performances.
 This implies that the suboptimal parameter 
\begin_inset Formula $t=2^{16}$
\end_inset

 found by the 
\noun on
partial 
\noun default
Binary Search run is close to the best value that is possible to find with
 the given dataset (see Subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Heuristic-resultsTiny"

\end_inset

), but is not the optimal one.
 The starting accuracy of this network is 8 points percentage less than
 the 9-layers CNN described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Case-Study-1"

\end_inset

, this is due to the simpler structure of this 6-layers CNN.
 However, this simpler structure allows to perform less operations.
 This implies to have an initial smaller noise budget and thus the possibility
 to employ a smaller 
\emph on
n.
 
\emph default
This halves the time needed to perform a forward on an image with respect
 to the 9-layers CNN case.
\end_layout

\begin_layout Chapter
Conclusions and Future Works
\begin_inset CommandInset label
LatexCommand label
name "chap:Conclusions-and-Future"

\end_inset


\end_layout

\begin_layout Standard
This Chapter reviews the explained work and offers final conclusions in
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusions"

\end_inset

 by giving an overview of the proposed methodology and of results.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Future-Works"

\end_inset

 describes some future works that may be worth of further analysis.
\end_layout

\begin_layout Section
Conclusions 
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusions"

\end_inset


\end_layout

\begin_layout Standard
This document proposes a methodology and a library to transform a normal
 CNN in a network able to process homomorphically encrypted images.
 Moreover it offers a mathematical formulation for the problem of finding
 the best encryption parameters for the BFV encryption scheme, by also consideri
ng the practical aspects of this problem.
 It also provides to the reader a heuristic, based on a binary search algorithm,
 to solve the problem of the parameters' choice, tailored on the specific
 privacy-preserving CNN.
 The tradeoff between accuracy and time to obtain the encrypted prediction
 at the varying of the CNN and the parameters found by the heuristic is
 also explored.
 The results show that the proposed methodology is effective since it enables
 to use a 9-layers CNN with two convolution and fully connected layers,
 to make predictions on encrypted images, even if the time needed to complete
 a forward on a single image is bigger than the time that would have been
 necessary without the encryption.
 The transformation of the CNN introduces a small loss in accuracy, in part
 due to the approximations of the functions computed by the layers to polynomial
 functions and in part due to the encryption parameters found.
 However, considering that the time needed to find the suboptimal encryption
 parameters by using the binary search is reasonably small, the loss in
 accuracy of 0.07% can be considered negligible.
 The proposed methodology is also tested on a smaller CNN with 6 layers
 that does not require any approximations to be compliant with the possible
 operations of the HE.
 This 6-layers CNN has a lower starting accuracy with respect to the 9-layers
 CNN and the loss in accuracy introduced by the suboptimal encryption parameters
 found by the proposed heuristic is of 0.15%, however it requires about half
 of the time needed by the 9-layers CNN to compute a forward on an image.
 Moreover, the heuristic proposed is a powerful instrument for those who
 want to use a CNN with encrypted images, but they have not a strong background
 in the field of homomorphic encryption.
\begin_inset Newline newline
\end_inset

This thesis proves that the possibility to use HE together with CNNs is
 a concrete solution to the privacy issues that arise by the usage of cloud
 based machine learning techniques and opens the way to many possible improvemen
ts and alternatives.
\end_layout

\begin_layout Section
Future Works 
\begin_inset CommandInset label
LatexCommand label
name "sec:Future-Works"

\end_inset


\end_layout

\begin_layout Standard
There are many possible related fields of research that can be explored
 as a continuation of this work.
 One of this consists in enhancing the performances of the encoded CNN in
 terms of times and in particular in terms of throughput.
 This could be done by introducing in the developed CrCNN library the possibilit
y of using SIMD 
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "SIMD"
description "Single Instruction Multiple Data"

\end_inset

operations, allowed by the BFV encryption scheme.
 Moreover, the consideration of a real scenario with a third party server
 to which send encrypted data can be useful in order to understand transmission
 times and message sizes.
\begin_inset Newline newline
\end_inset

Other alternatives researches can involve the implementation of techniques
 that allow to perform the backward step directly on encrypted data, since
 this implies to train the CNN homomorphically and in principle access to
 a larger base of data.
 If all the activation functions are polynomials, and the loss function
 is polynomial too, back-propagation can be computed using additions and
 multiplications only.
 However, there are several challenges in doing so.
 Computational complexity is a major challenge.
 Even when trained on plaintext, neural networks are slow to train.
 Another challenging aspect in the presence of encryption is the lack of
 ability of a data scientist to inspect the data and the trained model,
 to add features and to tune the network.
 The introduction of sophisticated hardware such as GPUs and FPGAs can also
 be considered to accelerate computations.
 
\begin_inset Newline newline
\end_inset

From the point of view of the homomorphic encryption theory and its implementati
on, it could be useful to think of an efficient way to allow multiple data
 providers to use the same public key to encrypt data and different secret
 keys to decrypt the result.
 This could permit to the outsourced server to analyze data coming from
 different users.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Kuri0OOAP0M17"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
